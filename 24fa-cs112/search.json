[
  {
    "objectID": "03-version-control.html",
    "href": "03-version-control.html",
    "title": "Version control",
    "section": "",
    "text": "One of the defining principles behind how this course teaches computing is that everything the instructor and the students produce should be reproducible – how you get a result is just as important as the result itself. Implicit in the idea of reproducibility is collaboration, the code you produce is documentation of the process and it is critical to share it (even if only with yourself in the future). One of the goals of this course is to teach students tools that make this documentation and collaboration as robust and painless as possible. This is best accomplished with a distributed version control system like Git\nThis course adopts a top down approach to teaching Git – students are required to use it for all assignments. These type of tools tend to suffer from delayed gratification as when they are first introduced students view them as a clunky addition to their workflow and it is not until weeks or even months later that they experience the value first hand.\nIf this section doesn’t convince you that you should be using Git and GitHub in your data science course, Alternative Setups describes how to leverage RStudio Cloud features for assignment dissemination, collection, and providing feedback. You can also use your own institution’s learning management system for this purpose as well.",
    "crumbs": [
      "Infrastructure",
      "Version control"
    ]
  },
  {
    "objectID": "03-version-control.html#git",
    "href": "03-version-control.html#git",
    "title": "Version control",
    "section": "Git",
    "text": "Git\nLearning Git is a steep hill to climb, but with appropriate and user friendly tooling and careful pedagogy, being able to use core functionality of git for the purposes of version control in a data analysis context doesn’t have to be.\nThe learning curve for Git is unavoidable but I have found it best to focus on core functionality. Specifically, I teach a simple centralized git workflow which uses RStudio’s project based git GUI. Each new assignment starts with creating a new project from git (i.e. clone), the RStudio git GUI continuously displays git status and allows users to add, rm, commit, push, and pull. These happen to be the most commonly used git commands, and using only these students will be able to do most of what they need to do to work and collaborate on assignments and submit them.\nHowever it is not unusual for students to mangle their repositories such that the command line tools become necessary, and when this happens, the instruction team can help students get out of the rut.\nThe most complicated task students regularly encounter are merge conflicts, most of which are straight forward to resolve. Students often develop elaborate workflows to avoid these types of issues but they eventually come to understand the resolution process.\nIt is super important to encourage students to commit early and often to reduce the size of each change. Finally, in the early stages of learning git it is useful to engineer situations in which students encounter problems while they are in the classroom so that the professor and teaching assistants are present to troubleshoot and walk them through the process in person. A sample activity for resolving merge conflicts is provided in the course materials here.",
    "crumbs": [
      "Infrastructure",
      "Version control"
    ]
  },
  {
    "objectID": "03-version-control.html#github",
    "href": "03-version-control.html#github",
    "title": "Version control",
    "section": "GitHub",
    "text": "GitHub\nThe use of GitHub also goes a long way to help students visualize and understand the git process which also aids in student buy-in. The web interface allows students to easily view diffs (file changes over time) in files they are collaborating on, keep track of commit histories, and search both the current state as well as the entire history of the code base. Within the classroom GitHub can be thought of as an advanced and flexible learning management system (compared to traditional tools like Blackboard or Sakai).\nAt its most basic, GitHub can be used as a central repository where students turn in their work and where the professor and teaching assistants then collect it and provide feedback. However using this ecosystem for only assignment submission ignores the most compelling features and advantages. In our classes students are expected to push their work in progress throughout the assignment period. This is not enforced explicitly, but rather through the design of the assignments. Most assignments are large scale and team based, meaning no one student can easily complete all the work on their own. In addition, the various tasks within the assignment are interdependent, meaning students are not able to divide up the work and complete each piece individually. This type of design strongly encourages the students to share their work in progress which they are able to do using GitHub. This is also useful to the instructor as it allows for opportunities for observation and feedback through the course of the assignment without forcing students to turn in “drafts”.\nAdditionally, GitHub’s organization and teams features are a natural fit for managing course related tasks. We have used a model where each class has a separate organization to which the students are invited at the beginning of the semester. Students have individual and team personas on GitHub, and are given write access to repos for assignments accordingly, depending on whether the assignment is to be completed individually or in teams.\nIn general, I have found that using one repository per team per assignment works best. This creates a LOT of repositories by the end of the semester, but that’s okay! In order to comply with Family Educational Rights and Privacy Act (FERPA) requirements all student repositories are kept private by default, which is possible at no cost thanks to GitHub’s generous academic discount policy.\nSetup and management for larger classes can be challenging due to the sheer number of components, however most actions can be scripted via the GitHub API which can dramatically reduce the course administrative workload. Two solutions to this problem are (1) GitHub Classroom and (2) ghclass. Use of ghclass, an R package for GitHub classroom tools is detailed below, and use of GitHub classroom is described in Alternative Setups.",
    "crumbs": [
      "Infrastructure",
      "Version control"
    ]
  },
  {
    "objectID": "03-version-control.html#ghclass",
    "href": "03-version-control.html#ghclass",
    "title": "Version control",
    "section": "ghclass",
    "text": "ghclass\nThe ghclass package is designed to enable instructors to efficiently manage their courses on GitHub. It has a wide range of functionality for managing organizations, teams, repositories, and users on GitHub and helps automate most of the tedious and repetitive tasks around creating and distributing assignments.\nIf you would like to learn more about using ghclass to set up your course on GitHub, I strongly recommend reviewing the video and materials from the following 1.5 hr workshop: Teaching computing with Git and GitHub.",
    "crumbs": [
      "Infrastructure",
      "Version control"
    ]
  },
  {
    "objectID": "03-version-control.html#learn-more",
    "href": "03-version-control.html#learn-more",
    "title": "Version control",
    "section": "Learn more",
    "text": "Learn more\nIf you would like to learn more about teaching with version control, I recommend the following paper.\n\nBeckman, M. D., Çetinkaya-Rundel, M., Horton, N. J., Rundel, C. W., Sullivan, A. J., & Tackett, M. (2020). Implementing version control with Git and GitHub as a learning objective in statistics and data science courses. doi.org/10.1080/10691898.2020.1848485\n\nIf you would like to learn more about using version control with R, I strongly recommend Happy Git with R.",
    "crumbs": [
      "Infrastructure",
      "Version control"
    ]
  },
  {
    "objectID": "hello.html",
    "href": "hello.html",
    "title": "Hello #dsbox!",
    "section": "",
    "text": "Hello! And welcome!\nThere is a little bit of something for everyone (who wants to teach/learn) data science in this box.\nIf you are an educator we recommend consuming the content in the order presented here: first familiarize yourself with the design principles, course syllabus, and the tech stack, then browse the course content, and then review the details of the computing infrastructure and pedagogy of the course.\nIf you are a learner, you might consider jumping straight into the course content.",
    "crumbs": [
      "Hello #dsbox!"
    ]
  },
  {
    "objectID": "02-making-rigorous-conclusions.html",
    "href": "02-making-rigorous-conclusions.html",
    "title": "Making rigorous conclusions",
    "section": "",
    "text": "In this part we introduce modelling and statistical inference for making data-based conclusions. We discuss building, interpreting, and selecting models, visualizing interaction effects, and prediction and model validation. Statistical inference is introduced from a simulation based perspective, and the Central Limit Theorem is discussed very briefly to lay the foundation for future coursework in statistics.",
    "crumbs": [
      "Content",
      "Making rigorous conclusions"
    ]
  },
  {
    "objectID": "02-making-rigorous-conclusions.html#slides-videos-and-application-exercises",
    "href": "02-making-rigorous-conclusions.html#slides-videos-and-application-exercises",
    "title": "Making rigorous conclusions",
    "section": "Slides, videos, and application exercises",
    "text": "Slides, videos, and application exercises\n\nModelling data\n\nUnit 4 - Deck 1: The language of models\n\nSlides\n\n\nSource\n\n\nVideo\n\n\n\nUnit 4 - Deck 2: Fitting and interpreting models\n\nSlides\n\n\nSource\n\n\nVideo\n\n\nIMS :: Chp 7 - Linear regression with a single predictor\n\n\n\nUnit 4 - Deck 3: Modelling nonlinear relationships\n\nSlides\n\n\nSource\n\n\nVideo\n\n\n\nUnit 4 - Deck 4: Models with multiple predictors\n\nSlides\n\n\nSource\n\n\nVideo\n\n\nIMS :: Chp 8 - Linear regression with multiple predictors\n\n\n\nUnit 4 - Deck 5: More models with multiple predictors\n\nSlides\n\n\nSource\n\n\nVideo\n\n\n\n\nClassification and model building\n\nUnit 4 - Deck 6: Logistic regression\n\nSlides\n\n\nSource\n\n\nVideo\n\n\nIMS :: Chp 9 - Logistic regression\n\n\n\nUnit 4 - Deck 7: Prediction and overfitting\n\nSlides\n\n\nSource\n\n\nVideo\n\n\ntidymodels :: Build a model\n\n\n\nUnit 4 - Deck 8: Feature engineering\n\nSlides\n\n\nSource\n\n\nVideo\n\n\ntidymodels :: Preprocess your data with recipes\n\n\n\n\nModel validation\n\nUnit 4 - Deck 9: Cross validation\n\nSlides\n\n\nSource\n\n\nVideo\n\n\ntidymodels :: Evaluate your model with resampling\n\n\n\nThe Office + Feature engineering, Pt. 1\n\nSource\n\n\nVideo\n\n\n\nThe Office + Cross validation, Pt. 2\n\nSource\n\n\nVideo\n\n\n\n\nUncertainty quantification\n\nUnit 4 - Deck 10: Quantifying uncertainty\n\nSlides\n\n\nSource\n\n\nVideo\n\n\n\nUnit 4 - Deck 11: Bootstrapping\n\nSlides\n\n\nSource\n\n\nVideo\n\n\nIMS :: Chp 12 - Confidence intervals with bootstrapping\n\n\n\nUnit 4 - Deck 12: Hypothesis testing\n\nSlides\n\n\nSource\n\n\nIMS :: Chp 11 - Hypothesis testing with randomization\n\n\n\nUnit 4 - Deck 13: Inference overview\n\nSlides\n\n\nSource",
    "crumbs": [
      "Content",
      "Making rigorous conclusions"
    ]
  },
  {
    "objectID": "02-making-rigorous-conclusions.html#labs",
    "href": "02-making-rigorous-conclusions.html#labs",
    "title": "Making rigorous conclusions",
    "section": "Labs",
    "text": "Labs\n\nLab 10: Grading the professor, Pt. 1\nFitting and interpreting simple linear regression models\n\nInstructions\n\n\nSource\n\n\nStarter\n\n\n\nLab 11: Grading the professor, Pt. 2\nFitting and interpreting multiple linear regression models\n\nInstructions\n\n\nSource\n\n\nStarter\n\n\n\nLab 12: Smoking while pregnant\nConstructing confidence intervals, conducting hypothesis tests, and interpreting results in context of the data\n\nInstructions\n\n\nSource\n\n\nStarter",
    "crumbs": [
      "Content",
      "Making rigorous conclusions"
    ]
  },
  {
    "objectID": "02-making-rigorous-conclusions.html#homework-assignments",
    "href": "02-making-rigorous-conclusions.html#homework-assignments",
    "title": "Making rigorous conclusions",
    "section": "Homework assignments",
    "text": "Homework assignments\n\nHW 7: Bike rentals in DC\nExploratory data analysis and fitting and interpreting models\n\nInstructions\n\n\nSource\n\n\nStarter\n\n\n\nHW 8: Exploring the GSS\nFitting and interpreting models\n\nInstructions\n\n\nSource\n\n\nStarter\n\n\n\nHW 9: Modelling the GSS\nModel validation and inference\n\nInstructions\n\n\nSource\n\n\nStarter",
    "crumbs": [
      "Content",
      "Making rigorous conclusions"
    ]
  },
  {
    "objectID": "01-topics.html",
    "href": "01-topics.html",
    "title": "Topics",
    "section": "",
    "text": "The course content is organized in three units:\n\n\n\n\n\n\nUnit 1 - Hello world: This unit is an introduction to the content, pedagogy, and toolkit of the course.\nUnit 2 - Exploring data: This unit focuses on data visualization and data wrangling. Specifically we cover fundamentals of data and data visualization, confounding variables, and Simpson’s paradox as well as the concept of tidy data, data import, data cleaning, and data curation. We end the unit with web scraping and introduce the idea of iteration in preparation for the next unit. Also in this unit students are introduced to the toolkit: R, RStudio, R Markdown, Git, and GitHub.\nUnit 3 - Data science ethics: In this unit we discuss misrepresentation of findings, particularly in data visualisations, breaches of data privacy, and algorithmic bias.\nUnit 4 - Making rigorous conclusions: In this unit we introduce modelling and statistical inference for making data-based conclusions. We discuss building, interpreting, and selecting models, visualizing interaction effects, and prediction and model validation. Statistical inference is introduced from a simulation based perspective, and the Central Limit Theorem is discussed very briefly to lay the foundation for future coursework in statistics.\nUnit 5 - Looking forward: In the last unit we present a series of modules such as interactive reporting and visualization with Shiny, text analysis, and Bayesian inference. These are independent modules that educators can choose to include in their introductory data science curriculum depending on how much time they have left in the semester.",
    "crumbs": [
      "Hello #dsbox!",
      "Topics"
    ]
  },
  {
    "objectID": "03-sharing.html",
    "href": "03-sharing.html",
    "title": "Sharing",
    "section": "",
    "text": "A nifty tool for building your course website is blogdown.\nPerhaps the most useful aspect of blogdown in this setting is that your slides, assignments, etc. written in R Markdown can be automatically rendered, so you don’t need to separately knit those documents.\nIf you would like to build your course website with blogdown, you can use this course website as an example, source code here.\nThis webinar by Alison Hill and Desirée De Leon is also very useful for options for sharing your course materials with students.",
    "crumbs": [
      "Infrastructure",
      "Sharing"
    ]
  },
  {
    "objectID": "infrastructure.html",
    "href": "infrastructure.html",
    "title": "Computational infrastructure",
    "section": "",
    "text": "One of the design principles of this course is “cherish day one” – get students from nothing to their first meaningful data visualization within the first 10 minutes of the course. Achieving this is possible, but requires careful consideration of the computing infrastructure. This section outlines how one can set up their course to run on RStudio Cloud, use GitHub for not only version control and collaboration but also as the learning management system for the course, and build their course materials with packages from the *down universe (rmarkdown, blogdown, xaringan, etc.). Lastly, the alternative setups section describes other approaches to setting up the computing infrastructure that can be just as efficient and effective as the ones described in the main choices for the course, and discusses pros and cons.\nWant some resources for learning more about teaching with Data Science in a Box or need a 10 or 15-week term schedule? You’ve come to the right place.",
    "crumbs": [
      "Infrastructure",
      "Computational infrastructure"
    ]
  },
  {
    "objectID": "course-materials/project-instructions/repo-structure/presentation/presentation.html",
    "href": "course-materials/project-instructions/repo-structure/presentation/presentation.html",
    "title": "Presentation title",
    "section": "",
    "text": "style_xaringan(\n  title_slide_background_image = \"img/confetti.jpg\"\n)\nclass: center, middle"
  },
  {
    "objectID": "course-materials/project-instructions/repo-structure/presentation/presentation.html#a-statement-of-the-overall-goal-research-question",
    "href": "course-materials/project-instructions/repo-structure/presentation/presentation.html#a-statement-of-the-overall-goal-research-question",
    "title": "Presentation title",
    "section": "A statement of the overall goal / research question",
    "text": "A statement of the overall goal / research question\n\nclass: inverse, center, middle"
  },
  {
    "objectID": "course-materials/project-instructions/repo-structure/presentation/presentation.html#plot-and-text",
    "href": "course-materials/project-instructions/repo-structure/presentation/presentation.html#plot-and-text",
    "title": "Presentation title",
    "section": "Plot and text",
    "text": "Plot and text\n.pull-left[ - Some text - goes here] .pull-right[\n\n\n\n\n\n\n\n\n\n]"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html",
    "href": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html",
    "title": "HW 08 - Exploring the GSS",
    "section": "",
    "text": "Photo by Mauro Mora on Unsplash\nThe GSS gathers data on contemporary American society in order to monitor and explain trends and constants in attitudes, behaviours, and attributes. Hundreds of trends have been tracked since 1972. In addition, since the GSS adopted questions from earlier surveys, trends can be followed for up to 70 years.\nThe GSS contains a standard core of demographic, behavioural, and attitudinal questions, plus topics of special interest. Among the topics covered are civil liberties, crime and violence, intergroup tolerance, morality, national spending priorities, psychological well-being, social mobility, and stress and traumatic events.\nIn this assignment we analyze data from the 2016 GSS, using it to estimate values of population parameters of interest about US adults.1"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#warm-up",
    "href": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#warm-up",
    "title": "HW 08 - Exploring the GSS",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#packages",
    "href": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#packages",
    "title": "HW 08 - Exploring the GSS",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#data",
    "href": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#data",
    "title": "HW 08 - Exploring the GSS",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it’s called gss16. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?gss16 in the Console or using the Help menu in RStudio to search for gss16. You can also find this information here."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#part-1-harassment-at-work",
    "href": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#part-1-harassment-at-work",
    "title": "HW 08 - Exploring the GSS",
    "section": "Part 1: Harassment at work",
    "text": "Part 1: Harassment at work\nIn 2016, the GSS added a new question on harassment at work. The question is phrased as the following.\n\nOver the past five years, have you been harassed by your superiors or co-workers at your job, for example, have you experienced any bullying, physical or psychological abuse?\n\nAnswers to this question are stored in the harass5 variable in our dataset.\n\nWhat are the possible responses to this question and how many respondents chose each of these answers?\nWhat percent of the respondents for whom this question is applicable\n(i.e. excluding NAs and Does not applys) have been harassed by their superiors or co-workers at their job.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#part-2-time-spent-on-email",
    "href": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#part-2-time-spent-on-email",
    "title": "HW 08 - Exploring the GSS",
    "section": "Part 2: Time spent on email",
    "text": "Part 2: Time spent on email\nThe 2016 GSS also asked respondents how many hours and minutes they spend on email weekly. The responses to these questions are recorded in the emailhr and emailmin variables. For example, if the response is 2.5 hrs, this would be recorded as emailhr = 2 and emailmin = 30.\n\nCreate a new variable called email that combines these two variables to reports the number of minutes the respondents spend on email weekly.\nVisualize the distribution of this new variable. Find the mean and the median number of minutes respondents spend on email weekly. Is the mean or the median a better measure of the typical among of time Americans spend on email weekly? Why?\nCreate another new variable, snap_insta that is coded as “Yes” if the respondent reported using any of Snapchat (snapchat) or Instagram (instagrm), and “No” if not. If the recorded value was NA for both of these questions, the value in your new variable should also be NA.\nCalculate the percentage of Yes’s for snap_insta among those who answered the question, i.e. excluding NAs.\nWhat are the possible responses to the question Last week were you working full time, part time, going to school, keeping house, or what? and how many respondents chose each of these answers? Note that this information is stored in the wrkstat variable.\nFit a model predicting email (number of minutes per week spent on email) from educ (number of years of education), wrkstat, and snap_insta. Interpret the slopes for each of these variables.\nCreate a predicted values vs. residuals plot for this model. Are there any issues with the model? If yes, describe them.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#part-3-political-views-and-science-research",
    "href": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#part-3-political-views-and-science-research",
    "title": "HW 08 - Exploring the GSS",
    "section": "Part 3: Political views and science research",
    "text": "Part 3: Political views and science research\nThe 2016 GSS also asked respondents whether they think of themselves as liberal or conservative (polviews) and whether they think science research is necessary and should be supported by the federal government (advfront).\n\nThe question on science research is worded as follows:\n\n\nEven if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government.\n\nAnd possible responses to this question are Strongly agree, Agree, Disagree, Strongly disagree, Don’t know, No answer, Not applicable.\n\nThe question on political views is worded as follows:\n\n\nWe hear a lot of talk these days about liberals and conservatives. I’m going to show you a seven-point scale on which the political views that people might hold are arranged from extremely liberal–point 1–to extremely conservative–point 7. Where would you place yourself on this scale?\n\n\n**Note:** The levels of this variables are spelled inconsistently: \"Extremely liberal\" vs. \"Extrmly conservative\". Since this is the spelling that shows up in the data, you need to make sure this is how you spell the levels in your code.\n\nAnd possible responses to this question are Extremely liberal, Liberal, Slightly liberal, Moderate, Slghtly conservative, Conservative, Extrmly conservative. Responses that were originally Don’t know, No answer and Not applicable are already mapped to NAs upon data import.\n\nIn a new variable, recode advfront such that Strongly Agree and Agree are mapped to \"Yes\", and Disagree and Strongly disagree are mapped to \"No\". The remaining levels can be left as is. Don’t overwrite the existing advfront, instead pick a different, informative name for your new variable.\nIn a new variable, recode polviews such that Extremely liberal, Liberal, and Slightly liberal, are mapped to \"Liberal\", and Slghtly conservative, Conservative, and Extrmly conservative disagree are mapped to \"Conservative\". The remaining levels can be left as is. Make sure that the levels are in a reasonable order. Don’t overwrite the existing polviews, instead pick a different, informative name for your new variable.\nCreate a visualization that displays the relationship between these two new variables and interpret it.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#footnotes",
    "href": "course-materials/hw-instructions/hw-08/hw-08-exploring-gss.html#footnotes",
    "title": "HW 08 - Exploring the GSS",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSmith, Tom W, Peter Marsden, Michael Hout, and Jibum Kim. General Social Surveys, 1972-2016 [machine-readable data file] /Principal Investigator, Tom W. Smith; Co-Principal Investigator, Peter V. Marsden; Co-Principal Investigator, Michael Hout; Sponsored by National Science Foundation. -NORC ed.- Chicago: NORC at the University of Chicago [producer and distributor]. Data accessed from the GSS Data Explorer website at gssdataexplorer.norc.org.↩︎"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html",
    "href": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html",
    "title": "HW 06 - Money in US politics",
    "section": "",
    "text": "Photo by Sharon McCutcheon on Unsplash\nEvery election cycle brings its own brand of excitement – and lots of money. Political donations are of particular interest to political scientists and other researchers studying politics and voting patterns. They are also of interest to citizens who want to stay informed of how much money their candidates raise and where that money comes from.\nIn the United States, “only American citizens (and immigrants with green cards) can contribute to federal politics, but the American divisions of foreign companies can form political action committees (PACs) and collect contributions from their American employees.”1\nIn this assignment we will scrape and work with data foreign connected PACs that donate to US political campaigns. First, we will get data foreign connected PAC contributions in the 2022 election cycle. Then, you will use a similar approach to get data such contributions from previous years so that we can examine trends over time.\nIn order to complete this assignment you will need a Chrome browser with the Selector Gadget extension installed."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#warm-up",
    "href": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#warm-up",
    "title": "HW 06 - Money in US politics",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#packages",
    "href": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#packages",
    "title": "HW 06 - Money in US politics",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation, the robotstxt package to check if we’re allowed to scrape the data, the rvest package for data scraping, and the scales package for better formatting of labels on visualisations. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(robotstxt)\nlibrary(rvest)\nlibrary(scales)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#data",
    "href": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#data",
    "title": "HW 06 - Money in US politics",
    "section": "Data",
    "text": "Data\nThis assignment does not come with any prepared datasets. Instead you’ll be scraping the data!"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#data-collection-via-web-scraping",
    "href": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#data-collection-via-web-scraping",
    "title": "HW 06 - Money in US politics",
    "section": "Data collection via web scraping",
    "text": "Data collection via web scraping\n\n\n\n\n\n\n\n\n\nThe data come from OpenSecrets.org, a “website tracking the influence of money on U.S. politics, and how that money affects policy and citizens’ lives”. This website is hosted by The Center for Responsive Politics, which is a nonpartisan, independent nonprofit that “tracks money in U.S. politics and its effect on elections and public policy.”2\nBefore getting started, let’s check that a bot has permissions to access pages on this domain.\n\nlibrary(robotstxt)\npaths_allowed(\"https://www.opensecrets.org\")\n\n[1] TRUE\n\n\nOur goal is to scrape data for contributions in all election years Open Secrets has data for. Since that means repeating a task many times, let’s first write a function that works on the first page. Confirm it works on a few others. Then iterate it over pages for all years.\n\nComplete the following set of steps in the scrape-pac.R file in the scripts folder of your repository. This file already contains some starter code to help you out.\n\n\nWrite a function called scrape_pac() that scrapes information from the Open Secrets webpage for foreign-connected PAC contributions in a given year. This function should\n\nhave one input: the URL of the webpage and should return a data frame.\nrename variables scraped, using snake_case naming.\nclean up the Country of Origin/Parent Company variable with str_squish().\nadd a new column to the data frame for year. We will want this information when we ultimately have data from all years, so this is a good time to keep track of it. Our function doesn’t take a year argument, but the year is embedded in the URL, so we can extract it out of there, and add it as a new column. Use the str_sub() function to extract the last 4 characters from the URL. You will probably want to look at the help for this function to figure out how to specify “last 4 characters”.\n\nDefine the URLs for 2022, 2020, and 2000 contributions. Then, test your function using these URLs as inputs. Does the function seem to do what you expected it to do?\nConstruct a vector called urls that contains the URLs for each webpage that contains information on foreign-connected PAC contributions for a given year.\nMap the scrape_pac() function over urls in a way that will result in a data frame called pac_all.\nWrite the data frame to a csv file called pac-all.csv in the data folder.\n\n✅⬆️ If you haven’t yet done so, now is definitely a good time to commit and push your changes to GitHub with an appropriate commit message (e.g. “Data scraping complete”). Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.\n\nComplete the following set of steps in the hw-06.Rmd file in your repository.\n\n\nIn your R Markdown file, load pac-all.csv and report its number of observations and variables using inline code."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#data-cleaning",
    "href": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#data-cleaning",
    "title": "HW 06 - Money in US politics",
    "section": "Data cleaning",
    "text": "Data cleaning\nIn this section we clean the pac_all data frame to prepare it for analysis and visualization. We have two goals in data cleaning:\n\nSeparate the country_parent into two such that country and parent company appear in different columns for country-level analysis.\nConvert contribution amounts in total, dems, and repubs from character strings to numeric values.\n\nThe following exercises walk you through how to make these fixes to the data.\n\nUse the separate() function to separate country_parent into country and parent columns. Note that country and parent company names are separated by \\ (which will need to be specified in your function) and also note that there are some entries where the \\ sign appears twice and in these cases we want to only split the value at the first occurrence of \\. This can be accomplished by setting the extra argument in to \"merge\" so that the cell is split into only 2 segments, e.g. we want \"Denmark/Novo Nordisk A/S\" to be split into \"Denmark\" and \"Novo Nordisk A/S\". (See help for separate() for more on this.) End your code chunk by printing out the top 10 rows of your data frame (if you just type the data frame name it should automatically do this for you).\nRemove the character strings including $ and , signs in the total, dems,and repubs columns and convert these columns to numeric. End your code chunk by printing out the top 10 rows of your data frame (if you just type the data frame name it should automatically do this for you). A couple hints to help you out:\n\nThe $ character is a special character so it will need to be escaped.\nSome contribution amounts are in the millions (e.g. Anheuser-Busch contributed a total of $1,510,897 in 2008). In this case we need to remove all occurrences of ,, which we can do by using str_remove_all() instead of str_remove().\n\n\n🧶 ✅ ⬆️ Now is a good time to knit your document, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#data-visualization-and-interpretation",
    "href": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#data-visualization-and-interpretation",
    "title": "HW 06 - Money in US politics",
    "section": "Data visualization and interpretation",
    "text": "Data visualization and interpretation\n\nCreate a line plot of total contributions from all foreign-connected PACs in the Canada and Mexico over the years. Once you have made the plot, write a brief interpretation of what the graph reveals. Few hints to help you out:\n\nFilter for only Canada and Mexico.\nCalculate sum of total contributions from PACs for each year for each country by using a sequence of group_by() then summarise().\nMake a plot of total contributions (y-axis) by year (x-axis) where two lines identified by different colours represent each of Canada and Mexico.\n\n\n\n**Note:** The figure you create might look slightly different than this one if the data on the website has been updated recently.\n\n\nRecreate the following visualisation. Once you have made the plot, write a brief interpretation of what the graph reveals. Note that these are only UK contributions. You will need to make use of functions from the scales package for axis labels as well as from ggplot2.\n\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#footnotes",
    "href": "course-materials/hw-instructions/hw-06/hw-06-money-in-politics.html#footnotes",
    "title": "HW 06 - Money in US politics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSource: Open Secrets - Foreign Connected PACs.↩︎\nSource: Open Secrets - About.↩︎"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html",
    "href": "course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html",
    "title": "HW 09 - Modeling the GSS",
    "section": "",
    "text": "Photo Mauro Mora on Unsplash\nIn this assignment we continue our exploration of the 2016 GSS dataset from the previous homework."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html#warm-up",
    "href": "course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html#warm-up",
    "title": "HW 09 - Modeling the GSS",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html#packages",
    "href": "course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html#packages",
    "title": "HW 09 - Modeling the GSS",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation, the tidymodels package for modeling and inference, and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html#data",
    "href": "course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html#data",
    "title": "HW 09 - Modeling the GSS",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it’s called gss16. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?gss16 in the Console or using the Help menu in RStudio to search for gss16. You can also find this information here."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html#scientific-research",
    "href": "course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html#scientific-research",
    "title": "HW 09 - Modeling the GSS",
    "section": "Scientific research",
    "text": "Scientific research\nIn this section we’re going to build a model to predict whether someone agrees or doesn’t agree with the following statement:\n\nEven if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government.\n\nThe responses to the question on the GSS about this statement are in the advfront variable.\n\nIt's important that you don't recode the NAs, just the remaining levels.\n\n\nRe-level the advfront variable such that it has two levels: Strongly agree and “Agree\" combined into a new level called agree and the remaining levels (except NAs) combined into”Not agree\". Then, re-order the levels in the following order: \"Agree\" and \"Not agree\". Finally, count() how many times each new level appears in the advfront variable.\n\n\nYou can do this in various ways. One option is to use the `str_detect()` function to detect the existence of words like liberal or conservative. Note that these sometimes show up with lowercase first letters and sometimes with upper case first letters. To detect either in the `str_detect()` function, you can use \"[Ll]iberal\" and \"[Cc]onservative\". But feel free to solve the problem however you like, this is just one option!\n\n\nCombine the levels of the polviews variable such that levels that have the word “liberal” in them are lumped into a level called \"Liberal\" and those that have the word conservative in them are lumped into a level called \"Conservative\". Then, re-order the levels in the following order: \"Conservative\" , \"Moderate\", and \"Liberal\". Finally, count() how many times each new level appears in the polviews variable.\nCreate a new data frame called gss16_advfront that includes the variables advfront, educ, polviews, and wrkstat. Then, use the drop_na() function to remove rows that contain NAs from this new data frame. Sample code is provided below.\n\n\ngss16_advfront &lt;- gss16 %&gt;%\n  select(___, ___, ___, ___) %&gt;%\n  drop_na()\n\n\nSplit the data into training (75%) and testing (25%) data sets. Make sure to set a seed before you do the initial_split(). Call the training data gss16_train and the testing data gss16_test. Sample code is provided below. Use these specific names to make it easier to follow the rest of the instructions.\n\n\nset.seed(___)\ngss16_split &lt;- initial_split(gss16_advfront)\ngss16_train &lt;- training(gss16_split)\ngss16_test  &lt;- testing(gss16_split)\n\n\nCreate a recipe with the following steps for predicting advfront from polviews, wrkstat, and educ. Name this recipe gss16_rec_1. (We’ll create one more recipe later, that’s why we’re naming this recipe _1.) Sample code is provided below.\n\nstep_other() to pool values that occur less than 10% of the time (threshold = 0.10) in the wrkstat variable into \"Other\".\nstep_dummy() to create dummy variables for all_nominal() variables that are predictors, i.e. all_predictors()\n\n\n\ngss16_rec_1 &lt;- recipe(___ ~ ___, data = ___) %&gt;%\n  step_other(wrkstat, threshold = ___, other = \"Other\") %&gt;%\n  step_dummy(all_nominal(), -all_outcomes())\n\n\nSpecify a logistic regression model using \"glm\" as the engine. Name this specification gss16_spec. Sample code is provided below.\n\n\ngss16_spec &lt;- ___() %&gt;%\n  set_engine(\"___\")\n\n\nBuild a workflow that uses the recipe you defined (gss16_rec) and the model you specified (gss16_spec). Name this workflow gss16_wflow_1. Sample code is provided below.\n\n\ngss16_wflow_1 &lt;- workflow() %&gt;%\n  add_model(___) %&gt;%\n  add_recipe(___)\n\n\nPerform 5-fold cross validation. specifically,\n\nsplit the training data into 5 folds (don’t forget to set a seed first!),\napply the workflow you defined earlier to the folds with fit_resamples(), and\ncollect_metrics() and comment on the consistency of metrics across folds (you can get the area under the ROC curve and the accuracy for each fold by setting summarize = FALSE in collect_metrics())\nreport the average area under the ROC curve and the accuracy for all cross validation folds collect_metrics()\n\n\n\nset.seed(___)\ngss16_folds &lt;- vfold_cv(___, v = ___)\n\ngss16_fit_rs_1 &lt;- gss16_wflow_1 %&gt;%\n  fit_resamples(___)\n\ncollect_metrics(___, summarize = FALSE)\ncollect_metrics(___)\n\n\nNow, try a different, simpler model: predict advfront from only polviews and educ. Specifically,\n\nupdate the recipe to reflect this simpler model specification (and name it gss16_rec_2),\nredefine the workflow with the new recipe (and name this new workflow gss16_wflow_2),\nperform cross validation, and\nreport the average area under the ROC curve and the accuracy for all cross validation folds collect_metrics().\n\nComment on which model performs better (one including wrkstat, model 1, or the one excluding wrkstat, model 2) on the training data based on area under the ROC curve.\nFit both models to the testing data, plot the ROC curves for the predictions for both models, and calculate the areas under the ROC curve. Does your answer to the previous exercise hold for the testing data as well? Explain your reasoning. Note: If you haven’t yet done so, you’ll need to first train your workflows on the training data with the following, and then use these fit objects to calculate predictions for the test data.\n\n\ngss16_fit_1 &lt;- gss16_wflow_1 %&gt;%\n  fit(gss16_train)\n\ngss16_fit_2 &lt;- gss16_wflow_2 %&gt;%\n  fit(gss16_train)\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html#harassment-at-work",
    "href": "course-materials/hw-instructions/hw-09/hw-09-modeling-gss.html#harassment-at-work",
    "title": "HW 09 - Modeling the GSS",
    "section": "Harassment at work",
    "text": "Harassment at work\nIn 2016, the GSS added a new question on harassment at work. The question is phrased as the following.\n\nOver the past five years, have you been harassed by your superiors or co-workers at your job, for example, have you experienced any bullying, physical or psychological abuse?\n\nAnswers to this question are stored in the harass5 variable in our dataset.\n\nCreate a subset of the data that only contains Yes and No answers for the harassment question. How many responses chose each of these answers?\nDescribe how bootstrapping can be used to estimate the proportion of Americans who have been harassed by their superiors or co-workers at their job.\nCalculate a 95% bootstrap confidence interval for the proportion of Americans who have been harassed by their superiors or co-workers at their job. Interpret this interval in context of the data.\nWould you expect a 90% confidence interval to be wider or narrower than the interval you calculated above? Explain your reasoning.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-05/hw-05-legos.html",
    "href": "course-materials/hw-instructions/hw-05/hw-05-legos.html",
    "title": "HW 05 - Legos",
    "section": "",
    "text": "Photo by Daniel Cheung on Unsplash\nThis week we’ll do some data gymnastics to refresh and review what we learned over the past few weeks using (simulated) data from Lego sales in 2018 for a sample of customers who bought Legos in the US."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-05/hw-05-legos.html#warm-up",
    "href": "course-materials/hw-instructions/hw-05/hw-05-legos.html#warm-up",
    "title": "HW 05 - Legos",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-05/hw-05-legos.html#packages",
    "href": "course-materials/hw-instructions/hw-05/hw-05-legos.html#packages",
    "title": "HW 05 - Legos",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-05/hw-05-legos.html#data",
    "href": "course-materials/hw-instructions/hw-05/hw-05-legos.html#data",
    "title": "HW 05 - Legos",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it’s called lego_sales. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?lego_sales in the Console or using the Help menu in RStudio to search for lego_sales. You can also find this information here."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-03/hw-03-accidents.html",
    "href": "course-materials/hw-instructions/hw-03/hw-03-accidents.html",
    "title": "HW 03 - Road traffic accidents",
    "section": "",
    "text": "Photo by Clark Van Der Beken on Unsplash\nIn this assignment we’ll look at traffic accidents in Edinburgh. The data are made available online by the UK Government. It covers all recorded accidents in Edinburgh in 2018 and some of the variables were modified for the purposes of this assignment."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-03/hw-03-accidents.html#warm-up",
    "href": "course-materials/hw-instructions/hw-03/hw-03-accidents.html#warm-up",
    "title": "HW 03 - Road traffic accidents",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and knit the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-03/hw-03-accidents.html#packages",
    "href": "course-materials/hw-instructions/hw-03/hw-03-accidents.html#packages",
    "title": "HW 03 - Road traffic accidents",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-03/hw-03-accidents.html#data",
    "href": "course-materials/hw-instructions/hw-03/hw-03-accidents.html#data",
    "title": "HW 03 - Road traffic accidents",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it’s called accidents. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?accidents in the Console or using the Help menu in RStudio to search for accidents. You can also find this information here."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html",
    "href": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "",
    "text": "Many college courses conclude by giving students the opportunity to evaluate the course and the instructor anonymously. However, the use of these student evaluations as an indicator of course quality and teaching effectiveness is often criticized because these measures may reflect the influence of non-teaching related characteristics, such as the physical appearance of the instructor. The article titled, “Beauty in the classroom: instructors’ pulchritude and putative pedagogical productivity” (Hamermesh and Parker, 2005) found that instructors who are viewed to be better looking receive higher instructional ratings. (Daniel S. Hamermesh, Amy Parker, Beauty in the classroom: instructors pulchritude and putative pedagogical productivity, Economics of Education Review, Volume 24, Issue 4, August 2005, Pages 369-376, ISSN 0272-7757, 10.1016/j.econedurev.2004.07.013. http://www.sciencedirect.com/science/article/pii/S0272775704001165.)\nIn this lab you will analyze the data from this study in order to learn what goes into a positive professor evaluation.\nThe data were gathered from end of semester student evaluations for a large sample of professors from the University of Texas at Austin. In addition, six students rated the professors’ physical appearance. (This is a slightly modified version of the original data set that was released as part of the replication data for Data Analysis Using Regression and Multilevel/Hierarchical Models (Gelman and Hill, 2007).) The result is a data frame where each row contains a different course and columns represent variables about the courses and professors."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#warm-up",
    "href": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#warm-up",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "Warm up",
    "text": "Warm up\nLet’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#packages",
    "href": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#packages",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation, the tidymodels package for modeling and inference, and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(tidymodels)\nlibrary(openintro)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#data",
    "href": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#data",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "Data",
    "text": "Data\nThe data can be found in the openintro package, and it’s called evals. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?evals in the Console or using the Help menu in RStudio to search for evals. You can also find this information here."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#exploratory-data-analysis",
    "href": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#exploratory-data-analysis",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\n\nVisualize the distribution of score. Is the distribution skewed? What does that tell you about how students rate courses? Is this what you expected to see? Why, or why not? Include any summary statistics and visualizations you use in your response.\nVisualize and describe the relationship between score and bty_avg.\n\n\n**Hint:** See the help page for the function at http://ggplot2.tidyverse.org/reference/index.html.\n\n\nRecreate the scatterplot from Exercise 2, but this time use\ngeom_jitter()? What does “jitter” mean? What was misleading about the initial scatterplot?\n\n🧶 ✅ ⬆️ If you haven’t done so recently, knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#linear-regression-with-a-numerical-predictor",
    "href": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#linear-regression-with-a-numerical-predictor",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "Linear regression with a numerical predictor",
    "text": "Linear regression with a numerical predictor\n\nLinear model is in the form $\\hat{y} = b_0 + b_1 x$.\n\n\nLet’s see if the apparent trend in the plot is something more than natural variation. Fit a linear model called score_bty_fit to predict average professor evaluation score by average beauty rating (bty_avg). Based on the regression output, write the linear model.\nRecreate the scatterplot from Exercise 2, and add the regression line to this plot in orange colour, with shading for the uncertainty of the line turned off.\nInterpret the slope of the linear model in context of the data.\nInterpret the intercept of the linear model in context of the data. Comment on whether or not the intercept makes sense in this context.\nDetermine the \\(R^2\\) of the model and interpret it in context of the data.\n\n🧶 ✅ ⬆️ If you haven’t done so recently, knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#linear-regression-with-a-categorical-predictor",
    "href": "course-materials/lab-instructions/lab-10/lab-10-slr-course-evals.html#linear-regression-with-a-categorical-predictor",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "Linear regression with a categorical predictor",
    "text": "Linear regression with a categorical predictor\n\nFit a new linear model called score_gender_fit to predict average professor evaluation score based on gender of the professor. Based on the regression output, write the linear model and interpret the slope and intercept in context of the data.\nWhat is the equation of the line corresponding to male professors? What is it for female professors?\nFit a new linear model called score_rank_fit to predict average professor evaluation score based on rank of the professor. Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data.\nCreate a new variable called rank_relevel where \"tenure track\" is the baseline level.\nFit a new linear model called score_rank_relevel_fit to predict average professor evaluation score based on rank_relevel of the professor. This is the new (releveled) variable you created in Exercise 12. Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data. Also determine and interpret the \\(R^2\\) of the model.\nCreate another new variable called tenure_eligible that labels \"teaching\" faculty as \"no\" and labels \"tenure track\" and \"tenured\" faculty as \"yes\".\nFit a new linear model called score_tenure_eligible_fit to predict average professor evaluation score based on tenure_eligibleness of the professor. This is the new (regrouped) variable you created in the previous exercise. Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data. Also determine and interpret the \\(R^2\\) of the model.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html",
    "href": "course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html",
    "title": "Lab 02 - Global plastic waste",
    "section": "",
    "text": "Plastic pollution is a major and growing problem, negatively affecting oceans and wildlife health. Our World in Data has a lot of great data at various levels including globally, per country, and over time. For this lab we focus on data from 2010.\nAdditionally, National Geographic ran a data visualization communication contest on plastic waste as seen here."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html#packages",
    "href": "course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html#packages",
    "title": "Lab 02 - Global plastic waste",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for this analysis. Run the following code in the Console to load this package.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html#data",
    "href": "course-materials/lab-instructions/lab-02/lab-02-plastic-waste.html#data",
    "title": "Lab 02 - Global plastic waste",
    "section": "Data",
    "text": "Data\nThe dataset for this assignment can be found as a csv file in the data folder of your repository. You can read it in using the following.\n\nplastic_waste &lt;- read_csv(\"data/plastic-waste.csv\")\n\nThe variable descriptions are as follows:\n\ncode: 3 Letter country code\nentity: Country name\ncontinent: Continent name\nyear: Year\ngdp_per_cap: GDP per capita constant 2011 international $, rate\nplastic_waste_per_cap: Amount of plastic waste per capita in kg/day\nmismanaged_plastic_waste_per_cap: Amount of mismanaged plastic waste per capita in kg/day\nmismanaged_plastic_waste: Tonnes of mismanaged plastic waste\ncoastal_pop: Number of individuals living on/near coast\ntotal_pop: Total population according to Gapminder"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html",
    "href": "course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html",
    "title": "Lab 04 - La Quinta is Spanish for next to Denny’s, Pt. 1",
    "section": "",
    "text": "Have you ever taken a road trip in the US and thought to yourself “I wonder what La Quinta means”. Well, the late comedian Mitch Hedberg thinks it’s Spanish for next to Denny’s.\nIf you’re not familiar with these two establishments, Denny’s is a casual diner chain that is open 24 hours and La Quinta Inn and Suites is a hotel chain.\nThese two establishments tend to be clustered together, or at least this observation is a joke made famous by Mitch Hedberg. In this lab we explore the validity of this joke and along the way learn some more data wrangling and tips for visualizing spatial data.\nThe inspiration for this lab comes from a blog post by John Reiser on his new jersey geographer blog. You can read that analysis here. Reiser’s blog post focuses on scraping data from Denny’s and La Quinta Inn and Suites websites using Python. In this lab we focus on visualization and analysis of these data. However note that the data scraping was also done in R, and we we will discuss web scraping using R later in the course. But for now we focus on the data that has already been scraped and tidied for you."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html#warm-up",
    "href": "course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html#warm-up",
    "title": "Lab 04 - La Quinta is Spanish for next to Denny’s, Pt. 1",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and knit the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html#packages",
    "href": "course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html#packages",
    "title": "Lab 04 - La Quinta is Spanish for next to Denny’s, Pt. 1",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html#data",
    "href": "course-materials/lab-instructions/lab-04/lab-04-viz-sp-data.html#data",
    "title": "Lab 04 - La Quinta is Spanish for next to Denny’s, Pt. 1",
    "section": "Data",
    "text": "Data\nThe datasets we’ll use are called dennys and laquinta from the dsbox package. Note that these data were scraped from here and here, respectively.\nSince the datasets are distributed with the package, we don’t need to load them separately; they become available to us when we load the package. You can find out more about the datasets by inspecting their documentation, which you can access by running ?dennys and ?laquinta in the Console or using the Help menu in RStudio to search for dennys or laquinta. You can also find this information here and here.\nTo help with our analysis we will also use a dataset on US states, which is located in your repository’s data folder.\n\nstates &lt;- read_csv(\"data/states.csv\")\n\nEach observation in this dataset represents a state, including DC. Along with the name of the state we have the two-letter abbreviation and we have the geographic area of the state (in square miles)."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html",
    "href": "course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html",
    "title": "Lab 14 - Collaborating on GitHub",
    "section": "",
    "text": "This week you’ll continue working on your projects. The first half of the workshop is structured, and you can use the second half to make progress on your projects."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html#opening-an-issue",
    "href": "course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html#opening-an-issue",
    "title": "Lab 14 - Collaborating on GitHub",
    "section": "Opening an issue",
    "text": "Opening an issue\n\nGo to your project repo and open a new issue titled “Practice issue”.\nAdd the following text to the issue:\n\n\nThis is not a real issue. This is just some placeholder text.\n\nAnd the following is a bulleted to-do list:\n- [ ] Do this\n- [ ] Then that\n- [ ] And finally this\n\nHit preview to make sure the issue looks like the following:\n\n\n\n\n\n\n\n\n\n\n\nSubmit the issue.\nThen, assign the issue to one or few members of the team."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html#working-on-the-issue",
    "href": "course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html#working-on-the-issue",
    "title": "Lab 14 - Collaborating on GitHub",
    "section": "Working on the issue",
    "text": "Working on the issue\nAs you work on the issue you can check the boxes.\n\n\n\n\n\n\n\n\n\nNote that this will also show progress on the issue on the issue dashboard.\n\n\n\n\n\n\n\n\n\n\nCheck some of the boxes on your practice issue and confirm that you can see the progress result on the issue dashboard."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html#closing-the-issue",
    "href": "course-materials/lab-instructions/lab-14/lab-14-collaborating-on-github.html#closing-the-issue",
    "title": "Lab 14 - Collaborating on GitHub",
    "section": "Closing the issue",
    "text": "Closing the issue\nOnce you’re done with an issue, you should close it. You can do this in one of two ways: on GitHub by clicking on Close issue or via a commit that directly addresses the issue. We’ll practice the second one. If you preface your commits with “Fixes”, “Fixed”, “Fix”, “Closes”, “Closed”, or “Close”, the issue will be closed when you push the changes to your repo.\n\nTake a note of the issue number, which will show up next to the issue title.\n\n\n\n\n\n\n\n\n\n\n\nGo to your project on RStudio and make a change. This can be something silly like adding a new line to the issue README. Then commit this change. In your commit message, use one of the special words listed above and reference the issue. For example, if the change I made was to add a new line to the README I would say something like the following:\n\n\nAdd a new line to the README, closes #2\n\n\n\n\n\n\n\n\n\n\nPush your changes and observe that the issue is now closed on GitHub. Click on the referenced commit to confirm that it was your last commit that closed the issue."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html",
    "href": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html",
    "title": "Lab 12 - Smoking during pregnacy",
    "section": "",
    "text": "In 2004, the state of North Carolina released a large data set containing information on births recorded in this state. This data set is useful to researchers studying the relation between habits and practices of expectant mothers and the birth of their children. We will work with a random sample of observations from this data set."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#warm-up",
    "href": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#warm-up",
    "title": "Lab 12 - Smoking during pregnacy",
    "section": "Warm up",
    "text": "Warm up\nLet’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#packages",
    "href": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#packages",
    "title": "Lab 12 - Smoking during pregnacy",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation, the tidymodels package for inference, and the data lives in the openintro package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(tidymodels)\nlibrary(openintro)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#data",
    "href": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#data",
    "title": "Lab 12 - Smoking during pregnacy",
    "section": "Data",
    "text": "Data\nThe data can be found in the openintro package, and it’s called ncbirths. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?ncbirths in the Console or using the Help menu in RStudio to search for ncbirths. You can also find this information here."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#baby-weights",
    "href": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#baby-weights",
    "title": "Lab 12 - Smoking during pregnacy",
    "section": "Baby weights",
    "text": "Baby weights\nA 1995 study suggests that average weight of Caucasian babies born in the US is 3,369 grams (7.43 pounds).1 In this dataset we only have information on mother’s race, so we will make the simplifying assumption that babies of Caucasian mothers are also Caucasian, i.e. whitemom = \"white\".\nWe want to evaluate whether the average weight of Caucasian babies has changed since 1995.\nOur null hypothesis should state “there is nothing going on”, i.e. no change since 1995: \\(H_0: \\mu = 7.43~pounds\\).\nOur alternative hypothesis should reflect the research question, i.e. some change since 1995. Since the research question doesn’t state a direction for the change, we use a two sided alternative hypothesis: \\(H_A: \\mu \\ne 7.43~pounds\\).\n\nCreate a filtered data frame called ncbirths_white that contain data only from white mothers. Then, calculate the mean of the weights of their babies.\nAre the conditions necessary for conducting simulation based inference satisfied? Explain your reasoning.\n\nLet’s discuss how this test would work. Our goal is to simulate a null distribution of sample means that is centred at the null value of 7.43 pounds. In order to do so, we\n\ntake a bootstrap sample of from the original sample,\ncalculate this bootstrap sample’s mean,\nrepeat these two steps a large number of times to create a bootstrap distribution of means centred at the observed sample mean,\nshift this distribution to be centred at the null value by subtracting / adding X to all bootstrap mean (X = difference between mean of bootstrap distribution and null value), and\ncalculate the p-value as the proportion of bootstrap samples that yielded a sample mean at least as extreme as the observed sample mean.\n\n\nRun the appropriate hypothesis test, visualize the null distribution, calculate the p-value, and interpret the results in context of the data and the hypothesis test."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#baby-weight-vs.-smoking",
    "href": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#baby-weight-vs.-smoking",
    "title": "Lab 12 - Smoking during pregnacy",
    "section": "Baby weight vs. smoking",
    "text": "Baby weight vs. smoking\nConsider the possible relationship between a mother’s smoking habit and the weight of her baby. Plotting the data is a useful first step because it helps us quickly visualize trends, identify strong associations, and develop research questions.\n\nMake side-by-side boxplots displaying the relationship between habit and weight. What does the plot highlight about the relationship between these two variables?\nBefore moving forward, save a version of the dataset omitting observations where there are NAs for habit. You can call this version ncbirths_habitgiven.\n\nThe box plots show how the medians of the two distributions compare, but we can also compare the means of the distributions using the following to first group the data by the habit variable, and then calculate the mean weight in these groups using.\n\nncbirths_habitgiven %&gt;%\n  group_by(habit) %&gt;%\n  summarise(mean_weight = mean(weight))\n\nThere is an observed difference, but is this difference statistically significant? In order to answer this question we will conduct a hypothesis test .\n\nWrite the hypotheses for testing if the average weights of babies born to smoking and non-smoking mothers are different.\nAre the conditions necessary for conducting simulation based inference satisfied? Explain your reasoning.\nRun the appropriate hypothesis test, calculate the p-value, and interpret the results in context of the data and the hypothesis test.\nConstruct a 95% confidence interval for the difference between the average weights of babies born to smoking and non-smoking mothers."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#baby-weight-vs.-mothers-age",
    "href": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#baby-weight-vs.-mothers-age",
    "title": "Lab 12 - Smoking during pregnacy",
    "section": "Baby weight vs. mother’s age",
    "text": "Baby weight vs. mother’s age\nIn this portion of the analysis we focus on two variables. The first one is maturemom.\n\nFirst, a non-inference task: Determine the age cutoff for younger and mature mothers. Use a method of your choice, and explain how your method works.\n\nThe other variable of interest is lowbirthweight.\n\nConduct a hypothesis test evaluating whether the proportion of low birth weight babies is higher for mature mothers. State the hypotheses, verify the conditions, run the test and calculate the p-value, and state your conclusion in context of the research question. Use \\(\\alpha = 0.05\\). If you find a significant difference, construct a confidence interval, at the equivalent level to the hypothesis test, for the difference between the proportions of low birth weight babies between mature and younger mothers, and interpret this interval in context of the data."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#footnotes",
    "href": "course-materials/lab-instructions/lab-12/lab-12-inference-smoking.html#footnotes",
    "title": "Lab 12 - Smoking during pregnacy",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWen, Shi Wu, Michael S. Kramer, and Robert H. Usher. “Comparison of birth weight distributions between Chinese and Caucasian infants.” American Journal of Epidemiology 141.12 (1995): 1177-1187.↩︎"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html",
    "href": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html",
    "title": "Lab 06 - Take a sad plot and make it better",
    "section": "",
    "text": "Given below are two data visualizations that violate many data visualization best practices. Improve these visualizations using R and the tips for effective visualizations that we introduced in class. You should produce one visualization per dataset. Your visualization should be accompanied by a brief paragraph describing the choices you made in your improvement, specifically discussing what you didn’t like in the original plots and why, and how you addressed them in the visualization you created.\nOn the due date you will give a brief presentation describing one of your improved visualizations and the reasoning for the choices you made."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#warm-up",
    "href": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#warm-up",
    "title": "Lab 06 - Take a sad plot and make it better",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#packages",
    "href": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#packages",
    "title": "Lab 06 - Take a sad plot and make it better",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#data",
    "href": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#data",
    "title": "Lab 06 - Take a sad plot and make it better",
    "section": "Data",
    "text": "Data\nThe datasets we’ll use are called instructors and fisheries from the dsbox package. Since the datasets are distributed with the package, we don’t need to load them separately; they become available to us when we load the package. You can find out more about the datasets by inspecting their documentation, which you can access by running ?instructors and ?fisheries in the Console or using the Help menu in RStudio to search for instructors or fisheries. You can also find this information here and here."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#instructional-staff-employment-trends",
    "href": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#instructional-staff-employment-trends",
    "title": "Lab 06 - Take a sad plot and make it better",
    "section": "Instructional staff employment trends",
    "text": "Instructional staff employment trends\nThe American Association of University Professors (AAUP) is a nonprofit membership association of faculty and other academic professionals. This report compiled by the AAUP shows trends in instructional staff employees between 1975 and 2011, and contains an image very similar to the one given below.\n\n\n\n\n\n\n\n\n\nLet’s start by loading the data used to create this plot.\n\nstaff &lt;- read_csv(\"data/instructional-staff.csv\")\n\nEach row in this dataset represents a faculty type, and the columns are the years for which we have data. The values are percentage of hires of that type of faculty for each year.\n\n\n# A tibble: 5 × 12\n  faculty_type    `1975` `1989` `1993` `1995` `1999` `2001` `2003` `2005` `2007`\n  &lt;chr&gt;            &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Full-Time Tenu…   29     27.6   25     24.8   21.8   20.3   19.3   17.8   17.2\n2 Full-Time Tenu…   16.1   11.4   10.2    9.6    8.9    9.2    8.8    8.2    8  \n3 Full-Time Non-…   10.3   14.1   13.6   13.6   15.2   15.5   15     14.8   14.9\n4 Part-Time Facu…   24     30.4   33.1   33.2   35.5   36     37     39.3   40.5\n5 Graduate Stude…   20.5   16.5   18.1   18.8   18.7   19     20     19.9   19.5\n# ℹ 2 more variables: `2009` &lt;dbl&gt;, `2011` &lt;dbl&gt;\n\n\nIn order to recreate this visualization we need to first reshape the data to have one variable for faculty type and one variable for year. In other words, we will convert the data from wide format to long format.\nBut before we do so, a thought exercise: How many rows will the long-format data have? It will have a row for each combination of year and faculty type. If there are 5 faculty types and 11 years of data, how many rows will we have?\nWe do the wide to long conversion using a new function: pivot_longer(). The animation below show how this function works, as well as its counterpart pivot_wider().\n\n\n\n\n\n\n\n\n\nThe function has the following arguments:\n\npivot_longer(data, cols, names_to = \"name\")\n\n\nThe first argument is data as usual.\nThe second argument, cols, is where you specify which columns to pivot into longer format – in this case all columns except for the faculty_type\nThe third argument, names_to, is a string specifying the name of the column to create from the data stored in the column names of data – in this case year\n\n\nstaff_long &lt;- staff %&gt;%\n  pivot_longer(cols = -faculty_type, names_to = \"year\") %&gt;%\n  mutate(year = as.numeric(year))\n\nLet’s take a look at what the new longer data frame looks like.\n\nstaff_long\n\n# A tibble: 55 × 3\n   faculty_type               year value\n   &lt;chr&gt;                     &lt;dbl&gt; &lt;dbl&gt;\n 1 Full-Time Tenured Faculty  1975  29  \n 2 Full-Time Tenured Faculty  1989  27.6\n 3 Full-Time Tenured Faculty  1993  25  \n 4 Full-Time Tenured Faculty  1995  24.8\n 5 Full-Time Tenured Faculty  1999  21.8\n 6 Full-Time Tenured Faculty  2001  20.3\n 7 Full-Time Tenured Faculty  2003  19.3\n 8 Full-Time Tenured Faculty  2005  17.8\n 9 Full-Time Tenured Faculty  2007  17.2\n10 Full-Time Tenured Faculty  2009  16.8\n# ℹ 45 more rows\n\n\nAnd now let’s plot is as a line plot. A possible approach for creating a line plot where we color the lines by faculty type is the following:\n\nstaff_long %&gt;%\n  ggplot(aes(x = year, y = value, color = faculty_type)) +\n  geom_line()\n\n\n\n\n\n\n\n\nBut note that this results in a message as well as an unexpected plot. The message is saying that there is only one observation for each faculty type year combination. We can fix this using the group aesthetic following.\n\nstaff_long %&gt;%\n  ggplot(aes(x = year, y = value, group = faculty_type, color = faculty_type)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\nInclude the line plot you made above in your report and make sure the figure width is large enough to make it legible. Also fix the title, axis labels, and legend label.\nSuppose the objective of this plot was to show that the proportion of part-time faculty have gone up over time compared to other instructional staff types. What changes would you propose making to this plot to tell this story and why.\nImplement the changes you proposed in the previous exercise.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#fisheries",
    "href": "course-materials/lab-instructions/lab-06/lab-06-sad-plots.html#fisheries",
    "title": "Lab 06 - Take a sad plot and make it better",
    "section": "Fisheries",
    "text": "Fisheries\nFisheries and Aquaculture Department of the Food and Agriculture Organization of the United Nations collects data on fisheries production of countries. This Wikipedia page lists fishery production of countries for 2016. For each country tonnage from capture and aquaculture are listed. Note that countries whose total harvest was less than 100,000 tons are not included in the visualization.\nA researcher shared with you the following visualization they created based on these data. 😳\n\n\n\n\n\n\n\n\n\n\nCan you help them make improve it? First, brainstorm how you would improve it. Then create the improved visualization and write up the changes/decisions you made as bullet points. It’s ok if some of your improvements are aspirational, i.e. you don’t know how to implement it, but you think it’s a good idea.\n\nLoad the data.\n\nfisheries &lt;- read_csv(\"data/fisheries.csv\")\n\n\nCreate a new data visualisation for these data that implements the improvements you proposed in the previous exercise (or many of them as you can).\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.html",
    "href": "course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.html",
    "title": "Lab 07 - Smokers in Whickham",
    "section": "",
    "text": "A study of conducted in Whickham, England recorded participants’ age, smoking status at baseline, and then 20 years later recorded their health outcome. In this lab we analyse the relationships between these variables, first two at a time, and then controlling for the third."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.html#warm-up",
    "href": "course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.html#warm-up",
    "title": "Lab 07 - Smokers in Whickham",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.html#packages",
    "href": "course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.html#packages",
    "title": "Lab 07 - Smokers in Whickham",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the mosaicData package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(mosaicData)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.html#data",
    "href": "course-materials/lab-instructions/lab-07/lab-07-simpsons-paradox.html#data",
    "title": "Lab 07 - Smokers in Whickham",
    "section": "Data",
    "text": "Data\nThe dataset we’ll use is called Whickham from the mosaicData package. You can find out more about the dataset by inspecting their documentation, which you can access by running ?Whickham in the Console or using the Help menu in RStudio to search for Whickham."
  },
  {
    "objectID": "course-materials/exams/exam-01/exam-01.html",
    "href": "course-materials/exams/exam-01/exam-01.html",
    "title": "SAMPLE TAKE HOME EXAM - STUDENT TEMPLATE",
    "section": "",
    "text": "I, ____________, hereby state that I have not communicated with or gained information in any way from my classmates or anyone other than the Professor or TA during this exam, and that all work is my own."
  },
  {
    "objectID": "course-materials/exams/exam-01/exam-01.html#academic-honesty-statement",
    "href": "course-materials/exams/exam-01/exam-01.html#academic-honesty-statement",
    "title": "SAMPLE TAKE HOME EXAM - STUDENT TEMPLATE",
    "section": "",
    "text": "I, ____________, hereby state that I have not communicated with or gained information in any way from my classmates or anyone other than the Professor or TA during this exam, and that all work is my own."
  },
  {
    "objectID": "course-materials/exams/exam-01/exam-01.html#load-packages",
    "href": "course-materials/exams/exam-01/exam-01.html#load-packages",
    "title": "SAMPLE TAKE HOME EXAM - STUDENT TEMPLATE",
    "section": "Load packages",
    "text": "Load packages\n\n# load required packages here"
  },
  {
    "objectID": "course-materials/exams/exam-01/exam-01.html#questions",
    "href": "course-materials/exams/exam-01/exam-01.html#questions",
    "title": "SAMPLE TAKE HOME EXAM - STUDENT TEMPLATE",
    "section": "Questions",
    "text": "Questions\n\nQuestion 1\n[Enter code and narrative here.]\n\n\nQuestion 2\n[Enter code and narrative here.]\n\n\nQuestion 3\n[Enter code and narrative here.]\n\n\nQuestion 4\n[Enter code and narrative here.]\n\n\nQuestion 5\n[Enter code and narrative here.]\n\n\nQuestion 6\n[Enter code and narrative here.]\n\n\nQuestion 7\n[Enter code and narrative here.]\n\n\nQuestion 8\n[Enter code and narrative here.]\n\n\nExtra Credit\n[Enter code and narrative here.]"
  },
  {
    "objectID": "course-materials/starters/project/presentation/presentation.html",
    "href": "course-materials/starters/project/presentation/presentation.html",
    "title": "Presentation title",
    "section": "",
    "text": "style_xaringan(\n  title_slide_background_image = \"img/confetti.jpg\"\n)\nclass: center, middle"
  },
  {
    "objectID": "course-materials/starters/project/presentation/presentation.html#a-statement-of-the-overall-goal-research-question",
    "href": "course-materials/starters/project/presentation/presentation.html#a-statement-of-the-overall-goal-research-question",
    "title": "Presentation title",
    "section": "A statement of the overall goal / research question",
    "text": "A statement of the overall goal / research question\n\nclass: inverse, center, middle"
  },
  {
    "objectID": "course-materials/starters/project/presentation/presentation.html#plot-and-text",
    "href": "course-materials/starters/project/presentation/presentation.html#plot-and-text",
    "title": "Presentation title",
    "section": "Plot and text",
    "text": "Plot and text\n.pull-left[ - Some text - goes here] .pull-right[\n\n\n\n\n\n\n\n\n\n]"
  },
  {
    "objectID": "course-materials/starters/lab/lab-07-simpsons-paradox/lab-07.html",
    "href": "course-materials/starters/lab/lab-07-simpsons-paradox/lab-07.html",
    "title": "Lab 07 - Simpson’s paradox",
    "section": "",
    "text": "Load packages and data\n\nlibrary(tidyverse) \nlibrary(mosaicData) \n\n\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/lab/lab-09-better-viz/lab-09.html",
    "href": "course-materials/starters/lab/lab-09-better-viz/lab-09.html",
    "title": "Lab 09 - Conveying the right message through visualisation",
    "section": "",
    "text": "Load packages and data\n\nlibrary(tidyverse) \n\n\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/lab/lab-02-plastic-waste/lab-02.html",
    "href": "course-materials/starters/lab/lab-02-plastic-waste/lab-02.html",
    "title": "Lab 02 - Plastic waste",
    "section": "",
    "text": "library(tidyverse) \n\n\nplastic_waste &lt;- read_csv(\"data/plastic-waste.csv\")"
  },
  {
    "objectID": "course-materials/starters/lab/lab-02-plastic-waste/lab-02.html#load-packages-and-data",
    "href": "course-materials/starters/lab/lab-02-plastic-waste/lab-02.html#load-packages-and-data",
    "title": "Lab 02 - Plastic waste",
    "section": "",
    "text": "library(tidyverse) \n\n\nplastic_waste &lt;- read_csv(\"data/plastic-waste.csv\")"
  },
  {
    "objectID": "course-materials/starters/lab/lab-02-plastic-waste/lab-02.html#exercises",
    "href": "course-materials/starters/lab/lab-02-plastic-waste/lab-02.html#exercises",
    "title": "Lab 02 - Plastic waste",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here.\n\n# insert code here\n\n\n\nExercise 2\n\n# insert code here\n\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here.\n\n\nExercise 4\nRemove this text, and add your answer for Exercise 4 here.\n\n# insert code here\n\n\n\nExercise 5\nRemove this text, and add your answer for Exercise 5 here.\n\n# insert code here\n\n\n\nExercise 6\nRemove this text, and add your answer for Exercise 6 here.\n\n# insert code here\n\n\n\nExercise 7\nRemove this text, and add your answer for Exercise 7 here.\n\n# insert code here\n\n\n# insert code here\n\n\n\nExercise 8\nRemove this text, and add your answer for Exercise 8 here.\n\n# insert code here"
  },
  {
    "objectID": "course-materials/starters/lab/lab-05-wrangle-sp-data/lab-05.html",
    "href": "course-materials/starters/lab/lab-05-wrangle-sp-data/lab-05.html",
    "title": "Lab 04 - La Quinta is Spanish for next to Denny’s, Pt. 2",
    "section": "",
    "text": "Load packages and data\n\nlibrary(tidyverse) \nlibrary(dsbox) \n\n\nstates &lt;- read_csv(\"data/states.csv\")\n\n\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\n…\n\n\nExercise 4\n…\n\n\nExercise 5\n…\n\n\nExercise 6\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/lab/lab-04-viz-sp-data/lab-04.html",
    "href": "course-materials/starters/lab/lab-04-viz-sp-data/lab-04.html",
    "title": "Lab 04 - La Quinta is Spanish for next to Denny’s, Pt. 1",
    "section": "",
    "text": "Load packages and data\n\nlibrary(tidyverse) \nlibrary(dsbox) \n\n\nstates &lt;- read_csv(\"data/states.csv\")\n\n\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\n…\n\n\nExercise 4\n…\n\n\nExercise 5\n…\n\n\nExercise 6\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/lab/lab-03-nobel-laureates/lab-03.html",
    "href": "course-materials/starters/lab/lab-03-nobel-laureates/lab-03.html",
    "title": "Lab 03 - Nobel laureates",
    "section": "",
    "text": "library(tidyverse) \n\n\nnobel &lt;- read_csv(\"data/nobel.csv\")"
  },
  {
    "objectID": "course-materials/starters/lab/lab-03-nobel-laureates/lab-03.html#exercises",
    "href": "course-materials/starters/lab/lab-03-nobel-laureates/lab-03.html#exercises",
    "title": "Lab 03 - Nobel laureates",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n…\n\n\nExercise 5\n…\n\n\nExercise 6\n…"
  },
  {
    "objectID": "course-materials/starters/hw/hw-09-modeling-gss/hw-09.html",
    "href": "course-materials/starters/hw/hw-09-modeling-gss/hw-09.html",
    "title": "HW 09 - Modeling the GSS",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-09-modeling-gss/hw-09.html#load-packages-and-data",
    "href": "course-materials/starters/hw/hw-09-modeling-gss/hw-09.html#load-packages-and-data",
    "title": "HW 09 - Modeling the GSS",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-09-modeling-gss/hw-09.html#exercises",
    "href": "course-materials/starters/hw/hw-09-modeling-gss/hw-09.html#exercises",
    "title": "HW 09 - Modeling the GSS",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n…\n\n\nExercise 5\n…\n\n\nExercise 6\n…\n\n\nExercise 7\n…\n\n\nExercise 8\n…\n\n\nExercise 9\n…\n\n\nExercise 10\n…\n\n\nExercise 11\n…\n\n\nExercise 12\n…\n\n\nExercise 13\n…\n\n\nExercise 14\n…\n\n\nExercise 15\n…"
  },
  {
    "objectID": "course-materials/starters/hw/hw-07-bike-rentals-dc/hw-07.html",
    "href": "course-materials/starters/hw/hw-07-bike-rentals-dc/hw-07.html",
    "title": "HW 07 - Bike rentals in DC",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-07-bike-rentals-dc/hw-07.html#load-packages-and-data",
    "href": "course-materials/starters/hw/hw-07-bike-rentals-dc/hw-07.html#load-packages-and-data",
    "title": "HW 07 - Bike rentals in DC",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-07-bike-rentals-dc/hw-07.html#exercises",
    "href": "course-materials/starters/hw/hw-07-bike-rentals-dc/hw-07.html#exercises",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n…\n\n\nExercise 5\n…\n\n\nExercise 6\n…\n\n\nExercise 7\n…\n\n\nExercise 8\n…\n\n\nExercise 9\n…\n\n\nExercise 10\n…\n\n\nExercise 11\n…\n\n\nExercise 12\n…\n\n\nExercise 13\n…\n\n\nExercise 14\n…\n\n\nExercise 15\n…"
  },
  {
    "objectID": "course-materials/starters/hw/hw-02-airbnb-edi/hw-02.html",
    "href": "course-materials/starters/hw/hw-02-airbnb-edi/hw-02.html",
    "title": "HW 01 - Airbnb listings in Edinburgh",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-02-airbnb-edi/hw-02.html#load-packages-and-data",
    "href": "course-materials/starters/hw/hw-02-airbnb-edi/hw-02.html#load-packages-and-data",
    "title": "HW 01 - Airbnb listings in Edinburgh",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-02-airbnb-edi/hw-02.html#exercises",
    "href": "course-materials/starters/hw/hw-02-airbnb-edi/hw-02.html#exercises",
    "title": "HW 01 - Airbnb listings in Edinburgh",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here.\n\n# remove this comment and add the code for Exercise 3 here\n\n\n\nExercise 4\nRemove this text, and add your answer for Exercise 4 here.\n\n# remove this comment and add the code for Exercise 4 here\n\n\n# remove this comment and add the code for Exercise 4 here\n\n\n# remove this comment and add the code for Exercise 4 here\n\n\n\nExercise 5\nRemove this text, and add your answer for Exercise 5 here.\n\n# remove this comment and add the code for Exercise 5 here"
  },
  {
    "objectID": "course-materials/starters/hw/hw-01-pet-names/hw-01.html",
    "href": "course-materials/starters/hw/hw-01-pet-names/hw-01.html",
    "title": "HW 01 - Pet names",
    "section": "",
    "text": "library(tidyverse)\nlibrary(openintro)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-01-pet-names/hw-01.html#load-packages-and-data",
    "href": "course-materials/starters/hw/hw-01-pet-names/hw-01.html#load-packages-and-data",
    "title": "HW 01 - Pet names",
    "section": "",
    "text": "library(tidyverse)\nlibrary(openintro)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-01-pet-names/hw-01.html#exercises",
    "href": "course-materials/starters/hw/hw-01-pet-names/hw-01.html#exercises",
    "title": "HW 01 - Pet names",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nThere are ___ pets in the dataset.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here.\n\nseattlepets %&gt;%\n  count(animal_name, sort = TRUE)\n\n# A tibble: 13,930 × 2\n   animal_name     n\n   &lt;chr&gt;       &lt;int&gt;\n 1 &lt;NA&gt;          483\n 2 Lucy          439\n 3 Charlie       387\n 4 Luna          355\n 5 Bella         331\n 6 Max           270\n 7 Daisy         261\n 8 Molly         240\n 9 Jack          232\n10 Lily          232\n# … with 13,920 more rows\n\n\n\n\nExercise 4\nRemove this text, and add your answer for Exercise 4 here.\n\n# remove this comment and add the code for Exercise 4 here\n\n\n\nExercise 5\nRemove this text, and add your answer for Exercise 5 here.\n\n\nExercise 6\nRemove this text, and add your answer for Exercise 6 here."
  },
  {
    "objectID": "course-materials/starters/hw/hw-04-college-majors/hw-04.html",
    "href": "course-materials/starters/hw/hw-04-college-majors/hw-04.html",
    "title": "HW 04 - What should I major in?",
    "section": "",
    "text": "library(tidyverse)\nlibrary(scales)\nlibrary(fivethirtyeight)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-04-college-majors/hw-04.html#load-packages-and-data",
    "href": "course-materials/starters/hw/hw-04-college-majors/hw-04.html#load-packages-and-data",
    "title": "HW 04 - What should I major in?",
    "section": "",
    "text": "library(tidyverse)\nlibrary(scales)\nlibrary(fivethirtyeight)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-04-college-majors/hw-04.html#exercises",
    "href": "course-materials/starters/hw/hw-04-college-majors/hw-04.html#exercises",
    "title": "HW 04 - What should I major in?",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n…\n\n\nExercise 5\n…\n\n\nExercise 6\n…\n\n\nExercise 7\n…\n\n\nExercise 8\n…\n\n\nExercise 9\n…\n\n\nExercise 10\n…"
  },
  {
    "objectID": "course-materials/application-exercises/ae-01b-covid/covid.html",
    "href": "course-materials/application-exercises/ae-01b-covid/covid.html",
    "title": "Cumulative deaths from COVID-19",
    "section": "",
    "text": "Countries around the world are responding to an outbreak of respiratory illness caused by a novel coronavirus, COVID-19. The outbreak first started in Wuhan, China, but cases have been identified in a growing number of other locations internationally, including the United States. In this report we explore how the trajectory of the cumulative deaths in a number of countries.\nThe data come from the coronavirus package, which pulls data from the Johns Hopkins University Center for Systems Science and Engineering (JHU CCSE) Coronavirus repository. The coronavirus package provides a tidy format dataset of the 2019 Novel Coronavirus COVID-19 (2019-nCoV) epidemic. The package is available on GitHub here and is updated daily.\nFor our analysis, in addition to the coronavirus package, we will use the following packages for data wrangling and visualisation.\n\ntidyverse for data wrangling and visualization\nlubridate package for handling dates\nglue package for constructing text strings\nscales package for formatting axis labels\nggrepel package for pretty printing of country labels\n\nWe will make use of the DT package for interactive display of tabular output in the Appendix.\n\nlibrary(coronavirus) # devtools::install_github(\"RamiKrispin/coronavirus\")\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(glue)\nlibrary(scales)\nlibrary(ggrepel)\nlibrary(DT)"
  },
  {
    "objectID": "course-materials/application-exercises/ae-01b-covid/covid.html#introduction",
    "href": "course-materials/application-exercises/ae-01b-covid/covid.html#introduction",
    "title": "Cumulative deaths from COVID-19",
    "section": "",
    "text": "Countries around the world are responding to an outbreak of respiratory illness caused by a novel coronavirus, COVID-19. The outbreak first started in Wuhan, China, but cases have been identified in a growing number of other locations internationally, including the United States. In this report we explore how the trajectory of the cumulative deaths in a number of countries.\nThe data come from the coronavirus package, which pulls data from the Johns Hopkins University Center for Systems Science and Engineering (JHU CCSE) Coronavirus repository. The coronavirus package provides a tidy format dataset of the 2019 Novel Coronavirus COVID-19 (2019-nCoV) epidemic. The package is available on GitHub here and is updated daily.\nFor our analysis, in addition to the coronavirus package, we will use the following packages for data wrangling and visualisation.\n\ntidyverse for data wrangling and visualization\nlubridate package for handling dates\nglue package for constructing text strings\nscales package for formatting axis labels\nggrepel package for pretty printing of country labels\n\nWe will make use of the DT package for interactive display of tabular output in the Appendix.\n\nlibrary(coronavirus) # devtools::install_github(\"RamiKrispin/coronavirus\")\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(glue)\nlibrary(scales)\nlibrary(ggrepel)\nlibrary(DT)"
  },
  {
    "objectID": "course-materials/application-exercises/ae-01b-covid/covid.html#data-prep",
    "href": "course-materials/application-exercises/ae-01b-covid/covid.html#data-prep",
    "title": "Cumulative deaths from COVID-19",
    "section": "Data prep",
    "text": "Data prep\nThe data frame called coronavirus in the coronavirus package provides a daily summary of the Coronavirus (COVID-19) cases by country. Each row in the data frame represents a country (or, where relevant, state/province). A full list of the countries in the data frame is provided in the Appendix. Note that the data provided in this package provides daily number of deaths, confirmed cases, and recovered cases. For this report, we will focus on the deaths.\nWe will start by making our selection for the countries we want to explore.\n\ncountries &lt;- c(\n  \"China\",\n  \"France\",\n  \"United Kingdom\",\n  \"US\",\n  \"Turkey\"\n)\n\nIn the following code chunk we filter the data frame for deaths in the countries we specified above and calculate cumulative number of deaths. We will only visualise data since 10th confirmed death.\n\ncountry_data &lt;- coronavirus %&gt;%\n  # filter for deaths in countries of interest\n  filter(\n    type == \"death\",\n    country %in% countries\n  ) %&gt;%\n  # fix county labels for pretty plotting\n  mutate(\n    country = case_when(\n      country == \"United Kingdom\" ~ \"UK\",\n      TRUE ~ country\n    )\n  ) %&gt;%\n  # calculate number of total cases for each country and date\n  group_by(country, date) %&gt;%\n  summarise(tot_cases = sum(cases)) %&gt;%\n  # arrange by date in ascending order\n  arrange(date) %&gt;%\n  # record daily cumulative cases as cumulative_cases\n  mutate(cumulative_cases = cumsum(tot_cases)) %&gt;%\n  # only use days since the 10th confirmed death\n  filter(cumulative_cases &gt; 9) %&gt;%\n  # record days elapsed, end date, and end label\n  mutate(\n    days_elapsed = as.numeric(date - min(date)),\n    end_date     = if_else(date == max(date), TRUE, FALSE),\n    end_label    = if_else(end_date, country, NA)\n  ) %&gt;%\n  # ungroup\n  ungroup()\n\n`summarise()` has grouped output by 'country'. You can override using the\n`.groups` argument.\n\n\nWe also need to take a note of the “as of date” for the data so that we can properly label our visualisation.\n\nas_of_date &lt;- country_data %&gt;% \n  summarise(max(date)) %&gt;% \n  pull()\n\nas_of_date_formatted &lt;- glue(\"{wday(as_of_date, label = TRUE)}, {month(as_of_date, label = TRUE)} {day(as_of_date)}, {year(as_of_date)}\")\n\nThese data are as of Thu, Mar 9, 2023."
  },
  {
    "objectID": "course-materials/application-exercises/ae-01b-covid/covid.html#visualisation",
    "href": "course-materials/application-exercises/ae-01b-covid/covid.html#visualisation",
    "title": "Cumulative deaths from COVID-19",
    "section": "Visualisation",
    "text": "Visualisation\nThe following visualisation shows the number of cumulative cases vs. days elapsed since the 10th confirmed death in each country. The time span plotted for each country varies since some countries started seeing (and reporting) deaths from COVID-19 much later than others.\n\nggplot(data = country_data,\n       mapping = aes(x = days_elapsed, \n                     y = cumulative_cases, \n                     color = country, \n                     label = end_label)) +\n  # represent cumulative cases with lines\n  geom_line(size = 0.7, alpha = 0.8) +\n  # add points to line endings\n  geom_point(data = country_data %&gt;% filter(end_date)) +\n  # add country labels, nudged above the lines\n  geom_label_repel(nudge_y = 1, direction = \"y\", hjust = 1) + \n  # turn off legend\n  guides(color = \"none\") +\n  # use pretty colors\n  scale_color_viridis_d() +\n  # better formatting for y-axis\n  scale_y_continuous(labels = label_comma()) +\n  # use minimal theme\n  theme_minimal() +\n  # customize labels\n  labs(\n    x = \"Days since 10th confirmed death\",\n    y = \"Cumulative number of deaths\",\n    title = \"Cumulative deaths from COVID-19, selected countries\",\n    subtitle = glue(\"Data as of\", as_of_date_formatted, .sep = \" \"),\n    caption = \"Source: github.com/RamiKrispin/coronavirus\"\n  )"
  },
  {
    "objectID": "course-materials/application-exercises/ae-01b-covid/covid.html#appendix",
    "href": "course-materials/application-exercises/ae-01b-covid/covid.html#appendix",
    "title": "Cumulative deaths from COVID-19",
    "section": "Appendix",
    "text": "Appendix\nA list of countries in the coronavirus data frame is provided below."
  },
  {
    "objectID": "course-materials/application-exercises/ae-03-starwars-dataviz/starwars.html",
    "href": "course-materials/application-exercises/ae-03-starwars-dataviz/starwars.html",
    "title": "Visualizing Starwars characters",
    "section": "",
    "text": "Glimpse at the starwars data frame.\n\n\nglimpse(starwars)\n\nRows: 87\nColumns: 14\n$ name       &lt;chr&gt; \"Luke Skywalker\", \"C-3PO\", \"R2-D2\", \"Darth Vader\", \"Leia Or…\n$ height     &lt;int&gt; 172, 167, 96, 202, 150, 178, 165, 97, 183, 182, 188, 180, 2…\n$ mass       &lt;dbl&gt; 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 84.0, 77.…\n$ hair_color &lt;chr&gt; \"blond\", NA, NA, \"none\", \"brown\", \"brown, grey\", \"brown\", N…\n$ skin_color &lt;chr&gt; \"fair\", \"gold\", \"white, blue\", \"white\", \"light\", \"light\", \"…\n$ eye_color  &lt;chr&gt; \"blue\", \"yellow\", \"red\", \"yellow\", \"brown\", \"blue\", \"blue\",…\n$ birth_year &lt;dbl&gt; 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0, 57.0, …\n$ sex        &lt;chr&gt; \"male\", \"none\", \"none\", \"male\", \"female\", \"male\", \"female\",…\n$ gender     &lt;chr&gt; \"masculine\", \"masculine\", \"masculine\", \"masculine\", \"femini…\n$ homeworld  &lt;chr&gt; \"Tatooine\", \"Tatooine\", \"Naboo\", \"Tatooine\", \"Alderaan\", \"T…\n$ species    &lt;chr&gt; \"Human\", \"Droid\", \"Droid\", \"Human\", \"Human\", \"Human\", \"Huma…\n$ films      &lt;list&gt; &lt;\"The Empire Strikes Back\", \"Revenge of the Sith\", \"Return…\n$ vehicles   &lt;list&gt; &lt;\"Snowspeeder\", \"Imperial Speeder Bike\"&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, \"Imp…\n$ starships  &lt;list&gt; &lt;\"X-wing\", \"Imperial shuttle\"&gt;, &lt;&gt;, &lt;&gt;, \"TIE Advanced x1\",…\n\n\n\nModify the following plot to change the color of all points to \"pink\".\n\n\nggplot(starwars, \n       aes(x = height, y = mass, color = gender, size = birth_year)) +\n  geom_point(color = \"pink\")\n\nWarning: Removed 51 rows containing missing values (geom_point).\n\n\n\n\n\n\n\n\n\n\nAdd labels for title, x and y axes, and size of points. Uncomment to see the effect.\n\n\nggplot(starwars, \n       aes(x = height, y = mass, color = gender, size = birth_year)) +\n  geom_point(color = \"#30509C\") +\n  labs(\n    #title = \"___\",\n    #x = \"___\", \n    #y = \"___\",\n    #___\n    )\n\nWarning: Removed 51 rows containing missing values (geom_point).\n\n\n\n\n\n\n\n\n\n\nPick a single numerical variable and make a histogram of it. Select a reasonable binwidth for it.\n\n(A little bit of starter code is provided below, and the code chunk is set to not be evaluated with eval: false because the current code in there is not valid code and hence the document wouldn’t knit. Once you replace the code with valid code, set the chunk option to eval: true, or remove the eval option altogether since it’s set to true by default.)\n\nggplot(starwars, aes(___)) +\n  geom___\n\n\nPick a numerical variable and a categorical variable and make a visualization (you pick the type!) to visualization the relationship between the two variables. Along with your code and output, provide an interpretation of the visualization.\n\nInterpretation goes here…\n\nPick a single categorical variable from the data set and make a bar plot of its distribution.\n\n\nPick two categorical variables and make a visualization to visualize the relationship between the two variables. Along with your code and output, provide an interpretation of the visualization.\n\nInterpretation goes here…\n\nPick two numerical variables and two categorical variables and make a visualization that incorporates all of them and provide an interpretation with your answer.\n\n(This time no starter code is provided, you’re on your own!)\nInterpretation goes here…"
  },
  {
    "objectID": "course-materials/application-exercises/ae-05-hotels-datatypes/hotels-forcats.html",
    "href": "course-materials/application-exercises/ae-05-hotels-datatypes/hotels-forcats.html",
    "title": "Hotel bookings - factors",
    "section": "",
    "text": "library(tidyverse)\nlibrary(skimr)\n\n\n# From TidyTuesday: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-11/readme.md\nhotels &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\nFirst, knit the document and view the following visualisation. How are the months ordered? What would be a better order? Then, reorder the months on the x-axis (levels of arrival_date_month) in a way that makes more sense. You will want to use a function from the forcats package, see https://forcats.tidyverse.org/reference/index.html for inspiration and help.\nStretch goal: If you finish the above task before time is up, change the y-axis label so the values are shown with dollar signs, e.g. $80 instead of 80. You will want to use a function from the scales package, see https://scales.r-lib.org/reference/index.html for inspiration and help.\n\nhotels %&gt;%\n  group_by(hotel, arrival_date_month) %&gt;%   # group by hotel type and arrival month\n  summarise(mean_adr = mean(adr)) %&gt;%       # calculate mean adr for each group\n  ggplot(aes(\n    x = arrival_date_month,                 # x-axis = arrival_date_month\n    y = mean_adr,                           # y-axis = mean_adr calculated above\n    group = hotel,                          # group lines by hotel type\n    color = hotel)                          # and color by hotel type\n    ) +\n  geom_line() +                             # use lines to represent data\n  theme_minimal() +                         # use a minimal theme\n  labs(\n    x = \"Arrival month\",                 # customize labels\n    y = \"Mean ADR (average daily rate)\",\n    title = \"Comparison of resort and city hotel prices across months\",\n    subtitle = \"Resort hotel prices soar in the summer while ciry hotel prices remain relatively constant throughout the year\",\n    color = \"Hotel type\"\n    )\n\n`summarise()` has grouped output by 'hotel'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "course-materials/application-exercises/ae-09-feat-eng-cv/theoffice-solution.html",
    "href": "course-materials/application-exercises/ae-09-feat-eng-cv/theoffice-solution.html",
    "title": "The Office - Solution",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(schrute)\nlibrary(lubridate)\n\nUse theoffice data from the schrute package to predict IMDB scores for episodes of The Office.\n\nglimpse(theoffice)\n\nRows: 55,130\nColumns: 12\n$ index            &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16…\n$ season           &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ episode          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ episode_name     &lt;chr&gt; \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\",…\n$ director         &lt;chr&gt; \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis…\n$ writer           &lt;chr&gt; \"Ricky Gervais;Stephen Merchant;Greg Daniels\", \"Ricky…\n$ character        &lt;chr&gt; \"Michael\", \"Jim\", \"Michael\", \"Jim\", \"Michael\", \"Micha…\n$ text             &lt;chr&gt; \"All right Jim. Your quarterlies look very good. How …\n$ text_w_direction &lt;chr&gt; \"All right Jim. Your quarterlies look very good. How …\n$ imdb_rating      &lt;dbl&gt; 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6…\n$ total_votes      &lt;int&gt; 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706,…\n$ air_date         &lt;fct&gt; 2005-03-24, 2005-03-24, 2005-03-24, 2005-03-24, 2005-…\n\n\nFix air_date for later use.\n\ntheoffice &lt;- theoffice %&gt;%\n  mutate(air_date = ymd(as.character(air_date)))\n\nWe will\n\nengineer features based on episode scripts\ntrain a model\nperform cross validation\nmake predictions\n\nNote: The episodes listed in theoffice don’t match the ones listed in the data we used in the cross validation lesson.\n\ntheoffice %&gt;%\n  distinct(season, episode)\n\n# A tibble: 186 × 2\n   season episode\n    &lt;int&gt;   &lt;int&gt;\n 1      1       1\n 2      1       2\n 3      1       3\n 4      1       4\n 5      1       5\n 6      1       6\n 7      2       1\n 8      2       2\n 9      2       3\n10      2       4\n# … with 176 more rows\n\n\n\nExercise 1 - Calculate the percentage of lines spoken by Jim, Pam, Michael, and Dwight for each episode of The Office.\n\noffice_lines &lt;- theoffice %&gt;%\n  group_by(season, episode) %&gt;%\n  mutate(\n    n_lines = n(),\n    lines_jim = sum(character == \"Jim\") / n_lines,\n    lines_pam = sum(character == \"Pam\") / n_lines,\n    lines_michael = sum(character == \"Michael\") / n_lines,\n    lines_dwight = sum(character == \"Dwight\") / n_lines,\n  ) %&gt;%\n  ungroup() %&gt;%\n  select(season, episode, episode_name, contains(\"lines_\")) %&gt;%\n  distinct(season, episode, episode_name, .keep_all = TRUE)\n\n\n\nExercise 2 - Identify episodes that touch on Halloween, Valentine’s Day, and Christmas.\n\ntheoffice &lt;- theoffice %&gt;%\n  mutate(text = tolower(text))\n\nhalloween_episodes &lt;- theoffice %&gt;%\n  filter(str_detect(text, \"halloween\")) %&gt;% \n  count(episode_name) %&gt;%\n  filter(n &gt; 1) %&gt;%\n  mutate(halloween = 1) %&gt;%\n  select(-n)\n\nvalentine_episodes &lt;- theoffice %&gt;%\n  filter(str_detect(text, \"valentine\")) %&gt;% \n  count(episode_name) %&gt;%\n  filter(n &gt; 1) %&gt;%\n  mutate(valentine = 1) %&gt;%\n  select(-n)\n\nchristmas_episodes &lt;- theoffice %&gt;%\n  filter(str_detect(text, \"christmas\")) %&gt;% \n  count(episode_name) %&gt;%\n  filter(n &gt; 1) %&gt;%\n  mutate(christmas = 1) %&gt;%\n  select(-n)\n\n\n\nExercise 3 - Put together a modeling dataset that includes features you’ve engineered. Also add an indicator variable called michael which takes the value 1 if Michael Scott (Steve Carrell) was there, and 0 if not. Note: Michael Scott (Steve Carrell) left the show at the end of Season 7.\n\noffice_df &lt;- theoffice %&gt;%\n  select(season, episode, episode_name, imdb_rating, total_votes, air_date) %&gt;%\n  distinct(season, episode, .keep_all = TRUE) %&gt;%\n  left_join(halloween_episodes, by = \"episode_name\") %&gt;% \n  left_join(valentine_episodes, by = \"episode_name\") %&gt;% \n  left_join(christmas_episodes, by = \"episode_name\") %&gt;% \n  replace_na(list(halloween = 0, valentine = 0, christmas = 0)) %&gt;%\n  mutate(michael = if_else(season &gt; 7, 0, 1)) %&gt;%\n  mutate(across(halloween:michael, as.factor)) %&gt;%\n  left_join(office_lines, by = c(\"season\", \"episode\", \"episode_name\"))\n\n\n\nExercise 4 - Split the data into training (75%) and testing (25%).\n\nset.seed(1122)\noffice_split &lt;- initial_split(office_df)\noffice_train &lt;- training(office_split)\noffice_test &lt;- testing(office_split)\n\n\n\nExercise 5 - Specify a linear regression model.\n\noffice_mod &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\")\n\n\n\nExercise 6 - Create a recipe that updates the role of episode_name to not be a predictor, removes air_date as a predictor, and removes all zero variance predictors.\n\noffice_rec &lt;- recipe(imdb_rating ~ ., data = office_train) %&gt;%\n  update_role(episode_name, new_role = \"id\") %&gt;%\n  step_rm(air_date) %&gt;%\n  step_dummy(all_nominal(), -episode_name) %&gt;%\n  step_zv(all_predictors())\n\n\n\nExercise 7 - Build a workflow for fitting the model specified earlier and using the recipe you developed to preprocess the data.\n\noffice_wflow &lt;- workflow() %&gt;%\n  add_model(office_mod) %&gt;%\n  add_recipe(office_rec)\n\n\n\nExercise 8 - Fit the model to training data and interpret a couple of the slope coefficients.\n\noffice_fit &lt;- office_wflow %&gt;%\n  fit(data = office_train)\n\ntidy(office_fit)\n\n# A tibble: 12 × 5\n   term           estimate std.error statistic  p.value\n   &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)    6.34     0.298       21.2    1.24e-43\n 2 season         0.0542   0.0224       2.42   1.68e- 2\n 3 episode        0.0125   0.00439      2.85   5.05e- 3\n 4 total_votes    0.000372 0.0000390    9.55   1.25e-16\n 5 lines_jim      0.653    0.679        0.962  3.38e- 1\n 6 lines_pam      0.0329   0.696        0.0473 9.62e- 1\n 7 lines_michael  0.111    0.544        0.204  8.39e- 1\n 8 lines_dwight   0.806    0.522        1.54   1.25e- 1\n 9 halloween_X1  -0.00340  0.181       -0.0188 9.85e- 1\n10 valentine_X1  -0.0573   0.180       -0.318  7.51e- 1\n11 christmas_X1   0.285    0.129        2.22   2.82e- 2\n12 michael_X1     0.585    0.141        4.15   6.01e- 5\n\n\n\n\nExercise 9 - Perform 5-fold cross validation and view model performance metrics.\n\nset.seed(345)\nfolds &lt;- vfold_cv(office_train, v = 5)\nfolds\n\n#  5-fold cross-validation \n# A tibble: 5 × 2\n  splits           id   \n  &lt;list&gt;           &lt;chr&gt;\n1 &lt;split [111/28]&gt; Fold1\n2 &lt;split [111/28]&gt; Fold2\n3 &lt;split [111/28]&gt; Fold3\n4 &lt;split [111/28]&gt; Fold4\n5 &lt;split [112/27]&gt; Fold5\n\nset.seed(456)\noffice_fit_rs &lt;- office_wflow %&gt;%\n  fit_resamples(folds)\n\ncollect_metrics(office_fit_rs)\n\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   0.367     5  0.0512 Preprocessor1_Model1\n2 rsq     standard   0.543     5  0.0386 Preprocessor1_Model1\n\n\n\n\nExercise 10 - Use your model to make predictions for the testing data and calculate the RMSE. Also use the model developed in the cross validation lesson to make predictions for the testing data and calculate the RMSE as well. Which model did a better job in predicting IMDB scores for the testing data?\n\nNew model\n\noffice_test_pred &lt;- predict(office_fit, new_data = office_test) %&gt;%\n  bind_cols(office_test %&gt;% select(imdb_rating, episode_name))\n\nrmse(office_test_pred, truth = imdb_rating, estimate = .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.401\n\n\n\n\nOld model\n\noffice_mod_old &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\")\n\noffice_rec_old &lt;- recipe(imdb_rating ~ season + episode + total_votes + air_date, data = office_train) %&gt;%\n  # extract month of air_date\n  step_date(air_date, features = \"month\") %&gt;%\n  step_rm(air_date) %&gt;%\n  # make dummy variables of month \n  step_dummy(contains(\"month\")) %&gt;%\n  # remove zero variance predictors\n  step_zv(all_predictors())\n\noffice_wflow_old &lt;- workflow() %&gt;%\n  add_model(office_mod_old) %&gt;%\n  add_recipe(office_rec_old)\n\noffice_fit_old &lt;- office_wflow_old %&gt;%\n  fit(data = office_train)\n\ntidy(office_fit_old)\n\n# A tibble: 12 × 5\n   term                estimate std.error statistic  p.value\n   &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)         7.20     0.188        38.4   9.92e-72\n 2 season             -0.0501   0.0140       -3.57  5.04e- 4\n 3 episode             0.0449   0.00877       5.11  1.13e- 6\n 4 total_votes         0.000360 0.0000404     8.89  4.99e-15\n 5 air_date_month_Feb -0.145    0.139        -1.04  2.99e- 1\n 6 air_date_month_Mar -0.376    0.134        -2.81  5.69e- 3\n 7 air_date_month_Apr -0.309    0.131        -2.36  1.96e- 2\n 8 air_date_month_May -0.128    0.162        -0.791 4.30e- 1\n 9 air_date_month_Sep  0.512    0.178         2.88  4.63e- 3\n10 air_date_month_Oct  0.270    0.139         1.95  5.38e- 2\n11 air_date_month_Nov  0.116    0.126         0.924 3.57e- 1\n12 air_date_month_Dec  0.407    0.165         2.47  1.49e- 2\n\noffice_test_pred_old &lt;- predict(office_fit_old, new_data = office_test) %&gt;%\n  bind_cols(office_test %&gt;% select(imdb_rating, episode_name))\n\nrmse(office_test_pred_old, truth = imdb_rating, estimate = .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.403"
  },
  {
    "objectID": "course-materials/application-exercises/ae-06-nobels-sales-dataimport/nobels-csv.html",
    "href": "course-materials/application-exercises/ae-06-nobels-sales-dataimport/nobels-csv.html",
    "title": "Nobel winners",
    "section": "",
    "text": "library(tidyverse)\n\nLet’s first load the data:\n\nnobel &lt;- ___(___)\n\nThen let’s split the data into two:\n\n# stem laureates\n___ &lt;- nobel %&gt;%\n  filter(___)\n\n# non-steam laureates\n___ &lt;- nobel %&gt;%\n  filter(___)\n\nAnd finally write out the data:\n\n# add code for writing out the two data frames here"
  },
  {
    "objectID": "course-materials/application-exercises/ae-07-brexit-story-dataviz/brexit.html",
    "href": "course-materials/application-exercises/ae-07-brexit-story-dataviz/brexit.html",
    "title": "Brexit",
    "section": "",
    "text": "library(tidyverse)\n\nIn September 2019, YouGov survey asked 1,639 GB adults the following question:\n\nIn hindsight, do you think Britain was right/wrong to vote to leave EU?\n\nRight to leave\n\nWrong to leave\n\nDon’t know\n\n\nThe data from the survey is in data/brexit.csv.\n\nbrexit &lt;- read_csv(\"data/brexit.csv\")\n\nIn the course video we made the following visualisation.\n\nbrexit &lt;- brexit %&gt;%\n  mutate(\n    region = fct_relevel(region, \"london\", \"rest_of_south\", \"midlands_wales\", \"north\", \"scot\"),\n    region = fct_recode(region, London = \"london\", `Rest of South` = \"rest_of_south\", `Midlands / Wales` = \"midlands_wales\", North = \"north\", Scotland = \"scot\")\n  )\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region, nrow = 1, labeller = label_wrap_gen(width = 12)) +\n  guides(fill = \"none\") +\n  labs(\n    title = \"Was Britain right/wrong to vote to leave EU?\",\n    subtitle = \"YouGov Survey Results, 2-3 September 2019\",\n    caption = \"Source: bit.ly/2lCJZVg\",\n    x = NULL, y = NULL\n  ) +\n  scale_fill_manual(values = c(\n    \"Wrong\" = \"#ef8a62\",\n    \"Right\" = \"#67a9cf\",\n    \"Don't know\" = \"gray\"\n  )) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nIn this application exercise we tell different stories with the same data.\n\nExercise 1 - Free scales\nAdd scales = \"free_x\" as an argument to the facet_wrap() function. How does the visualisation change? How is the story this visualisation telling different than the story the original plot tells?\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n  facet_wrap(~region,\n    nrow = 1, labeller = label_wrap_gen(width = 12),\n    # ___\n  ) +\n  guides(fill = \"none\") +\n  labs(\n    title = \"Was Britain right/wrong to vote to leave EU?\",\n    subtitle = \"YouGov Survey Results, 2-3 September 2019\",\n    caption = \"Source: bit.ly/2lCJZVg\",\n    x = NULL, y = NULL\n  ) +\n  scale_fill_manual(values = c(\n    \"Wrong\" = \"#ef8a62\",\n    \"Right\" = \"#67a9cf\",\n    \"Don't know\" = \"gray\"\n  )) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nExercise 2 - Comparing proportions across facets\nFirst, calculate the proportion of wrong, right, and don’t know answers in each category and then plot these proportions (rather than the counts) and then improve axis labeling. How is the story this visualisation telling different than the story the original plot tells? Hint: You’ll need the scales package to improve axis labeling, which means you’ll need to load it on top of the document as well.\n\n# code goes here\n\n\n\nExercise 3 - Comparing proportions across bars\nRecreate the same visualisation from the previous exercise, this time dodging the bars for opinion proportions for each region, rather than faceting by region and then improve the legend. How is the story this visualisation telling different than the story the previous plot tells?\n\n# code goes here"
  },
  {
    "objectID": "01-design-principles.html",
    "href": "01-design-principles.html",
    "title": "Design principles",
    "section": "",
    "text": "This course is designed with five principles in mind:",
    "crumbs": [
      "Hello #dsbox!",
      "Design principles"
    ]
  },
  {
    "objectID": "01-design-principles.html#start-with-cake",
    "href": "01-design-principles.html#start-with-cake",
    "title": "Design principles",
    "section": "Start with cake",
    "text": "Start with cake\nAssuming you like chocolate and strawberries, which of the following images is more likely to make you want to learn to bake a cake? I’m guessing the answer is the image on the left: the cake.\n\n\n\n\n\n\n\n\n\nThe teaching philosophy of this course builds on this same idea. We first show the students the end result, and then step back and teach the necessary components. Specifically, instead of starting with data structures and functions, we start data visualization. And not just a toy example, but a complex, multivariate data visualization. Of course, we don’t want students feeling like…\n\n\n\n\n\n\n\n\n\nThe course starts out slow and emphasizes iteration. Students are initially provided with lots of scaffolding, and then slowly we take away the scaffolding until they are starting with a blank slate for their final projects.",
    "crumbs": [
      "Hello #dsbox!",
      "Design principles"
    ]
  },
  {
    "objectID": "01-design-principles.html#cherish-day-one",
    "href": "01-design-principles.html#cherish-day-one",
    "title": "Design principles",
    "section": "Cherish day one",
    "text": "Cherish day one\nDon’t spend the first day going through the syllabus in detail, aim to get students to make their first meaningful data visualization in 10 minutes! This might sound impossible, and it probably is, if you start by installing R, and then RStudio, and then a bunch of packages, and making sure students have Git working on their computer. You could spend a whole class (or more) on this and not get to a point where every student has their local setup working in an ideal fashion.\nInstead, use cloud-based access to RStudio. This could be via RStudio Cloud or an RStudio Server you set up locally at your institution. Find out more about how you can set up your computing infrastructure for friction-less onboarding here.",
    "crumbs": [
      "Hello #dsbox!",
      "Design principles"
    ]
  },
  {
    "objectID": "01-design-principles.html#skip-baby-steps",
    "href": "01-design-principles.html#skip-baby-steps",
    "title": "Design principles",
    "section": "Skip baby steps",
    "text": "Skip baby steps\nIt’s tempting to start teaching with the simplest examples, e.g. starting data visualization with a bar graph of a single categorical variable instead of a multivariate faceted visualization, especially when teaching programming to build these visualizations since with complex examples comes an extensive amount of code. Unfortunately very basic data visualizations are rarely as motivating as those telling the story of the relationship between a number of variables at once. With the right choice of language and syntax, one can achieve the goal of starting with motivating and complex examples, and building up to such examples along the way. The ggplot2 package, a system for declaratively creating graphics, based on The Grammar of Graphics allows for just this in the context of data visualization. Similarly, the data wrangling packages dplyr and tidyr work really well with the pipe (%&gt;%) operator in R, which allows for building up your data manipulation and analysis in a step-wise fashion, similar in spirit to ggplot2’s layers.",
    "crumbs": [
      "Hello #dsbox!",
      "Design principles"
    ]
  },
  {
    "objectID": "01-design-principles.html#hide-the-veggies",
    "href": "01-design-principles.html#hide-the-veggies",
    "title": "Design principles",
    "section": "Hide the veggies",
    "text": "Hide the veggies\nThis is somewhat tongue-in-cheek. Veggies are absolutely good for you, and it is important that you learn to enjoy them. However many people wouldn’t list raw broccoli as their favourite food, however good it might be for them. Similarly there are many aspects of data science and programming that students must absolutely learn and understand the importance of, even if they are not the most exciting part of their data science journey. For example, one cannot do justice to working with text data without discussing regular expressions. However regular expressions are likely going to be a pain point in the learning journey of newcomers with little to no prior programming experience. So, in this course, instead of teaching students the basics of regular expressions as a unit, we hide this topic within the context of web scraping and manipulating text fields into multiple columns to get what we want out of them.",
    "crumbs": [
      "Hello #dsbox!",
      "Design principles"
    ]
  },
  {
    "objectID": "01-design-principles.html#leverage-the-ecosystem",
    "href": "01-design-principles.html#leverage-the-ecosystem",
    "title": "Design principles",
    "section": "Leverage the ecosystem",
    "text": "Leverage the ecosystem\nThe course materials make heavy use of the tidyverse for data visualization and data wrangling. However, until recently, there was a gap in the R ecosystem for doing basic statistical inference using a syntax that follows tidyverse design principles. This prompted the developments of infer, a package for performing statistical inference using an expressive statistical grammar that coheres with the tidyverse design framework. Using infer to introduce statistical inference makes the transition from the first to the second unit of the course much smoother, and the development of the package as a collaboration between like-minded educators is a great example of leveraging an existing ecosystem to provide a smoother learning experience for students.\nSimilarly, on the instructor facing side, course organization on GitHub is managed by the ghclass package. And the course slides are built with xaringan, and course website is built with blogdown. Leveraging all of these packages allows the instructor to live and breathe in R for all aspects of running their course.",
    "crumbs": [
      "Hello #dsbox!",
      "Design principles"
    ]
  },
  {
    "objectID": "01-design-principles.html#learn-more",
    "href": "01-design-principles.html#learn-more",
    "title": "Design principles",
    "section": "Learn more",
    "text": "Learn more\nThe following talk titled “Let them eat cake (first)!” describes in further detail and with examples from the course materials each of the design principles outlined above.",
    "crumbs": [
      "Hello #dsbox!",
      "Design principles"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "How can we effectively and efficiently teach data science to students with little to no background in computing and statistical thinking? How can we equip them with the skills and tools for reasoning with various types of data and leave them wanting to learn more? This introductory data science course is our (working) answer to this question.\nThe source code for everything you see here can be found on GitHub.\nThe core content of the course focuses on data acquisition and wrangling, exploratory data analysis, data visualization, inference, modelling, and effective communication of results. Time permitting, the course also introduces additional concepts and tools like interactive visualization and reporting, text analysis, and Bayesian inference. A heavy emphasis is placed on a consistent syntax (with tools from the tidyverse), reproducibility (with R Markdown), and version control and collaboration (with Git and GitHub). In addition, out-of-class learning is supplemented with interactive tutorials. The goal of the course is to bring students from zero to being able to work in a team on a fully reproducible data science project analysing a dataset of their choice and answering questions they care about.\nData Science in a Box contains the materials required to teach (or learn from) the course described above, all of which are freely-available and open-source. They include course materials such as slide decks, lecture and live coding videos, homework assignments, guided labs, sample exams, a final project assignment, as well as materials for instructors such as pedagogical tips, information on computing infrastructure, technology stack, and course logistics.\nMajority of the materials linked live in the GitHub repo serving this website. You can access the repo at https://github.com/rstudio-education/datascience-box.\nPlease note that Data Science in a Box uses a Contributor Code of Conduct. By contributing to this project, you agree to abide by its terms."
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Welcome",
    "section": "License",
    "text": "License\nThis online work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International. Visit here for more information about the license."
  },
  {
    "objectID": "index.html#acknowledements",
    "href": "index.html#acknowledements",
    "title": "Welcome",
    "section": "Acknowledements",
    "text": "Acknowledements\nHuge thanks to the #rstats education community who have made numerous suggestions for this resource, to Lee Suddaby and Zeno Kujawa for converting the homework assignments to learnr tutorials, and to Müge Çetinkaya for the hex logo!\nThis website is built with Quarto, the lovely icons by icons8, and none of this would be possible without the tidyverse."
  },
  {
    "objectID": "02-interactive-tutorials.html",
    "href": "02-interactive-tutorials.html",
    "title": "Interactive tutorials",
    "section": "",
    "text": "The following interactive tutorials have been built with learnr and gradethis. They’re available on shinyapps.io (linked) as well as distributed with the dsbox package.1 With the dsbox package installed, you can also run these tutorials in the Tutorials pane of your RStudio window. This might be preferable for courses with high enrollment where students need to access the tutorials at the same time.\nNote that many of these include examples and questions from the homework assignments listed earlier. You can think of these as interactive, auto-feedback versions of the simpler questions in the homework assignments. If using both the tutorials and the homework assignments in your teaching, I recommend modifying the homework assignments to remove the redundant questions (they will usually be the earlier, shorter, simpler questions) and making the homework assignment shorter. Students will ultimately get exposed to the same material, but get auto-feedback in the tutorials and human feedback on the homework assignments.\nIf you would like to learn about making your own tutorials with learnr, I strongly recommend reviewing the video and materials from the following 1.5 hour workshop: Building interactive tutorials in R.",
    "crumbs": [
      "Content",
      "Interactive tutorials"
    ]
  },
  {
    "objectID": "02-interactive-tutorials.html#footnotes",
    "href": "02-interactive-tutorials.html#footnotes",
    "title": "Interactive tutorials",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe dsbox package is not yet on CRAN, until then you will need to install from GitHub with devtools::install_github(\"rstudio-education/dsbox\").↩︎",
    "crumbs": [
      "Content",
      "Interactive tutorials"
    ]
  },
  {
    "objectID": "02-ethics.html",
    "href": "02-ethics.html",
    "title": "Data science ethics",
    "section": "",
    "text": "This unit touches on data science ethics, specifically on issues of misrepresentation of data and results, data privacy, and algorithmic bias. Course lectures are supplemented with “guest lectures” from domain experts.",
    "crumbs": [
      "Content",
      "Data science ethics"
    ]
  },
  {
    "objectID": "02-ethics.html#slides-videos-and-application-exercises",
    "href": "02-ethics.html#slides-videos-and-application-exercises",
    "title": "Data science ethics",
    "section": "Slides, videos, and application exercises",
    "text": "Slides, videos, and application exercises\n\nUnit 3 - Deck 1: Misrepresentation\n\nSlides\n\n\nSource\n\n\nVideo\n\n\n\nAlberto Cairo - How charts lie\n\nVideo\n\n\n\nUnit 3 - Deck 2: Data privacy\n\nSlides\n\n\nSource\n\n\nVideo\n\n\n\nThe Guardian - Cambridge Analytica whistleblower\n\nVideo\n\n\n\nUnit 3 - Deck 3: Algorithmic bias\n\nSlides\n\n\nSource\n\n\nVideo\n\n\n\nJoy Buolamwini - How I’m fighting bias in algorithms\n\nVideo\n\n\n\nCathy O’Neil - Weapons of Math Destruction\n\nVideo\n\n\n\nSafiya Umoja Noble - Imagining a Future Free from the Algorithms of Oppression\n\nVideo\n\n\n\nKristian Lum - What’s An Algorithm Got To Do With It\n\nVideo",
    "crumbs": [
      "Content",
      "Data science ethics"
    ]
  },
  {
    "objectID": "02-ethics.html#labs",
    "href": "02-ethics.html#labs",
    "title": "Data science ethics",
    "section": "Labs",
    "text": "Labs\n\nLab 9: Conveying the right message through visualisation\nImproving data visualisations to better convey the right message\n\nInstructions\n\n\nSource\n\n\nStarter",
    "crumbs": [
      "Content",
      "Data science ethics"
    ]
  },
  {
    "objectID": "04-schedule.html",
    "href": "04-schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "There are a lot of materials in Data Science Course in a Box, which allows instructors to pick and choose what they want depending on the length of the course they’re teaching, their audience, and the curriculum within which the course is placed. The following are two options for course schedules, one for a 11-week course and the other for a 15-week course.",
    "crumbs": [
      "Design",
      "Schedule"
    ]
  },
  {
    "objectID": "04-schedule.html#week-schedule",
    "href": "04-schedule.html#week-schedule",
    "title": "Schedule",
    "section": "11-week schedule",
    "text": "11-week schedule\n\n\n\n\n\n\n\n\n\nUnit\nWeek\nTitle\nType\n\n\n\n\n1\n1\nWelcome to data science!\nLecture\n\n\n1\n1\nMeet the toolkit: Programming\nLecture\n\n\n1\n1\nMeet the toolkit: Version control & collaboration\nLecture\n\n\n1\n1\nHello R\nLab\n\n\n1\n1\nPet names\nHomework\n\n\n2\n2\nData and visualisation\nLecture\n\n\n2\n2\nVisualising data with ggplot2\nLecture\n\n\n2\n2\nVisualising numerical data\nLecture\n\n\n2\n2\nVisualising categorical data\nLecture\n\n\n2\n2\nStarWars + Dataviz\nApplication exercise\n\n\n2\n2\nPlastic waste\nLab\n\n\n2\n2\nAirbnb listings in Edinburgh\nHomework\n\n\n2\n3\nTidy data\nLecture\n\n\n2\n3\nGrammar of data wrangling\nLecture\n\n\n2\n3\nWorking with a single data frame\nLecture\n\n\n2\n3\nWorking with multiple data frames\nLecture\n\n\n2\n3\nTidying data\nLecture\n\n\n2\n3\nHotels + Data wrangling\nApplication exercise\n\n\n2\n3\nNobel laureates\nLab\n\n\n2\n3\nRoad traffic accidents\nHomework\n\n\n2\n4\nData types\nLecture\n\n\n2\n4\nData classes\nLecture\n\n\n2\n4\nImporting data\nLecture\n\n\n2\n4\nRecoding data\nLecture\n\n\n2\n4\nHotels + Data types\nApplication exercise\n\n\n2\n4\nNobels + Sales + Data import\nApplication exercise\n\n\n2\n4\nOption 1: La Quinta is Spanish for next to Denny’s, Pt. 1\nOption 2: La Quinta is Spanish for next to Denny’s, Pt. 2\nLab\n\n\n2\n4\nCollege majors\nHomework\n\n\n2\n5\nTips for effective data visualization\nLecture\n\n\n2\n5\nBrexit + Telling stories with dataviz\nApplication exercise\n\n\n2\n5\nScientific studies and confounding\nLecture\n\n\n2\n5\nSimpson’s paradox\nLecture\n\n\n2\n5\nDoing data science\nLecture\n\n\n2\n5\nOption 1: Take a sad plot and make it better\nOption 2: Simpson’s paradox\nLab\n\n\n2\n5\nLegos\nHomework\n\n\n2\n6\nWeb scraping\nLecture\n\n\n2\n6\nScraping top 250 movies on IMDB\nLecture\n\n\n2\n6\nWeb scraping considerations\nLecture\n\n\n2\n6\nIMDB + Web scraping\nApplication exercise\n\n\n2\n6\nFunctions\nLecture\n\n\n2\n6\nIteration\nLecture\n\n\n2\n6\nUniversity of Edinburgh Art Collection\nLab\n\n\n2\n6\nMoney in politics\nHomework\n\n\n3\n7\nMisrepresentation\nLecture\n\n\n3\n7\nData privacy\nLecture\n\n\n3\n7\nAlgorithmic bias\nLecture\n\n\n3\n7\nConveying the right message through visualisation\nLab\n\n\n3\n7\nProject proposals\nProject\n\n\n4\n8\nFitting and interpreting models\nLecture\n\n\n4\n8\nModelling nonlinear relationships\nLecture\n\n\n4\n8\nModels with multiple predictors\nLecture\n\n\n4\n8\nMore models with multiple predictors\nLecture\n\n\n4\n8\nGrading the professor, Pt 1\nLab\n\n\n4\n8\nOption 1: Bike rentals in DC\nOption 2: Peer review of project proposals\nHomework\n\n\n4\n9\nLogistic regression\nLecture\n\n\n4\n9\nPrediction and overfitting\nLecture\n\n\n4\n9\nFeature engineering\nLecture\n\n\n4\n9\nGrading the professor, Pt 1\nLab\n\n\n4\n9\nExploring the GSS\nHomework\n\n\n4\n10\nCross validation\nLecture\n\n\n4\n10\nThe Office, Part 1\nApplication exercise\n\n\n4\n10\nThe Office, Part 2\nApplication exercise\n\n\n4\n10\nQuantifying uncertainty\nLecture\n\n\n4\n10\nBootstrapping\nLecture\n\n\n4\n10\nOption 1: Smoking during pregnancy\nOption 2: Work on projects\nOption 3: Collaboration on GitHub\nLab\n\n\n4\n10\nModelling the GSS\nHomework\n\n\n5\n11\nText analysis\nLecture\n\n\n5\n11\nComparing texts\nLecture\n\n\n5\n11\nInteractive web apps\nLecture\n\n\n5\n11\nMachine learning\nLecture\n\n\n5\n11\nProject presentations\nLab\n\n\n5\n11\nWrap up\nHomework",
    "crumbs": [
      "Design",
      "Schedule"
    ]
  },
  {
    "objectID": "04-schedule.html#week-schedule-1",
    "href": "04-schedule.html#week-schedule-1",
    "title": "Schedule",
    "section": "15-week schedule",
    "text": "15-week schedule\n\n\n\n\n\n\n\n\n\nUnit\nWeek\nTitle\nType\n\n\n\n\n1\n1\nWelcome to data science!\nLecture\n\n\n1\n1\nMeet the toolkit: Programming\nLecture\n\n\n1\n1\nMeet the toolkit: Version control & collaboration\nLecture\n\n\n1\n1\nHello R\nLab\n\n\n1\n1\nPet names\nHomework\n\n\n2\n2\nData and visualisation\nLecture\n\n\n2\n2\nVisualising data with ggplot2\nLecture\n\n\n2\n2\nVisualising numerical data\nLecture\n\n\n2\n2\nVisualising categorical data\nLecture\n\n\n2\n2\nStarWars + Dataviz\nApplication exercise\n\n\n2\n2\nPlastic waste\nLab\n\n\n2\n2\nAirbnb listings in Edinburgh\nHomework\n\n\n2\n3\nTidy data\nLecture\n\n\n2\n3\nGrammar of data wrangling\nLecture\n\n\n2\n3\nWorking with a single data frame\nLecture\n\n\n2\n3\nWorking with multiple data frames\nLecture\n\n\n2\n3\nTidying data\nLecture\n\n\n2\n3\nHotels + Data wrangling\nApplication exercise\n\n\n2\n3\nNobel laureates\nLab\n\n\n2\n3\nRoad traffic accidents\nHomework\n\n\n2\n4\nData types\nLecture\n\n\n2\n4\nData classes\nLecture\n\n\n2\n4\nRecoding data\nLecture\n\n\n2\n4\nHotels + Data types\nApplication exercise\n\n\n2\n4\nLa Quinta is Spanish for next to Denny’s, Pt. 1\nLab\n\n\n2\n4\nCollege majors\nHomework\n\n\n2\n5\nImporting data\nLecture\n\n\n2\n5\nNobels + Sales + Data import\nApplication exercise\n\n\n2\n5\nTips for effective data visualization\nLecture\n\n\n2\n5\nBrexit + Telling stories with dataviz\nApplication exercise\n\n\n2\n5\nTake a sad plot and make it better\nLab\n\n\n2\n5\nLa Quinta is Spanish for next to Denny’s, Pt. 2\nHomework\n\n\n2\n6\nScientific studies and confounding\nLecture\n\n\n2\n6\nSimpson’s paradox\nLecture\n\n\n2\n6\nDoing data science\nLecture\n\n\n2\n6\nSimpson’s paradox\nLab\n\n\n2\n6\nLegos\nHomework\n\n\n2\n7\nWeb scraping\nLecture\n\n\n2\n7\nScraping top 250 movies on IMDB\nLecture\n\n\n2\n7\nWeb scraping considerations\nLecture\n\n\n2\n7\nIMDB + Web scraping\nApplication exercise\n\n\n2\n7\nWork on projects\nLab\n\n\n2\n7\nWork on projects\nHomework\n\n\n2\n8\nFunctions\nLecture\n\n\n2\n8\nIteration\nLecture\n\n\n2\n8\nUniversity of Edinburgh Art Collection\nLab\n\n\n2\n8\nMoney in politics\nHomework\n\n\n3\n9\nMisrepresentation\nLecture\n\n\n3\n9\nData privacy\nLecture\n\n\n3\n9\nAlgorithmic bias\nLecture\n\n\n3\n9\nConveying the right message through visualisation\nLab\n\n\n3\n9\nProject proposals\nProject\n\n\n3\n9\nPeer review of project proposals\nHomework\n\n\n4\n10\nFitting and interpreting models\nLecture\n\n\n4\n10\nModelling nonlinear relationships\nLecture\n\n\n4\n10\nModels with multiple predictors\nLecture\n\n\n4\n10\nMore models with multiple predictors\nLecture\n\n\n4\n10\nGrading the professor, Pt 1\nLab\n\n\n4\n10\nBike rentals in DC\nHomework\n\n\n4\n11\nLogistic regression\nLecture\n\n\n4\n11\nPrediction and overfitting\nLecture\n\n\n4\n11\nFeature engineering\nLecture\n\n\n4\n11\nGrading the professor, Pt. 1\nLab\n\n\n4\n11\nExploring the GSS\nHomework\n\n\n4\n12\nCross validation\nLecture\n\n\n4\n12\nThe Office, Part 1\nApplication exercise\n\n\n4\n12\nThe Office, Part 2\nApplication exercise\n\n\n4\n12\nBootstrapping\nLecture\n\n\n4\n12\nWork on projects\nLab\n\n\n4\n12\nGrading the professor, Pt. 2\nHomework\n\n\n4\n13\nQuantifying uncertainty\nLecture\n\n\n4\n13\nBootstrapping\nLecture\n\n\n4\n13\nHypothesis testing\nLecture\n\n\n4\n13\nInference overview\nLecture\n\n\n4\n13\nSmoking during pregnancy\nLab\n\n\n4\n13\nModelling the GSS\nHomework\n\n\n5\n14\nText analysis\nLecture\n\n\n5\n14\nComparing texts\nLecture\n\n\n5\n14\nInteractive web apps\nLecture\n\n\n5\n14\nMachine learning\nLecture\n\n\n5\n14\nCollaborating on GitHub\nLab\n\n\n5\n14\nWrap up\nHomework\n\n\n5\n15\nBayesian inference\nLecture\n\n\n5\n15\nBuilding interactive web apps, Pt. 1\nLecture\n\n\n5\n15\nBuilding interactive web apps, Pt. 1\nLecture\n\n\n5\n15\nProject presentations\nLab\n\n\n5\n15\nN/A\nHomework",
    "crumbs": [
      "Design",
      "Schedule"
    ]
  },
  {
    "objectID": "01-overview.html",
    "href": "01-overview.html",
    "title": "Overview",
    "section": "",
    "text": "There are two answers to this question, depending on whether you are a learner or educator. (And really, aren’t we all both?)\nLearner persona\nIf you are a learner who is interested in making sense of (sometimes messy) data and who\n\nhas little to no background in data science, statistics, or programming, or\nhas been using R for a while but wants to modernize their skills,\n\nthe materials in this course are for you! The content is definitely newcomer friendly, however you should be willing to ask questions and dive into the documentation of the packages we introduce.\nNote that course prerequisites are not listed, and this is not an oversight. The course is designed to be accessible to new learners at the undergraduate level and above, though adventurous learners at the high school level might also enjoy these materials.\nEducator persona\nIf you are an educator who is / will be teaching data science at the introductory level and who\n\nhas been teaching with R for a while but wants to update bits of or completely overhaul their teaching materials, or\nis new to teaching (with) R but otherwise comfortable with the basics of the language\n\nthe course materials provided here are for you.\nThe course is designed to be taught at the introductory undergraduate level and above, however it is possible to re-purpose much of this content at the high school level as well.\nNote that a specific discipline is not mentioned, and this is not an oversight. Many disciplines are offering their version of introductory data science nowadays, and we think more the merrier! The course draws on data sets primarily from the social sciences and humanities, and a few from natural sciences.",
    "crumbs": [
      "Hello #dsbox!",
      "Overview"
    ]
  },
  {
    "objectID": "01-overview.html#who-is-this-course-for",
    "href": "01-overview.html#who-is-this-course-for",
    "title": "Overview",
    "section": "",
    "text": "There are two answers to this question, depending on whether you are a learner or educator. (And really, aren’t we all both?)\nLearner persona\nIf you are a learner who is interested in making sense of (sometimes messy) data and who\n\nhas little to no background in data science, statistics, or programming, or\nhas been using R for a while but wants to modernize their skills,\n\nthe materials in this course are for you! The content is definitely newcomer friendly, however you should be willing to ask questions and dive into the documentation of the packages we introduce.\nNote that course prerequisites are not listed, and this is not an oversight. The course is designed to be accessible to new learners at the undergraduate level and above, though adventurous learners at the high school level might also enjoy these materials.\nEducator persona\nIf you are an educator who is / will be teaching data science at the introductory level and who\n\nhas been teaching with R for a while but wants to update bits of or completely overhaul their teaching materials, or\nis new to teaching (with) R but otherwise comfortable with the basics of the language\n\nthe course materials provided here are for you.\nThe course is designed to be taught at the introductory undergraduate level and above, however it is possible to re-purpose much of this content at the high school level as well.\nNote that a specific discipline is not mentioned, and this is not an oversight. Many disciplines are offering their version of introductory data science nowadays, and we think more the merrier! The course draws on data sets primarily from the social sciences and humanities, and a few from natural sciences.",
    "crumbs": [
      "Hello #dsbox!",
      "Overview"
    ]
  },
  {
    "objectID": "01-overview.html#where-does-this-course-fit-in-a-curriculum",
    "href": "01-overview.html#where-does-this-course-fit-in-a-curriculum",
    "title": "Overview",
    "section": "Where does this course fit in a curriculum?",
    "text": "Where does this course fit in a curriculum?\nThis course can serve as a first course in an undergraduate data science or statistics curriculum. It can also serve as an introductory course in a graduate program, and depending on the background of the students, earlier topics can be covered more quickly to make room for more content at the end of the course.",
    "crumbs": [
      "Hello #dsbox!",
      "Overview"
    ]
  },
  {
    "objectID": "01-overview.html#what-is-in-the-box",
    "href": "01-overview.html#what-is-in-the-box",
    "title": "Overview",
    "section": "What is in the box?",
    "text": "What is in the box?\nStudent facing materials:\n\nslides: 30 slide decks, each to be covered roughly in a 75 minute class session\napplication exercises: 10 application exercises\nassignments: 8 homework assignments\nlabs: 12 guided hands on exercises for students requiring minimal introduction from the instructor\nexams: 2 sample take-home exams and keys\nproject: Final project assignment\ntutorials: 8 interactive learnr tutorials\n\nEducator facing materials:\n\nComputing infrastructure:\n\nRStudio: Choosing between RStudio Cloud, RStudio Server Pro, or local RStudio IDE and how to structure your course using each option\nGit/GitHub: How to use Git and GitHub as the learning management system for your course as well as a collaborative platform for your students and how to use GitHub Classroom and ghclass for setting up your course\nCreating learnr modules\nUsing blogdown to create your course website\n\nPedagogical tips",
    "crumbs": [
      "Hello #dsbox!",
      "Overview"
    ]
  },
  {
    "objectID": "01-overview.html#why-r",
    "href": "01-overview.html#why-r",
    "title": "Overview",
    "section": "Why R?",
    "text": "Why R?\nUnlike most other software designed specifically for teaching statistics, R is free and open source, powerful, flexible, and relevant beyond the introductory statistics classroom. Arguments against using and teaching R at especially the introductory statistics level generally cluster around the following two points: teaching programming in addition to statistical concepts is challenging and the command line is more intimidating to beginners than the graphical user interface (GUI) most point-and-click type software offer.\nOne solution for these concerns is to avoid hands-on data analysis completely. If we do not ask our students to start with raw data and instead always provide them with small, tidy rectangles of data then there is never really a need for statistical software beyond spreadsheet or graphing calculator. This is not what we want in a modern statistics course and is a disservice to students.\nAnother solution is to use traditional point-and-click software for data analysis. The typical argument is that the GUI is easier for students to learn and so they can spend more time on statistical concepts. However, this ignores the fact that these software tools also have nontrivial learning curves. In fact, teaching specific data analysis tasks using such software often requires lengthy step-by-step instructions, with annotated screenshots, for navigating menus and other interface elements. Also, it is not uncommon that instructions for one task do not easily extend to another. Replacing such instructions with just a few lines of R code actually makes the instructional materials more concise and less intimidating.\nMany in the statistics education community are in favor of teaching R (or some other programming language, like Python) in upper level statistics courses, however the value of using R in introductory statistics courses is not as widely accepted. We acknowledge that this addition can be burdensome, however we would argue that learning a tool that is applicable beyond the introductory statistics course and that enhances students’ problem solving skills is a burden worth bearing.",
    "crumbs": [
      "Hello #dsbox!",
      "Overview"
    ]
  },
  {
    "objectID": "01-overview.html#why-not-language-x",
    "href": "01-overview.html#why-not-language-x",
    "title": "Overview",
    "section": "Why not language X?",
    "text": "Why not language X?\nThere are a number of other great programming tools out there that can also be used for introducing students to data science, e.g. Python. These materials are designed for teaching data science with R. A great example of a similar curriculum using Python is Data 8 designed at University of California, Berkeley.",
    "crumbs": [
      "Hello #dsbox!",
      "Overview"
    ]
  },
  {
    "objectID": "01-overview.html#why-rstudio",
    "href": "01-overview.html#why-rstudio",
    "title": "Overview",
    "section": "Why RStudio?",
    "text": "Why RStudio?\nThe RStudio IDE includes a viewable environment, a file browser, data viewer, and a plotting pane, which makes it less intimidating than the bare R shell. Additionally, since it is a full fledged IDE, it also features integrated help, syntax highlighting, and context-aware tab completion, which are all powerful tools that help flatten the learning curve. RStudio also has direct integration with other critically important tools for teaching computing best practices and reproducible research.\nOur recommendation is that students access the RStudio IDE through a centralized RStudio server instance or using RStudio Cloud. We describe this in further detail in the Infrastructure section.\nIt should be noted that we do not want to completely dissuade students from downloading and installing R and RStudio locally, we just do not want it to be a prerequisite for getting started. We have found that teaching personal setup is best done progressively throughout a semester, usually via one-on-one interactions during office hours or after class. Our goal is that all students will be able to continue using R in any setting.",
    "crumbs": [
      "Hello #dsbox!",
      "Overview"
    ]
  },
  {
    "objectID": "01-overview.html#learn-more",
    "href": "01-overview.html#learn-more",
    "title": "Overview",
    "section": "Learn more",
    "text": "Learn more\nIf you would like to learn more about the design philosophy behind the course as well as implementation details, we recommend the following paper that is freely available online.\n\nMine Çetinkaya-Rundel & Victoria Ellison (In press), A fresh look at introductory data science, Journal of Statistics Education. doi.org/10.1080/10691898.2020.1804497.",
    "crumbs": [
      "Hello #dsbox!",
      "Overview"
    ]
  },
  {
    "objectID": "02-exams.html",
    "href": "02-exams.html",
    "title": "Exams",
    "section": "",
    "text": "I don’t think the best assessment method for this curriculum is an exam, but sometimes a take home exam can be an incredible motivator for students without stifling their creativity. I’ve provided two sample take home exams. You probably wouldn’t want to use them verbatim as exams, since they’re now publicly available. But they might give you some idea about how to structure take home exams, how to write directions to reduce issues around plagiarism while still encouraging students to search for resources, etc.\n\nExam 1\n[Instructions] [Source]\n\n\nExam 2\n[Instructions] [Source]",
    "crumbs": [
      "Content",
      "Exams"
    ]
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "Attribution-ShareAlike 4.0 International",
    "section": "",
    "text": "Creative Commons Corporation (“Creative Commons”) is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an “as-is” basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible."
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "title": "Attribution-ShareAlike 4.0 International",
    "section": "Creative Commons Attribution-ShareAlike 4.0 International Public License",
    "text": "Creative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\nSection 1 – Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\nSection 2 – Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\n\nreproduce and Share the Licensed Material, in whole or in part; and\nproduce, reproduce, and Share Adapted Material.\n\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\n\n__Additional offer from the Licensor – Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter’s License You apply.\n\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\n\n\nSection 3 – License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\n\nretain the following if it is supplied by the Licensor with the Licensed Material:\n\n\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\n\n\nindicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nindicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\n\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter’s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter’s License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter’s License You apply.\n\n\n\nSection 4 – Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\nSection 5 – Disclaimer of Warranties and Limitation of Liability.\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\nSection 6 – Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\nSection 7 – Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.t stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\nSection 8 – Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org"
  },
  {
    "objectID": "CODE_OF_CONDUCT.html",
    "href": "CODE_OF_CONDUCT.html",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#our-pledge",
    "href": "CODE_OF_CONDUCT.html#our-pledge",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#our-standards",
    "href": "CODE_OF_CONDUCT.html#our-standards",
    "title": "Contributor Covenant Code of Conduct",
    "section": "Our Standards",
    "text": "Our Standards\nExamples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting"
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement-responsibilities",
    "href": "CODE_OF_CONDUCT.html#enforcement-responsibilities",
    "title": "Contributor Covenant Code of Conduct",
    "section": "Enforcement Responsibilities",
    "text": "Enforcement Responsibilities\nCommunity leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#scope",
    "href": "CODE_OF_CONDUCT.html#scope",
    "title": "Contributor Covenant Code of Conduct",
    "section": "Scope",
    "text": "Scope\nThis Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement",
    "href": "CODE_OF_CONDUCT.html#enforcement",
    "title": "Contributor Covenant Code of Conduct",
    "section": "Enforcement",
    "text": "Enforcement\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at [INSERT CONTACT METHOD]. All complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement-guidelines",
    "href": "CODE_OF_CONDUCT.html#enforcement-guidelines",
    "title": "Contributor Covenant Code of Conduct",
    "section": "Enforcement Guidelines",
    "text": "Enforcement Guidelines\nCommunity leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\n1. Correction\nCommunity Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.\n\n\n2. Warning\nCommunity Impact: A violation through a single incident or series of actions.\nConsequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n3. Temporary Ban\nCommunity Impact: A serious violation of community standards, including sustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n4. Permanent Ban\nCommunity Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within the community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#attribution",
    "href": "CODE_OF_CONDUCT.html#attribution",
    "title": "Contributor Covenant Code of Conduct",
    "section": "Attribution",
    "text": "Attribution\nThis Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/ code_of_conduct.html.\nCommunity Impact Guidelines were inspired by Mozilla’s code of conduct enforcement ladder.\nFor answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https:// www.contributor-covenant.org/translations."
  },
  {
    "objectID": "02-hello-world.html",
    "href": "02-hello-world.html",
    "title": "Hello world",
    "section": "",
    "text": "I recommend starting the class off right, devoting more of the class time to introducing the course content instead of the course policies. And get students doing something with data as quickly as possible! A personal goal of mine is to get students to produce their first data visualization within the first 10 minutes of class. The application exercise in this lecture is one way of achieving this goal. Slides for Day One of class are provided below.\nNote that getting students computing on Day One in class requires that they come to class equipped with a laptop or that you’re holding your course online or in a computer lab. If teaching online, this is resolved automatically, of course. They do not need to do any preparation ahead of time, just need internet access. As outlined in the slides, give them a link to your RStudio Cloud workspace and get them started working on the application exercise you put together for them. There are two options for a day one application exercise. Note that one of them uses COVID-19 data and depending on where, when, and to whom you’re teaching, working with these data might not be the most pleasant experience for all students. Please make sure to consider this before using this activity.",
    "crumbs": [
      "Content",
      "Hello world"
    ]
  },
  {
    "objectID": "02-hello-world.html#slides-videos-and-application-exercises",
    "href": "02-hello-world.html#slides-videos-and-application-exercises",
    "title": "Hello world",
    "section": "Slides, videos, and application exercises",
    "text": "Slides, videos, and application exercises\n\nUnit 1 - Deck 1: Welcome\n\nSlides\n\n\nSource\n\n\nVideo\n\n\n\nFirst dataviz\n\nOption 1 - UN Votes\n\nSource\n\n\nVideo\n\n\n\nOption 2 - COVID-19\n\nSource\n\n\n\n\nUnit 1 - Deck 2: Meet the toolkit - Programming\n\nSlides\n\n\nSource\n\n\nVideo\n\n\n\nR4DS :: Chp 2 - Introduction\nIMS :: Sec 1.1 & 1.2 - Case study & Data basics\n\n\n\n\nBechdel + R Markdown\n\nSource\n\n\n\nUnit 1 - Deck 3: Meet the toolkit - Version control and collaboration\n\nSlides\n\n\nSource\n\n\nVideo",
    "crumbs": [
      "Content",
      "Hello world"
    ]
  },
  {
    "objectID": "04-pedagogy.html",
    "href": "04-pedagogy.html",
    "title": "Pedagogy",
    "section": "",
    "text": "The following resources describe the pedagogy used in designing and teaching a course with the materials provided in this resources.\n\nMine Çetinkaya-Rundel & Victoria Ellison. A fresh look at introductory data science, Journal of Statistics Education. doi.org/10.1080/10691898.2020.1804497.\n\n\nTalk: The art and science of teaching data science [Slides]\n\n\nTalk: Data Science in a Box [Slides] [Video]\n\n\nTalk: Let them eat cake (first)! [Slides] [Video]",
    "crumbs": [
      "Design",
      "Pedagogy"
    ]
  },
  {
    "objectID": "04-pedagogy.html#course-design",
    "href": "04-pedagogy.html#course-design",
    "title": "Pedagogy",
    "section": "",
    "text": "The following resources describe the pedagogy used in designing and teaching a course with the materials provided in this resources.\n\nMine Çetinkaya-Rundel & Victoria Ellison. A fresh look at introductory data science, Journal of Statistics Education. doi.org/10.1080/10691898.2020.1804497.\n\n\nTalk: The art and science of teaching data science [Slides]\n\n\nTalk: Data Science in a Box [Slides] [Video]\n\n\nTalk: Let them eat cake (first)! [Slides] [Video]",
    "crumbs": [
      "Design",
      "Pedagogy"
    ]
  },
  {
    "objectID": "04-pedagogy.html#teaching-the-tidyverse",
    "href": "04-pedagogy.html#teaching-the-tidyverse",
    "title": "Pedagogy",
    "section": "Teaching the tidyverse",
    "text": "Teaching the tidyverse\nThe following four part blog post series offers recommendations and tips for teaching the tidyverse in 2020.\n\nPart 1: Getting started\n\n\nPart 2: Data visualisation\n\n\nPart 3: Data wrangling and tidying\n\n\nPart 4: When to purrr?",
    "crumbs": [
      "Design",
      "Pedagogy"
    ]
  },
  {
    "objectID": "03-alternative-setups.html",
    "href": "03-alternative-setups.html",
    "title": "Alternative setups",
    "section": "",
    "text": "In this section we describe alternative setups for your course.\nIn a course at this level students should access the RStudio IDE through a centralized RStudio server instance, which allows us to provide students with uniform computing environments.\nIt should be noted that the goal isn’t to completely dissuade students from downloading and installing R and RStudio locally, we just don’t want it to be a prerequisite for getting started. Teaching personal setup is best done progressively throughout a semester, usually via one-on-one interactions during office hours or after class. The goal is that all students will be able to continue using R even if they no longer have access to departmental resources.\nIf you prefer to not use RStudio Cloud, you might consider one of the following approaches.",
    "crumbs": [
      "Infrastructure",
      "Alternative setups"
    ]
  },
  {
    "objectID": "03-alternative-setups.html#centralized-rstudio-server",
    "href": "03-alternative-setups.html#centralized-rstudio-server",
    "title": "Alternative setups",
    "section": "Centralized RStudio server",
    "text": "Centralized RStudio server\nOne approach that might work particularly well for higher level courses that require a shared infrastructure and higher end computational resources is running academically licensed RStudio Server Pro on a powerful server (e.g. 32 cores, 512 GB RAM). If this server is in the department, instructors can be given direct control over all aspects of the computing environment.\nThe figure below is a sketch of the architecture of the centralized RStudio server approach, which shows that students connect to a single RStudio server instance via a departmental login. This works well for upper division and graduate level courses as most students are directly affiliated with the department. Students taking courses who are not affiliated with the department are issued temporary visitor accounts which expire at the end of the semester.\n\n\n\n\n\nCentralized RStudio server\n\n\n\n\nMore modest configurations can be more than adequate (e.g., a mid-to-high end desktop) for the vast majority of use cases, however care should be given when working with larger datasets in a shared environment. An alternative approach is to use a virtualized hardware in the cloud (e.g. EC2, Azure, etc.).\nThe primary benefit of running and managing the server in-house comes down to control - as needed the instructor(s) are able to install and update software, change configurations, restart or kill sessions, and monitor all aspects of the system. This does increase the demands on the instructor and any involved IT staff, but we have found the benefits to far outweigh the costs. One other unforeseen benefit to a centralized approach is that it makes it possible to present large scale analytic tasks that would not be possible on a traditional desktop or laptop. For example, advanced courses can include homework assignments where students need to process a dataset that is on the order of several hundred gigabytes in size, which would not be possible if they were required to use their own system.",
    "crumbs": [
      "Infrastructure",
      "Alternative setups"
    ]
  },
  {
    "objectID": "03-alternative-setups.html#dockerized-rstudio-server",
    "href": "03-alternative-setups.html#dockerized-rstudio-server",
    "title": "Alternative setups",
    "section": "Dockerized RStudio server",
    "text": "Dockerized RStudio server\nA second approach to running RStudio server involves the construction and hosting of a farm of individualized Docker container instances. A sketch of the architecture of the Docker containers is in the figure below, which shows that students authenticate via university login which redirects them to a personal RStudio instance running in a Docker container on either a local or cloud based server.\n\n\n\n\n\nDockerized RStudio server\n\n\n\n\nDocker is a popular and rapidly evolving containerization tool suite that allows users to automate the deployment of software in a repeatable and self-contained way. Each container wraps a portion of the file system in such a way that all of the code, runtimes, tools, and libraries needed for a piece of software are available, meaning that software will always run in exactly the same way regardless of the environment in which it is being run. As such, Docker is a powerful tool for reproducible computational research, since every Dockerfile transparently and clearly defines exactly what software and which version is being used for any particular computation task.\nAn additional advantage of Docker containers is that they are similar to virtual machines in that they are sandboxed from one another. By mapping each student to a single container we are able to keep all student processes segregated and enforce strict CPU, memory, and disk usage quotas to avoid accidental disruption of the work of one another.\nHowever Docker containers are generally lighter weight than virtual machines, in terms of system resources used. This makes it feasible to run a large number of containers on a single system at the same time. Since most RStudio usage (particularly by our introductory students) is intermittent, we have found that it is possible to run more than 100 RStudio containers concurrently on a single server. Servers can be run locally or on a cloud-based service. The cost for the latter can be defrayed by the credits many services offer for academic use.\nFurther details of a containerized RStudio server approach implemented at Duke can be found at here. This repository contains a README which explains how the large-scale container farm is set up and also contains the Dockerfiles that are used to create the individual containers.\nImplementing the infrastructure solutions discussed above can be overwhelming and time consuming. We encourage faculty interested in adopting these tools to partner with their departmental and/or university IT professionals. Additionally, building these partnerships can lead to collaborations that benefit the entire university.",
    "crumbs": [
      "Infrastructure",
      "Alternative setups"
    ]
  },
  {
    "objectID": "03-alternative-setups.html#learn-more",
    "href": "03-alternative-setups.html#learn-more",
    "title": "Alternative setups",
    "section": "Learn more",
    "text": "Learn more\nIf you would like to learn more about computing infrastructure for statistics and data science courses, we recommend the following paper.\n\nÇetinkaya-Rundel, M., & Rundel, C. (2018). Infrastructure and tools for teaching computing throughout the statistical curriculum. The American Statistician, 72(1), 58-65. doi.org/10.1080/00031305.2017.1397549\n\nA freely available version of the paper can be found here.",
    "crumbs": [
      "Infrastructure",
      "Alternative setups"
    ]
  },
  {
    "objectID": "02-project.html",
    "href": "02-project.html",
    "title": "Project",
    "section": "",
    "text": "The following is a sample project assignment for this curriculum. You can find the source code for this assignment write up here. I’ve also provided sample evaluation forms to be used by the teaching team and students as well as a sample repo structure for the project.",
    "crumbs": [
      "Content",
      "Project"
    ]
  },
  {
    "objectID": "02-project.html#tldr",
    "href": "02-project.html#tldr",
    "title": "Project",
    "section": "TL;DR",
    "text": "TL;DR\nPick a dataset, any dataset…\n…and do something with it. That is your final project in a nutshell. More details below.",
    "crumbs": [
      "Content",
      "Project"
    ]
  },
  {
    "objectID": "02-project.html#may-be-too-long-but-please-do-read",
    "href": "02-project.html#may-be-too-long-but-please-do-read",
    "title": "Project",
    "section": "May be too long, but please do read",
    "text": "May be too long, but please do read\nThe final project for this class will consist of analysis on a dataset of your own choosing. The dataset may already exist, or you may collect your own data using a survey or by conducting an experiment. You can choose the data based on your interests or based on work in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like) and apply them to a novel dataset in a meaningful way.\nThe goal is not to do an exhaustive data analysis i.e., do not calculate every statistic and procedure you have learned for every variable, but rather let me know that you are proficient at asking meaningful questions and answering them with results of data analysis, that you are proficient in using R, and that you are proficient at interpreting and presenting the results. Focus on methods that help you begin to answer your research questions. You do not have to apply every statistical procedure we learned (and you can use techniques we haven’t officially covered in class, if you’re feeling adventurous). Also, critique your own methods and provide suggestions for improving your analysis. Issues pertaining to the reliability and validity of your data, and appropriateness of the statistical analysis should be discussed here.\nThe project is very open ended. You should create some kind of compelling visualization(s) of this data in R. There is no limit on what tools or packages you may use, but sticking to packages we learned in class (tidyverse) is required. You do not need to visualize all of the data at once. A single high quality visualization will receive a much higher grade than a large number of poor quality visualizations. Also pay attention to your presentation. Neatness, coherency, and clarity will count. All analyses must be done in RStudio, using R.",
    "crumbs": [
      "Content",
      "Project"
    ]
  },
  {
    "objectID": "02-project.html#data",
    "href": "02-project.html#data",
    "title": "Project",
    "section": "Data",
    "text": "Data\nIn order for you to have the greatest chance of success with this project it is important that you choose a manageable dataset. This means that the data should be readily accessible and large enough that multiple relationships can be explored. As such, your dataset must have at least 50 observations and between 10 to 20 variables (exceptions can be made but you must speak with me first). The dataset’s variables should include categorical variables, discrete numerical variables, and continuous numerical variables.\nIf you are using a dataset that comes in a format that we haven’t encountered in class, make sure that you are able to load it into R as this can be tricky depending on the source. If you are having trouble ask for help before it is too late.\nNote on reusing datasets from class: Do not reuse datasets used in examples, homework assignments, or labs in the class.\nBelow are a list of data repositories that might be of interest to browse. You’re not limited to these resources, and in fact you’re encouraged to venture beyond them. But you might find something interesting there:\n\nTidyTuesday\nNHS Scotland Open Data\nEdinburgh Open Data\nOpen access to Scotland’s official statistics\nBikeshare data portal\nUK Gov Data\nKaggle datasets\nOpenIntro datasets\nAwesome public datasets\nYouth Risk Behavior Surveillance System (YRBSS)\nPRISM Data Archive Project\nHarvard Dataverse\nIf you know of others, let me know, and we’ll add here…\n\n\nDeliverables\n\nProposal - due [ENTER DUE DATE]\nPresentation - due [ENTER DUE DATE]\nExecutive summary - due [ENTER DUE DATE]\n\n\nProposal\nThis is a draft of the introduction section of your project as well as a data analysis plan and your dataset.\n\nSection 1 - Introduction: The introduction should introduce your general\nresearch question and your data (where it came from, how it was collected,\nwhat are the cases, what are the variables, etc.).\nSection 2 - Data: Place your data in the `/data` folder, and add dimensions and codebook to the README in that folder. Then print out the output of and codebook to the README in that folder. Then print out the output of glimpse() or skim() of your data frame.\nSection 3 - Data analysis plan:\n\nThe outcome (response, Y) and predictor (explanatory, X) variables you will use to answer your question.\nThe comparison groups you will use, if applicable.\nVery preliminary exploratory data analysis, including some summary statistics and visualizations, along with some explanation on how they help you learn more about your data. (You can add to these later as you work on your project.)\nThe method(s) that you believe will be useful in answering your question(s). (You can update these later as you work on your project.)\nWhat results from these specific statistical methods are needed to support your hypothesized answer?\n\n\nEach section should be no more than 1 page (excluding figures). You can check a print preview to confirm length.\nThe grading scheme for the project proposal is as follows. Note that after you receive feedback for your proposal you can improve it based on the feedback and re-submit it. If you re-submit, your final score for the proposal will be the average of two scores you receive (first and second submission).\n\n\n\nTotal\n10 pts\n\n\n\n\nData\n3 pts\n\n\nProposal\n5 pts\n\n\nWorkflow, organization, code quality\n1 pt\n\n\nTeamwork\n1 pt\n\n\n\n\n\nPresentation\n5 minutes maximum, and each team member should say something substantial. You can either present live during your workshop or pre-record and submit your video to be played during the workshop.\nPrepare a slide deck using the template in your repo. This template uses a package called xaringan, and allows you to make presentation slides using R Markdown syntax. There isn’t a limit to how many slides you can use, just a time limit (5 minutes total). Each team member should get a chance to speak during the presentation. Your presentation should not just be an account of everything you tried (“then we did this, then we did this, etc.”), instead it should convey what choices you made, and why, and what you found.\nBefore you finalize your presentation, make sure your chunks are turned off with echo = FALSE.\nPresentations will take place during the last workshop of the semester. You can choose to do your presentation live or pre-record it. During your workshop you will watch presentations from other teams in your workshop and provide feedback in the form of peer evaluations. The presentation line-up will be generated randomly.\nThe grading scheme for the presentation is as follows:\n\n\n\n\n\n\n\nTotal\n50 pts\n\n\n\n\nTime management: Did the team divide the time well amongst themselves or got cut off going over time?\n4 pts\n\n\nContent: Is the research question well designed and is the data being used relevant to the research question?\n5 pts\n\n\nProfessionalism: How well did the team present? Does the presentation appear to be well practiced? Did everyone get a chance to say something meaningful about the project?\n5 pts\n\n\nTeamwork: Did the team present a unified story, or did it seem like independent pieces of work patched together?\n6 pts\n\n\nContent: Did the team use appropriate statistical procedures and interpretations of results accurately?\n10 pts\n\n\nCreativity and Critical Thought: Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n10 pts\n\n\nSlides: Are the slides well organized, readable, not full of text, featuring figures with legible labels, legends, etc.?\n10 pts\n\n\n\n\n\nExecutive summary\nAlong with your presentation slides, we want you to provide a brief summary of your project in the README of your repository.\nThis executive summary should provide information on the dataset you’re using, your research question(s), your methodology, and your findings.\nThe executive summary is worth 15 points and will be evaluated based on whether it follows guidance and whether it’s concise but detailed enough.\n\n\nRepo organization\nThe following folders and files in your project repository:\n\npresentation.Rmd + presentation.html: Your presentation slides\nREADME.Rmd + README.md: Your write-up\n/data: Your dataset in CSV or RDS format and your data dictionary\n/proposal: Your project proposal\n\nStyle and format does count for this assignment, so please take the time to make sure everything looks good and your data and code are properly formatted.\n\n\n\nTips\n\nYou’re working in the same repo as your teammates now, so merge conflicts will happen, issues will arise, and that’s fine Commit and push often, and ask questions when stuck.\nReview the marking guidelines below and ask questions if any of the expectations are unclear.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nSet aside time to work together and apart (physically).\nWhen you’re done, review the documents on GitHub to make sure you’re happy with the final state of your work. Then go get some rest!\nCode: In your presentation your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your R Markdown file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcomed to show that portion.\n\nTeamwork: You are to complete the assignment as a team. All team members are expected to contribute equally to the completion of this assignment and team evaluations will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works.\n\n\n\nMarking\n\n\n\nTotal\n100 pts\n\n\n\n\nProposal\n10 pts\n\n\nPresentation\n50 pts\n\n\nExecutive summary\n15 pts\n\n\nReproducibility and organization\n10 pts\n\n\nTeam peer evaluation\n10 pts\n\n\nClassmates’ evaluation\n5 pts\n\n\n\n\nCriteria\nYour project will be assessed on the following criteria:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100% - Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89% - Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79% - Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69% - Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60% - Student is not making a sufficient effort.\n\n\n\nTeam peer evaluation\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member out of 10 points. You will additionally report a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation.If you are suggesting that an individual did less than 20% of the work, please provide some explanation. If any individual gets an average peer score indicating that they did less than 10% of the work, this person will receive half the grade of the rest of the group.",
    "crumbs": [
      "Content",
      "Project"
    ]
  },
  {
    "objectID": "content.html",
    "href": "content.html",
    "title": "Course content",
    "section": "",
    "text": "The course content is organized in five units: Hello world, Exploring data, Data science ethics, Making rigorous conclusions, and Looking further. For each unit numerous slide decks, homework and lab assignments, and application exercises are provided. Also provided are interactive tutorials, exams, and project assignment.",
    "crumbs": [
      "Content",
      "Course content"
    ]
  },
  {
    "objectID": "design.html",
    "href": "design.html",
    "title": "Course design",
    "section": "",
    "text": "Want some resources for learning more about teaching with Data Science in a Box or need a 11 or 15-week term schedule? You’ve come to the right place.",
    "crumbs": [
      "Design",
      "Course design"
    ]
  },
  {
    "objectID": "01-community.html",
    "href": "01-community.html",
    "title": "Community",
    "section": "",
    "text": "Do you like what’s in the box? Do you have questions? Is something you need missing? Want to exchange ideas with others teaching similar courses?\nWe now have a dsbox Slack channel, you can join here.1 The Slack channel is a place for discussion on using these or similar materials in data science courses. Please make sure to review the Code of Conduct before joining.\nOther great venues for questions are the RStudio Community under Teaching or #rstats Twitter.\nAdditionally, we would love to hear from you if you are using these resources. Please take just a few minutes to fill out this Google form. All fields are optional, but the more information you provide, the more data we will have to assess the reach and impact of this project.",
    "crumbs": [
      "Hello #dsbox!",
      "Community"
    ]
  },
  {
    "objectID": "01-community.html#footnotes",
    "href": "01-community.html#footnotes",
    "title": "Community",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf the link has expired, please email me at cetinkaya.mine@gmail.com to request a new one.↩︎",
    "crumbs": [
      "Hello #dsbox!",
      "Community"
    ]
  },
  {
    "objectID": "02-exploring-data.html",
    "href": "02-exploring-data.html",
    "title": "Exploring data",
    "section": "",
    "text": "This unit focuses on data visualization and data wrangling. Specifically we cover fundamentals of data and data visualization, confounding variables, and Simpson’s paradox as well as the concept of tidy data, data import, data cleaning, and data curation. We end the unit with web scraping and introduce the idea of iteration in preparation for the next unit. Also in this unit students are introduced to the toolkit: R, RStudio, R Markdown, Git, and GitHub.",
    "crumbs": [
      "Content",
      "Exploring data"
    ]
  },
  {
    "objectID": "02-exploring-data.html#slides-videos-and-application-exercises",
    "href": "02-exploring-data.html#slides-videos-and-application-exercises",
    "title": "Exploring data",
    "section": "Slides, videos, and application exercises",
    "text": "Slides, videos, and application exercises\n\nVisualising data\n\nUnit 2 - Deck 1: Data and visualisation\n\nSlides\n\n\nSource\n\n\nVideo\n\n\n\nUnit 2 - Deck 2: Visualising data with ggplot2\n\nSlides\n\n\nSource\n\n\nVideo\n\n\nR4DS :: Chp 3 - Data visualization\n\n\n\nUnit 2 - Deck 3: Visualising numerical data\n\nSlides\n\n\nSource\n\n\nVideo\n\n\nIMS :: Chp 4 - Exploring numerical data\n\n\n\nUnit 2 - Deck 4: Visualising categorical data\n\nSlides\n\n\nSource\n\n\nVideo\n\n\nIMS :: Chp 5 - Exploring categorical data\n\n\n\nStarWars + Dataviz\n\nSource\n\n\nVideo\n\n\n\n\nWrangling and tidying data\n\nUnit 2 - Deck 5: Tidy data\n\nSlides\n\n\nSource\n\n\nVideo\n\n\nJSS :: Tidy data\n\n\n\nUnit 2 - Deck 6: Grammar of data wrangling\n\nSlides\n\n\nSource\n\n\nVideo\n\n\n\nUnit 2 - Deck 7: Working with a single data frame\n\nSlides\n\n\nSource\n\n\nVideo\n\n\nR4DS :: Chp 5 - Data transformation\n\n\n\nUnit 2 - Deck 8: Working with multiple data frames\n\nSlides\n\n\nSource\n\n\nVideo\n\n\nR4DS :: Chp 13 - Relational data\n\n\n\nUnit 2 - Deck 9: Tidying data\n\nSlides\n\n\nSource\n\n\nVideo\n\n\nR4DS :: Chp 12 - Tidy data\n\n\n\nHotels + Data wrangling\n\nSource\n\n\nVideo\n\n\n\n\nImporting and recoding data\n\nUnit 2 - Deck 10: Data types\n\nSlides\n\n\nSource\n\n\nVideo\n\n\n\nUnit 2 - Deck 11: Data classes\n\nSlides\n\n\nSource\n\n\nVideo\n\n\nR4DS :: Chp 15 - Factors\n\n\n\nUnit 2 - Deck 12: Importing data\n\nSlides\n\n\nSource\n\n\nVideo\n\n\nR4DS :: Chp 11 - Data import\n\n\n\nUnit 2 - Deck 13: Recoding data\n\nSlides\n\n\nSource\n\n\nVideo\n\n\nR4DS :: Sec 16.1 - 16.3 - Dates and times\n\n\n\nHotels + Data types\n\nSource\n\n\nSource\n\n\nVideo\n\n\n\nNobels + Sales + Data import\n\nSource\n\n\nSource\n\n\nVideo\n\n\n\n\nCommunicating data science results effectively\n\nUnit 2 - Deck 14: Tips for effective data visualization\n\nSlides\n\n\nSource\n\n\nVideo\n\n\nIMS :: Chp 6 - Applications: Explore\n\n\n\nBrexit + Telling stories with dataviz\n\nSource\n\n\nVideo\n\n\n\nUnit 2 - Deck 15: Scientific studies and confounding\n\nSlides\n\n\nSource\n\n\nVideo\n\n\nIMS :: Chp 2 - Study design\n\n\n\nUnit 2 - Deck 16: Simpson’s paradox\n\nSlides\n\n\nSource\n\n\nVideo\n\n\n\nUnit 2 - Deck 17: Doing data science\n\nSlides\n\n\nSource\n\n\nVideo\n\n\nR4DS :: Chp 7 - Exploratory data analysis\n\n\n\n\nWeb scraping and programming\n\nUnit 2 - Deck 18: Web scraping\n\nSlides\n\n\nSource\n\n\nVideo\n\n\n\nUnit 2 - Deck 19: Scraping top 250 movies on IMDB\n\nSlides\n\n\nSource\n\n\nVideo\n\n\n\nUnit 2 - Deck 20: Web scraping considerations\n\nSlides\n\n\nSource\n\n\nVideo\n\n\n\nIMDB + Web scraping\n\nSource\n\n\nVideo\n\n\n\nUnit 2 - Deck 21: Functions\n\nSlides\n\n\nSource\n\n\nVideo\n\n\nR4DS :: Chp 19 - Functions\n\n\n\nUnit 2 - Deck 22: Iteration\n\nSlides\n\n\nSource\n\n\nVideo\n\n\nR4DS :: Chp 20 - Iteration",
    "crumbs": [
      "Content",
      "Exploring data"
    ]
  },
  {
    "objectID": "02-exploring-data.html#labs",
    "href": "02-exploring-data.html#labs",
    "title": "Exploring data",
    "section": "Labs",
    "text": "Labs\n\nLab 1: Hello R\nIntroduction to R, R Markdown, Git, and GitHub\n\nInstructions\n\n\nSource\n\n\nStarter\n\n\n\nLab 2: Plastic waste\nIntroduction to working with data in R with the tidyverse\n\nInstructions\n\n\nSource\n\n\nStarter\n\n\n\nLab 3: Nobel laureates\nData wrangling and tidying\n\nInstructions\n\n\nSource\n\n\nStarter\n\n\n\nLab 4: La Quinta is Spanish for ‘next to Denny’s’, Pt. 1\nVisualizing spatial data\n\nInstructions\n\n\nSource\n\n\nStarter\n\n\n\nLab 5: La Quinta is Spanish for ‘next to Denny’s’, Pt. 2\nWrangling spatial data\n\nInstructions\n\n\nSource\n\n\nStarter\n\n\n\nLab 6: Sad plots\nCritiquing and improving data visualisations\n\nInstructions\n\n\nSource\n\n\nStarter\n\n\n\nLab 7: Simpson’s paradox\nData visualisation, confounding, multivariable relationships\n\nInstructions\n\n\nSource\n\n\nStarter\n\n\n\nLab 8: University of Edinburgh Art Collection\nWeb scraping, function, iteration\n\nInstructions\n\n\nSource\n\n\nStarter",
    "crumbs": [
      "Content",
      "Exploring data"
    ]
  },
  {
    "objectID": "02-exploring-data.html#homework-assignments",
    "href": "02-exploring-data.html#homework-assignments",
    "title": "Exploring data",
    "section": "Homework assignments",
    "text": "Homework assignments\n\nHW 1: Pet names\nIntroduction to working with data in R with the tidyverse\n\nInstructions\n\n\nSource\n\n\nStarter\n\n\n\nHW 2: Edinburgh Airbnb rentals\nData visualisation with the tidyverse\n\nInstructions\n\n\nSource\n\n\nStarter\n\n\n\nHW 3: Road traffic accidents\nData wrangling, tidying, and visualization\n\nInstructions\n\n\nSource\n\n\nStarter\n\n\n\nHW 4: What should I major in?\nMore data wrangling, summarizing, and visualization\n\nInstructions\n\n\nSource\n\n\nStarter\n\n\n\nHW 5: Legos\nMore data wrangling, summarizing, and visualization\n\nInstructions\n\n\nSource\n\n\nStarter\n\n\n\nHW 6: Money in politics\nWeb scraping, functions, and iteration\n\nInstructions\n\n\nSource\n\n\nStarter",
    "crumbs": [
      "Content",
      "Exploring data"
    ]
  },
  {
    "objectID": "course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.html",
    "href": "course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.html",
    "title": "Hotel bookings - data wrangling",
    "section": "",
    "text": "library(tidyverse)\nlibrary(skimr)\n# From TidyTuesday: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-11/readme.md\nhotels &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")"
  },
  {
    "objectID": "course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.html#exercises",
    "href": "course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.html#exercises",
    "title": "Hotel bookings - data wrangling",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1.\nWarm up! Take a look at an overview of the data with the skim() function.\nNote: I already gave you the answer to this exercise. You just need to knit the document and view the output. A definition of all variables is given in the Data dictionary section at the end, though you don’t need to familiarize yourself with all variables in order to work through these exercises.\n\nskim(hotels)\n\n\nData summary\n\n\nName\nhotels\n\n\nNumber of rows\n119390\n\n\nNumber of columns\n32\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n13\n\n\nDate\n1\n\n\nnumeric\n18\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nhotel\n0\n1\n10\n12\n0\n2\n0\n\n\narrival_date_month\n0\n1\n3\n9\n0\n12\n0\n\n\nmeal\n0\n1\n2\n9\n0\n5\n0\n\n\ncountry\n0\n1\n2\n4\n0\n178\n0\n\n\nmarket_segment\n0\n1\n6\n13\n0\n8\n0\n\n\ndistribution_channel\n0\n1\n3\n9\n0\n5\n0\n\n\nreserved_room_type\n0\n1\n1\n1\n0\n10\n0\n\n\nassigned_room_type\n0\n1\n1\n1\n0\n12\n0\n\n\ndeposit_type\n0\n1\n10\n10\n0\n3\n0\n\n\nagent\n0\n1\n1\n4\n0\n334\n0\n\n\ncompany\n0\n1\n1\n4\n0\n353\n0\n\n\ncustomer_type\n0\n1\n5\n15\n0\n4\n0\n\n\nreservation_status\n0\n1\n7\n9\n0\n3\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nreservation_status_date\n0\n1\n2014-10-17\n2017-09-14\n2016-08-07\n926\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nis_canceled\n0\n1\n0.37\n0.48\n0.00\n0.00\n0.00\n1\n1\n▇▁▁▁▅\n\n\nlead_time\n0\n1\n104.01\n106.86\n0.00\n18.00\n69.00\n160\n737\n▇▂▁▁▁\n\n\narrival_date_year\n0\n1\n2016.16\n0.71\n2015.00\n2016.00\n2016.00\n2017\n2017\n▃▁▇▁▆\n\n\narrival_date_week_number\n0\n1\n27.17\n13.61\n1.00\n16.00\n28.00\n38\n53\n▅▇▇▇▅\n\n\narrival_date_day_of_month\n0\n1\n15.80\n8.78\n1.00\n8.00\n16.00\n23\n31\n▇▇▇▇▆\n\n\nstays_in_weekend_nights\n0\n1\n0.93\n1.00\n0.00\n0.00\n1.00\n2\n19\n▇▁▁▁▁\n\n\nstays_in_week_nights\n0\n1\n2.50\n1.91\n0.00\n1.00\n2.00\n3\n50\n▇▁▁▁▁\n\n\nadults\n0\n1\n1.86\n0.58\n0.00\n2.00\n2.00\n2\n55\n▇▁▁▁▁\n\n\nchildren\n4\n1\n0.10\n0.40\n0.00\n0.00\n0.00\n0\n10\n▇▁▁▁▁\n\n\nbabies\n0\n1\n0.01\n0.10\n0.00\n0.00\n0.00\n0\n10\n▇▁▁▁▁\n\n\nis_repeated_guest\n0\n1\n0.03\n0.18\n0.00\n0.00\n0.00\n0\n1\n▇▁▁▁▁\n\n\nprevious_cancellations\n0\n1\n0.09\n0.84\n0.00\n0.00\n0.00\n0\n26\n▇▁▁▁▁\n\n\nprevious_bookings_not_canceled\n0\n1\n0.14\n1.50\n0.00\n0.00\n0.00\n0\n72\n▇▁▁▁▁\n\n\nbooking_changes\n0\n1\n0.22\n0.65\n0.00\n0.00\n0.00\n0\n21\n▇▁▁▁▁\n\n\ndays_in_waiting_list\n0\n1\n2.32\n17.59\n0.00\n0.00\n0.00\n0\n391\n▇▁▁▁▁\n\n\nadr\n0\n1\n101.83\n50.54\n-6.38\n69.29\n94.58\n126\n5400\n▇▁▁▁▁\n\n\nrequired_car_parking_spaces\n0\n1\n0.06\n0.25\n0.00\n0.00\n0.00\n0\n8\n▇▁▁▁▁\n\n\ntotal_of_special_requests\n0\n1\n0.57\n0.79\n0.00\n0.00\n0.00\n1\n5\n▇▁▁▁▁\n\n\n\n\n\n\n\nExercise 2.\nAre people traveling on a whim? Let’s see…\nFill in the blanks for filtering for hotel bookings where the guest is not from the US (country code \"USA\") and the lead_time is less than 1 day.\nNote: You will need to set eval=TRUE when you have an answer you want to try out.\n\nhotels %&gt;%\n  filter(\n    country ____ \"USA\", \n    lead_time ____ ____\n    )\n\n\n\nExercise 3.\nHow many bookings involve at least 1 child or baby?\nIn the following chunk, replace\n\n[AT LEAST] with the logical operator for “at least” (in two places)\n[OR] with the logical operator for “or”\n\nNote: You will need to set eval=TRUE when you have an answer you want to try out.\n\nhotels %&gt;%\n  filter(\n    children [AT LEAST] 1 [OR] babies [AT LEAST] 1\n    )\n\n\n\nExercise 4.\nDo you think it’s more likely to find bookings with children or babies in city hotels or resort hotels? Test your intuition. Using filter() determine the number of bookings in resort hotels that have more than 1 child or baby in the room? Then, do the same for city hotels, and compare the numbers of rows in the resulting filtered data frames.\n\n# add code here\n# pay attention to correctness and code style\n\n\n# add code here\n# pay attention to correctness and code style\n\n\n\nExercise 5.\nCreate a frequency table of the number of adults in a booking. Display the results in descending order so the most common observation is on top. What is the most common number of adults in bookings in this dataset? Are there any surprising results?\nNote: Don’t forget to label your R chunk as well (where it says label-me-1). Your label should be short, informative, and shouldn’t include spaces. It also shouldn’t repeat a previous label, otherwise R Markdown will give you an error about repeated R chunk labels.\n\n# add code here\n# pay attention to correctness and code style\n\n\n\nExercise 6.\nRepeat Exercise 5, once for canceled bookings (is_canceled coded as 1) and once for not canceled bookings (is_canceled coded as 0). What does this reveal about the surprising results you spotted in the previous exercise?\nNote: Don’t forget to label your R chunk as well (where it says label-me-2).\n\n# add code here\n# pay attention to correctness and code style\n\n\n\nExercise 7.\nCalculate minimum, mean, median, and maximum average daily rate (adr) grouped by hotel type so that you can get these statistics separately for resort and city hotels. Which type of hotel is higher, on average?\n\n# add code here\n# pay attention to correctness and code style\n\n\n\nExercise 8.\nWe observe two unusual values in the summary statistics above – a negative minimum, and a very high maximum). What types of hotels are these? Locate these observations in the dataset and find out the arrival date (year and month) as well as how many people (adults, children, and babies) stayed in the room. You can investigate the data in the viewer to locate these values, but preferably you should identify them in a reproducible way with some code.\nHint: For example, you can filter for the given adr amounts and select the relevant columns.\n\n# add code here\n# pay attention to correctness and code style"
  },
  {
    "objectID": "course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.html#data-dictionary",
    "href": "course-materials/application-exercises/ae-04-hotels-datawrangling/hotels-datawrangling.html#data-dictionary",
    "title": "Hotel bookings - data wrangling",
    "section": "Data dictionary",
    "text": "Data dictionary\nBelow is the full data dictionary. Note that it is long (there are lots of variables in the data), but we will be using a limited set of the variables for our analysis.\n\n\n\n\n\n\n\n\nvariable\nclass\ndescription\n\n\n\n\nhotel\ncharacter\nHotel (H1 = Resort Hotel or H2 = City Hotel)\n\n\nis_canceled\ndouble\nValue indicating if the booking was canceled (1) or not (0)\n\n\nlead_time\ndouble\nNumber of days that elapsed between the entering date of the booking into the PMS and the arrival date\n\n\narrival_date_year\ndouble\nYear of arrival date\n\n\narrival_date_month\ncharacter\nMonth of arrival date\n\n\narrival_date_week_number\ndouble\nWeek number of year for arrival date\n\n\narrival_date_day_of_month\ndouble\nDay of arrival date\n\n\nstays_in_weekend_nights\ndouble\nNumber of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel\n\n\nstays_in_week_nights\ndouble\nNumber of week nights (Monday to Friday) the guest stayed or booked to stay at the hotel\n\n\nadults\ndouble\nNumber of adults\n\n\nchildren\ndouble\nNumber of children\n\n\nbabies\ndouble\nNumber of babies\n\n\nmeal\ncharacter\nType of meal booked. Categories are presented in standard hospitality meal packages:  Undefined/SC – no meal package;BB – Bed & Breakfast;  HB – Half board (breakfast and one other meal – usually dinner);  FB – Full board (breakfast, lunch and dinner)\n\n\ncountry\ncharacter\nCountry of origin. Categories are represented in the ISO 3155–3:2013 format\n\n\nmarket_segment\ncharacter\nMarket segment designation. In categories, the term “TA” means “Travel Agents” and “TO” means “Tour Operators”\n\n\ndistribution_channel\ncharacter\nBooking distribution channel. The term “TA” means “Travel Agents” and “TO” means “Tour Operators”\n\n\nis_repeated_guest\ndouble\nValue indicating if the booking name was from a repeated guest (1) or not (0)\n\n\nprevious_cancellations\ndouble\nNumber of previous bookings that were cancelled by the customer prior to the current booking\n\n\nprevious_bookings_not_canceled\ndouble\nNumber of previous bookings not cancelled by the customer prior to the current booking\n\n\nreserved_room_type\ncharacter\nCode of room type reserved. Code is presented instead of designation for anonymity reasons\n\n\nassigned_room_type\ncharacter\nCode for the type of room assigned to the booking. Sometimes the assigned room type differs from the reserved room type due to hotel operation reasons (e.g. overbooking) or by customer request. Code is presented instead of designation for anonymity reasons\n\n\nbooking_changes\ndouble\nNumber of changes/amendments made to the booking from the moment the booking was entered on the PMS until the moment of check-in or cancellation\n\n\ndeposit_type\ncharacter\nIndication on if the customer made a deposit to guarantee the booking. This variable can assume three categories:No Deposit – no deposit was made;Non Refund – a deposit was made in the value of the total stay cost;Refundable – a deposit was made with a value under the total cost of stay.\n\n\nagent\ncharacter\nID of the travel agency that made the booking\n\n\ncompany\ncharacter\nID of the company/entity that made the booking or responsible for paying the booking. ID is presented instead of designation for anonymity reasons\n\n\ndays_in_waiting_list\ndouble\nNumber of days the booking was in the waiting list before it was confirmed to the customer\n\n\ncustomer_type\ncharacter\nType of booking, assuming one of four categories:Contract - when the booking has an allotment or other type of contract associated to it;Group – when the booking is associated to a group;Transient – when the booking is not part of a group or contract, and is not associated to other transient booking;Transient-party – when the booking is transient, but is associated to at least other transient booking\n\n\nadr\ndouble\nAverage Daily Rate as defined by dividing the sum of all lodging transactions by the total number of staying nights\n\n\nrequired_car_parking_spaces\ndouble\nNumber of car parking spaces required by the customer\n\n\ntotal_of_special_requests\ndouble\nNumber of special requests made by the customer (e.g. twin bed or high floor)\n\n\nreservation_status\ncharacter\nReservation last status, assuming one of three categories:Canceled – booking was canceled by the customer;Check-Out – customer has checked in but already departed;No-Show – customer did not check-in and did inform the hotel of the reason why\n\n\nreservation_status_date\ndouble\nDate at which the last status was set. This variable can be used in conjunction with the ReservationStatus to understand when was the booking canceled or when did the customer checked-out of the hotel"
  },
  {
    "objectID": "course-materials/application-exercises/ae-06-nobels-sales-dataimport/sales-excel.html",
    "href": "course-materials/application-exercises/ae-06-nobels-sales-dataimport/sales-excel.html",
    "title": "Sales",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\n\n\nRead in the Excel file called sales.xlsx from the data-raw/ folder such that it looks like the following.\n\n\n\n\n\n\n\n\n\n\n\nStretch goal: Manipulate the sales data such such that it looks like the following."
  },
  {
    "objectID": "course-materials/application-exercises/ae-09-feat-eng-cv/theoffice.html",
    "href": "course-materials/application-exercises/ae-09-feat-eng-cv/theoffice.html",
    "title": "The Office",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(schrute)\nlibrary(lubridate)\n\nUse theoffice data from the schrute package to predict IMDB scores for episodes of The Office.\n\nglimpse(theoffice)\n\nRows: 55,130\nColumns: 12\n$ index            &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16…\n$ season           &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ episode          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ episode_name     &lt;chr&gt; \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\",…\n$ director         &lt;chr&gt; \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis…\n$ writer           &lt;chr&gt; \"Ricky Gervais;Stephen Merchant;Greg Daniels\", \"Ricky…\n$ character        &lt;chr&gt; \"Michael\", \"Jim\", \"Michael\", \"Jim\", \"Michael\", \"Micha…\n$ text             &lt;chr&gt; \"All right Jim. Your quarterlies look very good. How …\n$ text_w_direction &lt;chr&gt; \"All right Jim. Your quarterlies look very good. How …\n$ imdb_rating      &lt;dbl&gt; 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6…\n$ total_votes      &lt;int&gt; 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706,…\n$ air_date         &lt;chr&gt; \"2005-03-24\", \"2005-03-24\", \"2005-03-24\", \"2005-03-24…\n\n\nFix air_date for later use.\n\ntheoffice &lt;- theoffice %&gt;%\n  mutate(air_date = ymd(as.character(air_date)))\n\nWe will\n\nengineer features based on episode scripts\ntrain a model\nperform cross validation\nmake predictions\n\nNote: The episodes listed in theoffice don’t match the ones listed in the data we used in the cross validation lesson.\n\ntheoffice %&gt;%\n  distinct(season, episode)\n\n# A tibble: 186 × 2\n   season episode\n    &lt;int&gt;   &lt;int&gt;\n 1      1       1\n 2      1       2\n 3      1       3\n 4      1       4\n 5      1       5\n 6      1       6\n 7      2       1\n 8      2       2\n 9      2       3\n10      2       4\n# ℹ 176 more rows\n\n\n\nExercise 1 - Calculate the percentage of lines spoken by Jim, Pam, Michael, and Dwight for each episode of The Office.\n\n\nExercise 2 - Identify episodes that touch on Halloween, Valentine’s Day, and Christmas.\n\n\nExercise 3 - Put together a modeling dataset that includes features you’ve engineered. Also add an indicator variable called michael which takes the value 1 if Michael Scott (Steve Carrell) was there, and 0 if not. Note: Michael Scott (Steve Carrell) left the show at the end of Season 7.\n\n\nExercise 4 - Split the data into training (75%) and testing (25%).\n\nset.seed(1122)\n\n\n\nExercise 5 - Specify a linear regression model.\n\n\nExercise 6 - Create a recipe that updates the role of episode_name to not be a predictor, removes air_date as a predictor, uses season as a factor, and removes all zero variance predictors.\n\n\nExercise 7 - Build a workflow for fitting the model specified earlier and using the recipe you developed to preprocess the data.\n\n\nExercise 8 - Fit the model to training data and interpret a couple of the slope coefficients.\n\n\nExercise 9 - Perform 5-fold cross validation and view model performance metrics.\n\n#set.seed(345)\n#folds &lt;- vfold_cv(___, v = ___)\n#folds\n#\n#set.seed(456)\n#office_fit_rs &lt;- ___ %&gt;%\n#  ___(___)\n#\n#___(office_fit_rs)\n\n\n\nExercise 10 - Use your model to make predictions for the testing data and calculate the RMSE. Also use the model developed in the cross validation lesson to make predictions for the testing data and calculate the RMSE as well. Which model did a better job in predicting IMDB scores for the testing data?\n\nNew model\n\n\nOld model\nTO DO: See what ___ is.\n#| label: old-model\n#| error: true\n\noffice_mod_old &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\")\n\noffice_rec_old &lt;- recipe(imdb_rating ~ season + episode + total_votes + air_date, data = office_train) %&gt;%\n  # extract month of air_date\n  step_date(air_date, features = \"month\") %&gt;%\n  step_rm(air_date) %&gt;%\n  # make dummy variables of month \n  step_dummy(contains(\"month\")) %&gt;%\n  # remove zero variance predictors\n  step_zv(all_predictors())\n\noffice_wflow_old &lt;- workflow() %&gt;%\n  add_model(office_mod_old) %&gt;%\n  add_recipe(office_rec_old)\n\noffice_fit_old &lt;- office_wflow_old %&gt;%\n  fit(data = office_train)\n\ntidy(office_fit_old)\n\n___"
  },
  {
    "objectID": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html",
    "href": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html",
    "title": "UN Votes",
    "section": "",
    "text": "How do various countries vote in the United Nations General Assembly, how have their voting patterns evolved throughout time, and how similarly or differently do they view certain issues? Answering these questions (at a high level) is the focus of this analysis.\n\n\nWe will use the tidyverse, lubridate, and scales packages for data wrangling and visualization, and the DT package for interactive display of tabular output, and the unvotes package for the data.\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(scales)\nlibrary(DT)\nlibrary(unvotes)\n\n\n\n\nThe data we’re using originally come from the unvotes package. In the chunk below we modify the data by joining the various data frames provided in the package to help you get started with the analysis.\n\nunvotes &lt;- un_votes %&gt;%\n  inner_join(un_roll_calls, by = \"rcid\") %&gt;%\n  inner_join(un_roll_call_issues, by = \"rcid\")"
  },
  {
    "objectID": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html#introduction",
    "href": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html#introduction",
    "title": "UN Votes",
    "section": "",
    "text": "How do various countries vote in the United Nations General Assembly, how have their voting patterns evolved throughout time, and how similarly or differently do they view certain issues? Answering these questions (at a high level) is the focus of this analysis.\n\n\nWe will use the tidyverse, lubridate, and scales packages for data wrangling and visualization, and the DT package for interactive display of tabular output, and the unvotes package for the data.\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(scales)\nlibrary(DT)\nlibrary(unvotes)\n\n\n\n\nThe data we’re using originally come from the unvotes package. In the chunk below we modify the data by joining the various data frames provided in the package to help you get started with the analysis.\n\nunvotes &lt;- un_votes %&gt;%\n  inner_join(un_roll_calls, by = \"rcid\") %&gt;%\n  inner_join(un_roll_call_issues, by = \"rcid\")"
  },
  {
    "objectID": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html#un-voting-patterns",
    "href": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html#un-voting-patterns",
    "title": "UN Votes",
    "section": "UN voting patterns",
    "text": "UN voting patterns\nLet’s create a data visualisation that displays how the voting record of the UK & NI changed over time on a variety of issues, and compares it to two other countries: US and Turkey.\nWe can easily change which countries are being plotted by changing which countries the code above filters for. Note that the country name should be spelled and capitalized exactly the same way as it appears in the data. See the Appendix for a list of the countries in the data.\n\nunvotes %&gt;%\n  filter(country %in% c(\"United Kingdom\", \"United States\", \"Turkey\")) %&gt;%\n  mutate(year = year(date)) %&gt;%\n  group_by(country, year, issue) %&gt;%\n  summarize(percent_yes = mean(vote == \"yes\")) %&gt;%\n  ggplot(mapping = aes(x = year, y = percent_yes, color = country)) +\n  geom_point(alpha = 0.4) +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  facet_wrap(~issue) +\n  scale_y_continuous(labels = percent) +\n  labs(\n    title = \"Percentage of 'Yes' votes in the UN General Assembly\",\n    subtitle = \"1946 to 2019\",\n    y = \"% Yes\",\n    x = \"Year\",\n    color = \"Country\"\n  )"
  },
  {
    "objectID": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html#references",
    "href": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html#references",
    "title": "UN Votes",
    "section": "References",
    "text": "References\n\nDavid Robinson (2017). unvotes: United Nations General Assembly Voting Data. R package version 0.2.0.\nErik Voeten “Data and Analyses of Voting in the UN General Assembly” Routledge Handbook of International Organization, edited by Bob Reinalda (published May 27, 2013).\nMuch of the analysis has been modeled on the examples presented in the unvotes package vignette."
  },
  {
    "objectID": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html#appendix",
    "href": "course-materials/application-exercises/ae-01a-un-votes/unvotes.html#appendix",
    "title": "UN Votes",
    "section": "Appendix",
    "text": "Appendix\nBelow is a list of countries in the dataset:"
  },
  {
    "objectID": "course-materials/application-exercises/ae-05-hotels-datatypes/type-coercion.html",
    "href": "course-materials/application-exercises/ae-05-hotels-datatypes/type-coercion.html",
    "title": "Type coercion",
    "section": "",
    "text": "c(1, 1L, \"C\")\n\n\nc(1, 1L, \"C\")\n\n[1] \"1\" \"1\" \"C\"\n\n\n\n1\n\n[1] 1\n\n1L\n\n[1] 1\n\n\"C\"\n\n[1] \"C\"\n\n\n\n#typeof(c(1, 1L, \"C\"))\n\n\nc(1L / 0, \"A\")\n\n\nc(1L / 0, \"A\")\n\n[1] \"Inf\" \"A\"  \n\n\n\ntypeof(1L)\n\n[1] \"integer\"\n\ntypeof(0)\n\n[1] \"double\"\n\ntypeof(1L/0)\n\n[1] \"double\"\n\ntypeof(\"A\")\n\n[1] \"character\"\n\n\n\n#typeof(c(1L / 0, \"A\"))\n\n\nc(1:3, 5)\n\n\nc(1:3, 5)\n\n[1] 1 2 3 5\n\n\n\ntypeof(1:3)\n\n[1] \"integer\"\n\ntypeof(5)\n\n[1] \"double\"\n\n\n\n#typeof(c(1:3, 5))\n\n\nc(3, \"3+\")\n\n\nc(3, \"3+\")\n\n[1] \"3\"  \"3+\"\n\n\n\ntypeof(3)\n\n[1] \"double\"\n\ntypeof(\"3+\")\n\n[1] \"character\"\n\n\n\n#typeof(c(3, \"3+\"))\n\n\nc(NA, TRUE)\n\n\nc(NA, TRUE)\n\n[1]   NA TRUE\n\n\n\ntypeof(NA)\n\n[1] \"logical\"\n\ntypeof(TRUE)\n\n[1] \"logical\"\n\n\n\n#typeof(c(NA, TRUE))"
  },
  {
    "objectID": "course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.html",
    "href": "course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.html",
    "title": "Bechdel",
    "section": "",
    "text": "In this mini analysis we work with the data used in the FiveThirtyEight story titled “The Dollar-And-Cents Case Against Hollywood’s Exclusion of Women”. Your task is to fill in the blanks denoted by ___."
  },
  {
    "objectID": "course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.html#data-and-packages",
    "href": "course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.html#data-and-packages",
    "title": "Bechdel",
    "section": "Data and packages",
    "text": "Data and packages\nWe start with loading the packages we’ll use.\n\nlibrary(fivethirtyeight)\nlibrary(tidyverse)\n\nThe dataset contains information on 1794 movies released between 1970 and 2013. However we’ll focus our analysis on movies released between 1990 and 2013.\n\nbechdel90_13 &lt;- bechdel %&gt;% \n  filter(between(year, 1990, 2013))\n\nThere are ___ such movies.\nThe financial variables we’ll focus on are the following:\n\nbudget_2013: Budget in 2013 inflation adjusted dollars\ndomgross_2013: Domestic gross (US) in 2013 inflation adjusted dollars\nintgross_2013: Total International (i.e., worldwide) gross in 2013 inflation adjusted dollars\n\nAnd we’ll also use the binary and clean_test variables for grouping."
  },
  {
    "objectID": "course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.html#analysis",
    "href": "course-materials/application-exercises/ae-02-bechdel-rmarkdown/bechdel.html#analysis",
    "title": "Bechdel",
    "section": "Analysis",
    "text": "Analysis\nLet’s take a look at how median budget and gross vary by whether the movie passed the Bechdel test, which is stored in the binary variable.\n\nbechdel90_13 %&gt;%\n  group_by(binary) %&gt;%\n  summarise(\n    med_budget = median(budget_2013),\n    med_domgross = median(domgross_2013, na.rm = TRUE),\n    med_intgross = median(intgross_2013, na.rm = TRUE)\n    )\n\n# A tibble: 2 × 4\n  binary med_budget med_domgross med_intgross\n  &lt;chr&gt;       &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 FAIL    48385984.    57318606.    104475669\n2 PASS    31070724     45330446.     80124349\n\n\nNext, let’s take a look at how median budget and gross vary by a more detailed indicator of the Bechdel test result. This information is stored in the clean_test variable, which takes on the following values:\n\nok = passes test\ndubious\nmen = women only talk about men\nnotalk = women don’t talk to each other\nnowomen = fewer than two women\n\n\nbechdel90_13 %&gt;%\n  #group_by(___) %&gt;%\n  summarise(\n    med_budget = median(budget_2013),\n    med_domgross = median(domgross_2013, na.rm = TRUE),\n    med_intgross = median(intgross_2013, na.rm = TRUE)\n    )\n\n# A tibble: 1 × 3\n  med_budget med_domgross med_intgross\n       &lt;int&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1   37878971     52270207     93523336\n\n\nIn order to evaluate how return on investment varies among movies that pass and fail the Bechdel test, we’ll first create a new variable called roi as the ratio of the gross to budget.\n\nbechdel90_13 &lt;- bechdel90_13 %&gt;%\n  mutate(roi = (intgross_2013 + domgross_2013) / budget_2013)\n\nLet’s see which movies have the highest return on investment.\n\nbechdel90_13 %&gt;%\n  arrange(desc(roi)) %&gt;% \n  select(title, roi, year)\n\n# A tibble: 1,615 × 3\n   title                     roi  year\n   &lt;chr&gt;                   &lt;dbl&gt; &lt;int&gt;\n 1 Paranormal Activity      671.  2007\n 2 The Blair Witch Project  648.  1999\n 3 El Mariachi              583.  1992\n 4 Clerks.                  258.  1994\n 5 In the Company of Men    231.  1997\n 6 Napoleon Dynamite        227.  2004\n 7 Once                     190.  2006\n 8 The Devil Inside         155.  2012\n 9 Primer                   142.  2004\n10 Fireproof                134.  2008\n# … with 1,605 more rows\n\n\nBelow is a visualization of the return on investment by test result, however it’s difficult to see the distributions due to a few extreme observations.\n\nggplot(data = bechdel90_13, \n       mapping = aes(x = clean_test, y = roi, color = binary)) +\n  geom_boxplot() +\n  labs(\n    title = \"Return on investment vs. Bechdel test result\",\n    x = \"Detailed Bechdel result\",\n    y = \"___\",\n    color = \"Binary Bechdel result\"\n    )\n\n\n\n\n\n\n\n\nWhat are those movies with very high returns on investment?\n\nbechdel90_13 %&gt;%\n  filter(roi &gt; 400) %&gt;%\n  select(title, budget_2013, domgross_2013, year)\n\n# A tibble: 3 × 4\n  title                   budget_2013 domgross_2013  year\n  &lt;chr&gt;                         &lt;int&gt;         &lt;dbl&gt; &lt;int&gt;\n1 Paranormal Activity          505595     121251476  2007\n2 The Blair Witch Project      839077     196538593  1999\n3 El Mariachi                   11622       3388636  1992\n\n\nZooming in on the movies with roi &lt; ___ provides a better view of how the medians across the categories compare:\n\nggplot(data = bechdel90_13, mapping = aes(x = clean_test, y = roi, color = binary)) +\n  geom_boxplot() +\n  labs(\n    title = \"Return on investment vs. Bechdel test result\",\n    subtitle = \"___\", # Something about zooming in to a certain level\n    x = \"Detailed Bechdel result\",\n    y = \"Return on investment\",\n    color = \"Binary Bechdel result\"\n    ) +\n  coord_cartesian(ylim = c(0, 15))"
  },
  {
    "objectID": "course-materials/starters/hw/hw-10-wrap-up/hw-10.html",
    "href": "course-materials/starters/hw/hw-10-wrap-up/hw-10.html",
    "title": "HW 10 - Wrap up",
    "section": "",
    "text": "library(tidyverse)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-10-wrap-up/hw-10.html#load-packages-and-data",
    "href": "course-materials/starters/hw/hw-10-wrap-up/hw-10.html#load-packages-and-data",
    "title": "HW 10 - Wrap up",
    "section": "",
    "text": "library(tidyverse)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-10-wrap-up/hw-10.html#exercises",
    "href": "course-materials/starters/hw/hw-10-wrap-up/hw-10.html#exercises",
    "title": "HW 10 - Wrap up",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels."
  },
  {
    "objectID": "course-materials/starters/hw/hw-06-money-in-politics/hw-06.html",
    "href": "course-materials/starters/hw/hw-06-money-in-politics/hw-06.html",
    "title": "HW 06 - Money in politics",
    "section": "",
    "text": "library(tidyverse)\nlibrary(rvest)\nlibrary(scales)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-06-money-in-politics/hw-06.html#load-packages-and-data",
    "href": "course-materials/starters/hw/hw-06-money-in-politics/hw-06.html#load-packages-and-data",
    "title": "HW 06 - Money in politics",
    "section": "",
    "text": "library(tidyverse)\nlibrary(rvest)\nlibrary(scales)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-06-money-in-politics/hw-06.html#exercises",
    "href": "course-materials/starters/hw/hw-06-money-in-politics/hw-06.html#exercises",
    "title": "HW 06 - Money in politics",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n…\n\n\nExercise 5\n…"
  },
  {
    "objectID": "course-materials/starters/hw/hw-03-bike-crash/hw-03.html",
    "href": "course-materials/starters/hw/hw-03-bike-crash/hw-03.html",
    "title": "HW 02 - Road traffic accidents",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-03-bike-crash/hw-03.html#load-packages-and-data",
    "href": "course-materials/starters/hw/hw-03-bike-crash/hw-03.html#load-packages-and-data",
    "title": "HW 02 - Road traffic accidents",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-03-bike-crash/hw-03.html#exercises",
    "href": "course-materials/starters/hw/hw-03-bike-crash/hw-03.html#exercises",
    "title": "HW 02 - Road traffic accidents",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here.\n\n# remove this comment and add the code for Exercise 3 here\n\n\n\nExercise 4\nRemove this text, and add your answer for Exercise 4 here.\n\n# remove this comment and add the code for Exercise 4 here"
  },
  {
    "objectID": "course-materials/starters/hw/hw-08-exploring-gss/hw-08.html",
    "href": "course-materials/starters/hw/hw-08-exploring-gss/hw-08.html",
    "title": "HW 08 - Exploring the GSS",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-08-exploring-gss/hw-08.html#load-packages-and-data",
    "href": "course-materials/starters/hw/hw-08-exploring-gss/hw-08.html#load-packages-and-data",
    "title": "HW 08 - Exploring the GSS",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-08-exploring-gss/hw-08.html#exercises",
    "href": "course-materials/starters/hw/hw-08-exploring-gss/hw-08.html#exercises",
    "title": "HW 08 - Exploring the GSS",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n…\n\n\nExercise 5\n…\n\n\nExercise 6\n…\n\n\nExercise 7\n…\n\n\nExercise 8\n…\n\n\nExercise 9\n…\n\n\nExercise 10\n…\n\n\nExercise 11\n…\n\n\nExercise 12\n…"
  },
  {
    "objectID": "course-materials/starters/hw/hw-05-legos/hw-05.html",
    "href": "course-materials/starters/hw/hw-05-legos/hw-05.html",
    "title": "HW 05 - Legos",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-05-legos/hw-05.html#load-packages-and-data",
    "href": "course-materials/starters/hw/hw-05-legos/hw-05.html#load-packages-and-data",
    "title": "HW 05 - Legos",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/starters/hw/hw-05-legos/hw-05.html#exercises",
    "href": "course-materials/starters/hw/hw-05-legos/hw-05.html#exercises",
    "title": "HW 05 - Legos",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 2 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\nRemove this text, and add your answer for Exercise 3 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 4\n…\n\n\nExercise 5\n…\n\n\nExercise 6\n…\n\n\nExercise 7\n…\n\n\nExercise 8\n…\n\n\nExercise 9\n…"
  },
  {
    "objectID": "course-materials/starters/lab/lab-11-mlr-course-evals/lab-11.html",
    "href": "course-materials/starters/lab/lab-11-mlr-course-evals/lab-11.html",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "",
    "text": "Load packages and data\n\nlibrary(tidyverse) \nlibrary(tidymodels)\nlibrary(openintro)\n\n\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/lab/lab-06-sad-plots/lab-06.html",
    "href": "course-materials/starters/lab/lab-06-sad-plots/lab-06.html",
    "title": "Lab 06 - Sad plots",
    "section": "",
    "text": "Load packages and data\n\nlibrary(tidyverse) \nlibrary(dsbox) \n\n\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 3\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/lab/lab-08-uoe-art/lab-08.html",
    "href": "course-materials/starters/lab/lab-08-uoe-art/lab-08.html",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "",
    "text": "Load packages and data\n\nlibrary(tidyverse) \nlibrary(skimr)\n\n\n# Remove eval = FALSE or set it to TRUE once data is ready to be loaded\nuoe_art &lt;- read_csv(\"data/uoe-art.csv\")\n\n\n\nExercise 9\nuoe_art &lt;- uoe_art %&gt;%\n  separate(title, into = c(\"title\", \"date\"), sep = \"\\\\(\") %&gt;%\n  mutate(year = str_remove(date, \"\\\\)\") %&gt;% as.numeric()) %&gt;%\n  select(title, artist, year, ___)\nTO DO: Add error true\n\n\nExercise 10\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 11\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/lab/lab-01-hello-r/lab-01.html",
    "href": "course-materials/starters/lab/lab-01-hello-r/lab-01.html",
    "title": "Lab 01 - Hello R",
    "section": "",
    "text": "library(tidyverse) \nlibrary(datasauRus)"
  },
  {
    "objectID": "course-materials/starters/lab/lab-01-hello-r/lab-01.html#load-packages-and-data",
    "href": "course-materials/starters/lab/lab-01-hello-r/lab-01.html#load-packages-and-data",
    "title": "Lab 01 - Hello R",
    "section": "",
    "text": "library(tidyverse) \nlibrary(datasauRus)"
  },
  {
    "objectID": "course-materials/starters/lab/lab-01-hello-r/lab-01.html#exercises",
    "href": "course-materials/starters/lab/lab-01-hello-r/lab-01.html#exercises",
    "title": "Lab 01 - Hello R",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here.\n\n\nExercise 2\nThe answers for this Exercise are given for you below. But you should clean up some of the narrative so that it only includes what you want to turn in.\nFirst let’s plot the data in the dino dataset:\n\ndino_data &lt;- datasaurus_dozen %&gt;%\n  filter(dataset == \"dino\")\n\nggplot(data = dino_data, mapping = aes(x = x, y = y)) +\n  geom_point()\n\n\n\n\n\n\n\n\nAnd next calculate the correlation between x and y in this dataset:\n\ndino_data %&gt;%\n  summarize(r = cor(x, y))\n\n# A tibble: 1 × 1\n        r\n    &lt;dbl&gt;\n1 -0.0645\n\n\n\n\nExercise 3\nAdd code and narrative as needed. Note that the R chunks are labelled with plot-star and cor-star to provide spaces to place the code for plotting and calculating the correlation coefficient. To finish, clean up the narrative by removing these instructions.\nBlah blah blah…\nI’m some text, you should replace me with more meaningful text…\n\n\nExercise 4\nAdd code and narrative as needed. Note that two R chunks are given but they are not labeled. Use the convention from above to name them appropriately.\n\n\nExercise 5\nAdd code and narrative as needed. To add R chunks either type out the backticks, curly braces, and the letter r or use the Insert chunk button above, green C+."
  },
  {
    "objectID": "course-materials/starters/lab/lab-12-inference-smoking/lab-12.html",
    "href": "course-materials/starters/lab/lab-12-inference-smoking/lab-12.html",
    "title": "Lab 12 - Smoking during pregnancy",
    "section": "",
    "text": "Load packages and data\n\nlibrary(tidyverse) \nlibrary(tidymodels)\nlibrary(openintro)\n\n\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/lab/lab-10-slr-course-evals/lab-10.html",
    "href": "course-materials/starters/lab/lab-10-slr-course-evals/lab-10.html",
    "title": "Lab 10 - Grading the professor, Pt. 1",
    "section": "",
    "text": "Load packages and data\n\nlibrary(tidyverse) \nlibrary(tidymodels)\nlibrary(openintro)\n\n\n\nExercise 1\nRemove this text, and add your answer for Exercise 1 here. Add code chunks as needed. Don’t forget to label your code chunk. Do not use spaces in code chunk labels.\n\n\nExercise 2\n…\nAdd exercise headings as needed."
  },
  {
    "objectID": "course-materials/starters/project/proposal/proposal.html",
    "href": "course-materials/starters/project/proposal/proposal.html",
    "title": "Project proposal",
    "section": "",
    "text": "library(tidyverse)\nlibrary(broom)"
  },
  {
    "objectID": "course-materials/starters/project/proposal/proposal.html#introduction",
    "href": "course-materials/starters/project/proposal/proposal.html#introduction",
    "title": "Project proposal",
    "section": "1. Introduction",
    "text": "1. Introduction"
  },
  {
    "objectID": "course-materials/starters/project/proposal/proposal.html#data",
    "href": "course-materials/starters/project/proposal/proposal.html#data",
    "title": "Project proposal",
    "section": "2. Data",
    "text": "2. Data"
  },
  {
    "objectID": "course-materials/starters/project/proposal/proposal.html#data-analysis-plan",
    "href": "course-materials/starters/project/proposal/proposal.html#data-analysis-plan",
    "title": "Project proposal",
    "section": "3. Data analysis plan",
    "text": "3. Data analysis plan"
  },
  {
    "objectID": "course-materials/exams/exam-02/exam-02.html",
    "href": "course-materials/exams/exam-02/exam-02.html",
    "title": "SAMPLE TAKE HOME EXAM - STUDENT TEMPLATE",
    "section": "",
    "text": "I, ____________, hereby state that I have not communicated with or gained information in any way from my classmates or anyone other than the Professor or TA during this exam, and that all work is my own."
  },
  {
    "objectID": "course-materials/exams/exam-02/exam-02.html#academic-honesty-statement",
    "href": "course-materials/exams/exam-02/exam-02.html#academic-honesty-statement",
    "title": "SAMPLE TAKE HOME EXAM - STUDENT TEMPLATE",
    "section": "",
    "text": "I, ____________, hereby state that I have not communicated with or gained information in any way from my classmates or anyone other than the Professor or TA during this exam, and that all work is my own."
  },
  {
    "objectID": "course-materials/exams/exam-02/exam-02.html#load-packages",
    "href": "course-materials/exams/exam-02/exam-02.html#load-packages",
    "title": "SAMPLE TAKE HOME EXAM - STUDENT TEMPLATE",
    "section": "Load packages",
    "text": "Load packages\n\n# load required packages here"
  },
  {
    "objectID": "course-materials/exams/exam-02/exam-02.html#questions",
    "href": "course-materials/exams/exam-02/exam-02.html#questions",
    "title": "SAMPLE TAKE HOME EXAM - STUDENT TEMPLATE",
    "section": "Questions",
    "text": "Questions\n\nQuestion 1\n[Enter code and/or narrative here.]\n\n\nQuestion 2\n[Enter code and/or narrative here.]\n\n\nQuestion 3\n[Enter code and/or narrative here.]\n…\n[Add headers for subsequent questions as needed.]\n\n\nExtra Credit\n[Enter code and narrative here.]"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-09/lab-09-better-viz.html",
    "href": "course-materials/lab-instructions/lab-09/lab-09-better-viz.html",
    "title": "Lab 09 - Conveying the right message through visualisation",
    "section": "",
    "text": "In this lab our goal is to reconstruct and improve a data visualisation on COVID and mask wearing."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-09/lab-09-better-viz.html#warm-up",
    "href": "course-materials/lab-instructions/lab-09/lab-09-better-viz.html#warm-up",
    "title": "Lab 09 - Conveying the right message through visualisation",
    "section": "Warm up",
    "text": "Warm up\nLet’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-09/lab-09-better-viz.html#packages",
    "href": "course-materials/lab-instructions/lab-09/lab-09-better-viz.html#packages",
    "title": "Lab 09 - Conveying the right message through visualisation",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation. This package is already installed for you. You can load it by running the following in your Console:\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-09/lab-09-better-viz.html#data",
    "href": "course-materials/lab-instructions/lab-09/lab-09-better-viz.html#data",
    "title": "Lab 09 - Conveying the right message through visualisation",
    "section": "Data",
    "text": "Data\nIn this lab you’ll construct the dataset!"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-01/lab-01-hello-r.html",
    "href": "course-materials/lab-instructions/lab-01/lab-01-hello-r.html",
    "title": "Lab 01 - Hello R!",
    "section": "",
    "text": "R is the name of the programming language itself and RStudio is a convenient interface.\nThe main goal of this lab is to introduce you to R and RStudio, which we will be using throughout the course both to learn the statistical concepts discussed in the course and to analyze real data and come to informed conclusions.\ngit is a version control system (like \"Track Changes\" features from Microsoft Word on steroids) and GitHub is the home for your Git-based projects on the internet (like DropBox but much, much better).\nAn additional goal is to introduce you to Git and GitHub, which is the collaboration and version control system that we will be using throughout the course.\nAs the labs progress, you are encouraged to explore beyond what the labs dictate; a willingness to experiment will make you a much better programmer. Before we get to that stage, however, you need to build some basic fluency in R. Today we begin with the fundamental building blocks of R and RStudio: the interface, reading in data, and basic commands.\nAnd to make versioning simpler, this is a solo lab. Additionally, we want to make sure everyone gets a significant amount of time at the steering wheel. In future labs you’ll learn about collaborating on GitHub and produce a single lab report for your team."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-01/lab-01-hello-r.html#warm-up",
    "href": "course-materials/lab-instructions/lab-01/lab-01-hello-r.html#warm-up",
    "title": "Lab 01 - Hello R!",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises.\n\nThe top portion of your R Markdown file (between the three dashed lines) is called YAML. It stands for \"YAML Ain't Markup Language\". It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\n\nYAML\nOpen the R Markdown (Rmd) file in your project, change the author name to your name, and knit the document.\n\n\n\n\n\n\n\n\n\n\n\nCommitting changes\nThen go to the Git pane in your RStudio.\nIf you have made changes to your Rmd file, you should see it listed here. Click on it to select it in this list and then click on Diff. This shows you the difference between the last committed state of the document and its current state that includes your changes. If you’re happy with these changes, write “Update author name” in the Commit message box and hit Commit.\n\n\n\n\n\n\n\n\n\nYou don’t have to commit after every change, this would get quite cumbersome. You should consider committing states that are meaningful to you for inspection, comparison, or restoration. In the first few assignments we will tell you exactly when to commit and in some cases, what commit message to use. As the semester progresses we will let you make these decisions.\n\n\nPushing changes\nNow that you have made an update and committed this change, it’s time to push these changes to the web! Or more specifically, to your repo on GitHub. Why? So that others can see your changes. And by others, we mean the course teaching team (your repos in this course are private to you and us, only).\nIn order to push your changes to GitHub, click on Push. This will prompt a dialogue box where you first need to enter your user name, and then your password. This might feel cumbersome. Bear with me… We will teach you how to save your password so you don’t have to enter it every time. But for this one assignment you’ll have to manually enter each time you push in order to gain some experience with it."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-01/lab-01-hello-r.html#packages",
    "href": "course-materials/lab-instructions/lab-01/lab-01-hello-r.html#packages",
    "title": "Lab 01 - Hello R!",
    "section": "Packages",
    "text": "Packages\nIn this lab we will work with two packages: datasauRus which contains the dataset we’ll be using and tidyverse which is a collection of packages for doing data analysis in a “tidy” way. These packages are already installed for you. You can load the packages by running the following in the Console.\n\nlibrary(tidyverse) \nlibrary(datasauRus)\n\nNote that the packages are also loaded with the same commands in your R Markdown document."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-01/lab-01-hello-r.html#data",
    "href": "course-materials/lab-instructions/lab-01/lab-01-hello-r.html#data",
    "title": "Lab 01 - Hello R!",
    "section": "Data",
    "text": "Data\n\nIf it's confusing that the data frame is called `datasaurus_dozen` when it contains 13 datasets, you're not alone! Have you heard of a [baker's dozen](https://en.wikipedia.org/wiki/Dozen#Baker's_dozen)?\n\nThe data frame we will be working with today is called datasaurus_dozen and it’s in the datasauRus package. Actually, this single data frame contains 13 datasets, designed to show us why data visualisation is important and how summary statistics alone can be misleading. The different datasets are marked by the dataset variable.\nTo find out more about the dataset, type the following in your Console: ?datasaurus_dozen. A question mark before the name of an object will always bring up its help file. This command must be ran in the Console."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "",
    "text": "The University of Edinburgh Art Collection “supports the world-leading research and teaching that happens within the University. Comprised of an astonishing range of objects and ideas spanning two millennia and a multitude of artistic forms, the collection reflects not only the long and rich trajectory of the University, but also major national and international shifts in art history.”1.\nSee the sidebar [here](https://collections.ed.ac.uk/art) and note that there are 2970 pieces in the art collection we're collecting data on. Note that more pieces may have been added or some pieces may have been removed between when this lab was written and when you're working on it.\nIn this lab we’ll scrape data on all art pieces in the Edinburgh College of Art collection."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#r-scripts-vs.-r-markdown-documents",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#r-scripts-vs.-r-markdown-documents",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "R scripts vs. R Markdown documents",
    "text": "R scripts vs. R Markdown documents\nToday we will be using both R scripts and R Markdown documents:\n\n.R: R scripts are plain text files containing only code and brief comments,\n\nWe’ll use R scripts in the web scraping stage and ultimately save the scraped data as a csv.\n\n.Rmd: R Markdown documents are plain text files containing.\n\nWe’ll use an R Markdown document in the web analysis stage, where we start off by reading in the csv file we wrote out in the scraping stage.\n\n\nHere is the organization of your repo, and the corresponding section in the lab that each file will be used for:"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#warm-up",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#warm-up",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Warm up",
    "text": "Warm up\nLet’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#packages",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#packages",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation, the robotstxt package to check if we’re allowed to scrape the data, the rvest package for data scraping. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(robotstxt)\nlibrary(rvest)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#data",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#data",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Data",
    "text": "Data\nThis assignment does not come with any prepared datasets. Instead you’ll be scraping the data! But before doing so, let’s check that a bot has permissions to access pages on this domain.\n\npaths_allowed(\"https://collections.ed.ac.uk/art)\")\n\n\n collections.ed.ac.uk                      \n\n\n[1] TRUE"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#scraping-a-single-page",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#scraping-a-single-page",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Scraping a single page",
    "text": "Scraping a single page\n\n**Tip:** To run the code you can highlight or put your cursor next to the lines of code you want to run and hit Command+Enter.\n\n\nWork in scripts/01-scrape-page-one.R.\n\nWe will start off by scraping data on the first 10 pieces in the collection from here.\nFirst, we define a new object called first_url, which is the link above. Then, we read the page at this url with the read_html() function from the rvest package. The code for this is already provided in 01-scrape-page-one.R.\n\n# set url\nfirst_url &lt;- \"https://collections.ed.ac.uk/art/search/*:*/Collection:%22edinburgh+college+of+art%7C%7C%7CEdinburgh+College+of+Art%22?offset=0\"\n\n# read html page\npage &lt;- read_html(first_url)\n\nFor the ten pieces on this page we will extract title, artist, and link information, and put these three variables in a data frame.\n\nTitles\nLet’s start with titles. We make use of the SelectorGadget to identify the tags for the relevant nodes:\n\n\n\n\n\n\n\n\n\n\npage %&gt;%\n  html_nodes(\".iteminfo\") %&gt;%\n  html_node(\"h3 a\")\n\n{xml_nodeset (10)}\n [1] &lt;a href=\"./record/20610?highlight=*:*\"&gt;Mourner No. 54 from the Tomb of J ...\n [2] &lt;a href=\"./record/50603?highlight=*:*\"&gt;Unknown                           ...\n [3] &lt;a href=\"./record/21414?highlight=*:*\"&gt;Portrait of a Woman               ...\n [4] &lt;a href=\"./record/122781?highlight=*:*\"&gt;Still Life with Jugs and Milk Bo ...\n [5] &lt;a href=\"./record/21846?highlight=*:*\"&gt;John Mooney Paintings             ...\n [6] &lt;a href=\"./record/20736?highlight=*:*\"&gt;Female Nude with Pitcher          ...\n [7] &lt;a href=\"./record/21790?highlight=*:*\"&gt;West Coast Seascape               ...\n [8] &lt;a href=\"./record/21566?highlight=*:*\"&gt;Untitled                          ...\n [9] &lt;a href=\"./record/102679?highlight=*:*\"&gt;Ayrshire christening robe        ...\n[10] &lt;a href=\"./record/22475?highlight=*:*\"&gt;Untitled                          ...\n\n\nThen we extract the text with html_text():\n\npage %&gt;%\n  html_nodes(\".iteminfo\") %&gt;%\n  html_node(\"h3 a\") %&gt;%\n  html_text()\n\n [1] \"Mourner No. 54 from the Tomb of John the fearless                                                                            (Pre 1895)\"\n [2] \"Unknown                                                                            (1955)\"                                              \n [3] \"Portrait of a Woman                                                                            (Feb 1952)\"                              \n [4] \"Still Life with Jugs and Milk Bottle                                                                            (Circa 1962)\"           \n [5] \"John Mooney Paintings                                                                            (1984)\"                                \n [6] \"Female Nude with Pitcher                                    \"                                                                           \n [7] \"West Coast Seascape                                                                            (Unknown)\"                               \n [8] \"Untitled                                                                            (Unknown)\"                                          \n [9] \"Ayrshire christening robe                                                                            (1800-1899)\"                       \n[10] \"Untitled                                                                            (1967)\"                                             \n\n\nAnd get rid of all the spurious white space in the text with str_squish(), which reduces repeated whitespace inside a string.\n\nTake a look at the help for `str_squish()` to find out more about how it works and how it's different from `str_trim()`.\n\n\npage %&gt;%\n  html_nodes(\".iteminfo\") %&gt;%\n  html_node(\"h3 a\") %&gt;%\n  html_text() %&gt;%\n  str_squish()\n\n [1] \"Mourner No. 54 from the Tomb of John the fearless (Pre 1895)\"\n [2] \"Unknown (1955)\"                                              \n [3] \"Portrait of a Woman (Feb 1952)\"                              \n [4] \"Still Life with Jugs and Milk Bottle (Circa 1962)\"           \n [5] \"John Mooney Paintings (1984)\"                                \n [6] \"Female Nude with Pitcher\"                                    \n [7] \"West Coast Seascape (Unknown)\"                               \n [8] \"Untitled (Unknown)\"                                          \n [9] \"Ayrshire christening robe (1800-1899)\"                       \n[10] \"Untitled (1967)\"                                             \n\n\nAnd finally save the resulting data as a vector of length 10:\n\ntitles &lt;- page %&gt;%\n  html_nodes(\".iteminfo\") %&gt;%\n  html_node(\"h3 a\") %&gt;%\n  html_text() %&gt;%\n  str_squish()\n\n\n\nLinks\nThe same nodes that contain the text for the titles also contains information on the links to individual art piece pages for each title. We can extract this information using a new function from the rvest package, html_attr(), which extracts attributes.\nA mini HTML lesson! The following is how we define hyperlinked text in HTML:\n&lt;a href=\"https://www.google.com\"&gt;Seach on Google&lt;/a&gt;\nAnd this is how the text would look like on a webpage: Seach on Google.\nHere the text is Seach on Google and the href attribute contains the url of the website you’d go to if you click on the hyperlinked text: https://www.google.com.\nThe moral of the story is: the link is stored in the href attribute.\n\npage %&gt;%\n  html_nodes(\".iteminfo\") %&gt;%   # same nodes\n  html_node(\"h3 a\") %&gt;%         # as before\n  html_attr(\"href\")             # but get href attribute instead of text\n\n [1] \"./record/20610?highlight=*:*\"  \"./record/50603?highlight=*:*\" \n [3] \"./record/21414?highlight=*:*\"  \"./record/122781?highlight=*:*\"\n [5] \"./record/21846?highlight=*:*\"  \"./record/20736?highlight=*:*\" \n [7] \"./record/21790?highlight=*:*\"  \"./record/21566?highlight=*:*\" \n [9] \"./record/102679?highlight=*:*\" \"./record/22475?highlight=*:*\" \n\n\nThese don’t really look like URLs as we know then though. They’re relative links.\n\nSee the help for `str_replace()` to find out how it works. Remember that the first argument is passed in from the pipeline, so you just need to define the `pattern` and `replacement` arguments.\n\n\nClick on one of art piece titles in your browser and take note of the url of the webpage it takes you to. Think about how that url compares to what we scraped above? How is it different? Using str_replace(), fix the URLs. You’ll note something special happening in the pattern to replace. We want to replace the ., but we have it as \\\\.. This is because the period . is a special character and so we need to escape it first with backslashes, \\\\s.\n\n\n\nArtists\n\nFill in the blanks to scrape artist names.\n\n\n\nPut it altogether\n\nFill in the blanks to organize everything in a tibble.\n\n\n\nScrape the next page\n\nClick on the next page, and grab its url. Fill in the blank in to define a new object: second_url. Copy-paste code from top of the R script to scrape the new set of art pieces, and save the resulting data frame as second_ten.\n\n✅ ⬆️ If you haven’t done so recently, commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#functions",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#functions",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Functions",
    "text": "Functions\n\nWork in scripts/02-scrape-page-function.R.\n\nYou’ve been using R functions, now it’s time to write your own!\nLet’s start simple. Here is a function that takes in an argument x, and adds 2 to it.\n\nadd_two &lt;- function(x){\n  x + 2\n}\n\nLet’s test it:\n\nadd_two(3)\n\n[1] 5\n\nadd_two(10)\n\n[1] 12\n\n\nThe skeleton for defining functions in R is as follows:\n\nfunction_name &lt;- function(input){\n  # do something with the input(s)\n  # return something\n}\n\nThen, a function for scraping a page should look something like:\n\n**Reminder:** Function names should be short but evocative verbs.\n\n\nfunction_name &lt;- function(url){\n  # read page at url\n  # extract title, link, artist info for n pieces on page\n  # return a n x 3 tibble\n}\n\n\nFill in the blanks using code you already developed in the previous exercises. Name the function scrape_page.\n\nTest out your new function by running the following in the console. Does the output look right? Discuss with teammates whether you’re getting the same results as before.\n\nscrape_page(first_url)\nscrape_page(second_url)\n\n✅ ⬆️ If you haven’t done so recently, commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#iteration",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#iteration",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Iteration",
    "text": "Iteration\n\nWork in scripts/03-scrape-page-many.R.\n\nWe went from manually scraping individual pages to writing a function to do the same. Next, we will work on making our workflow a little more efficient by using R to iterate over all pages that contain information on the art collection.\n\n**Reminder:** The collection has 2970 pieces in total.\n\nThat means we give develop a list of URLs (of pages that each have 10 art pieces), and write some code that applies the scrape_page() function to each page, and combines the resulting data frames from each page into a single data frame with 2970 rows and 3 columns.\n\nList of URLs\nClick through the first few of the pages in the art collection and observe their URLs to confirm the following pattern:\n[sometext]offset=0     # Pieces 1-10\n[sometext]offset=10    # Pieces 11-20\n[sometext]offset=20    # Pieces 21-30\n[sometext]offset=30    # Pieces 31-40\n...\n[sometext]offset=2960  # Pieces 2961-2970\nWe can construct these URLs in R by pasting together two pieces: (1) a common (root) text for the beginning of the URL, and (2) numbers starting at 0, increasing by 10, all the way up to 2970. Two new functions are helpful for accomplishing this: glue() for pasting two pieces of text and seq() for generating a sequence of numbers.\n\nFill in the blanks to construct the list of URLs.\n\n\n\nMapping\nFinally, we’re ready to iterate over the list of URLs we constructed. We will do this by mapping the function we developed over the list of URLs. There are a series of mapping functions in R (which we’ll learn about in more detail tomorrow), and they each take the following form:\nmap([x], [function to apply to each element of x])\nIn our case x is the list of URLs we constructed and the function to apply to each element of x is the function we developed earlier, scrape_page. And as a result we want a data frame, so we use map_dfr function:\n\nmap_dfr(urls, scrape_page)\n\n\nFill in the blanks to scrape all pages, and to create a new data frame called uoe_art.\n\n\n\nWrite out data\n\nFinally write out the data frame you constructed into the data folder so that you can use it in the analysis section.\n\n\nAim to make it to this point during the workshop.\n\n✅ ⬆️ If you haven’t done so recently, commit and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#analysis",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#analysis",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Analysis",
    "text": "Analysis\n\nWork in lab-08.Rmd for the rest of the lab.\n\nNow that we have a tidy dataset that we can analyze, let’s do that!\nWe’ll start with some data cleaning, to clean up the dates that appear at the end of some title text in parentheses. Some of these are years, others are more specific dates, some art pieces have no date information whatsoever, and others have some non-date information in parentheses. This should be interesting to clean up!\nFirst thing we’ll try is to separate the title column into two: one for the actual title and the other for the date if it exists. In human speak, we need to\n\n“separate the title column at the first occurrence of ( and put the contents on one side of the ( into a column called title and the contents on the other side into a column called date”\n\nLuckily, there’s a function that does just this: separate()!\nAnd once we have completed separating the single title column into title and date, we need to do further clean-up in the date column to get rid of extraneous )s with str_remove(), capture year information, and save the data as a numeric variable.\n\n**Hint:** Remember escaping special characters from yesterday's lecture? You'll need to use that trick again.\n\n\nFill in the blanks in to implement the data wrangling we described above. Note that this will result in some warnings when you run the code, and that’s OK! Read the warnings, and explain what they mean, and why we are ok with leaving them in given that our objective is to just capture year where it’s convenient to do so.\nPrint out a summary of the data frame using the skim() function. How many pieces have artist info missing? How many have year info missing?\nMake a histogram of years. Use a reasonable binwidth. Do you see anything out of the ordinary?\n\n\n**Hint:** You'll want to use `mutate()` and `if_else()` or `case_when()` to implement the correction.\n\n\nFind which piece has the out of the ordinary year and go to its page on the art collection website to find the correct year for it. Can you tell why our code didn’t capture the correct year information? Correct the error in the data frame and visualize the data again.\n\n🧶 ✅ ⬆️ If you haven’t done so recently, knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.\n\nWho is the most commonly featured artist in the collection? Do you know them? Any guess as to why the university has so many pieces from them?\n\n\n**Hint:** `str_subset()` can be helful here. You should consider how you might capture titles where the word appears as \"child\" and \"Child\".\n\n\nFinal question! How many art pieces have the word “child” in their title? Try to figure it out, and ask for help if you’re stuck.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#footnotes",
    "href": "course-materials/lab-instructions/lab-08/lab-08-uoe-art.html#footnotes",
    "title": "Lab 08 - University of Edinburgh Art Collection",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSource: https://collections.ed.ac.uk/art/about↩︎"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-13/lab-13-work-on-projects.html",
    "href": "course-materials/lab-instructions/lab-13/lab-13-work-on-projects.html",
    "title": "Lab 13 - Work on projects",
    "section": "",
    "text": "This week you’ll be working on your projects. Here are a few to do items to get you started. Once you complete these, use the rest of the time to, well, work on your project!\n\nRemind yourself of the project assignment\nGo to the course organization on GitHub and clone your project repo titled project-TEAM_NAME\nAdd your project title and team name to the README.Rmd file in the repo and commit and push your changes. Observe that these are updated in the README of the repo.\nOpen the presentation.Rmd file, knit the document, and review the presentation format. This is where your presentation will go. Update the YAML with your project title, team name, etc. and commit and push your changes.\nGo to your project repo on GitHub, click on Settings on the top right corner, and scroll down to the section titled GiHub Pages. Under Source, select main branch and the root folder. This will give you a URL where the website for your project will be automatically built from the content in your README. This might take a few minutes.\n\nOnce the website is built, pull changes to your project in RStudio.\nTake a look at your rendered project website. Click on the link in the presentation section and you should be able to view the rendered slides. This is the link we will use to project your slides during the presentations.\nOn your repo you should see a text on top No description, website, or topics provided.. Next to it there’s an Edit button. Add a short description as well as the URL of your project website here.\nNote: This website is public, but your repository will remain private,unless… you as a team decide you would like to feature your repos in your personal GitHub profiles. If so, I will help you convert your repo to a public repo at the end of the semester. I will not add any marks to your repos so that your public work won’t contain your score for the project.\n\nAdd your dataset to the data folder and add your codebook to the README in that folder.\n\nIf in your proposal you were advised to update your codebook, make sure to make those updates.\nIf you had R scripts you used to scrape your data, add them to this folder as well.\n\nAdd the content from your proposal to the proposal.Rmd file in the proposal folder. Knit the document to make sure everything works and commit and push your proposal to your project repo.\n\nImportant: Your data now lives in a folder called data that is not inside your proposal folder. So you need to specify the path to your data with \"../data/name_of_datafile\" in your read_csv() (or similar) function.\nYou don’t need to make further updates to your proposal at this point, even if your plans for the project change slightly.\n\nLoad your data in your presentation.Rmd, knit, and make sure everything works. Commit and push your updated proposal to your project repo.\n\nImportant: Same note as above! Your data now lives in a folder called data that is not inside your presentation folder. So you need to specify the path to your data with \"../data/name_of_datafile\" in your read_csv() (or similar) function.\n\nNow that all the logistical details are done, start working on your project.\n\nOpen issues for things you want to accomplish. Assign them to specific team member(s) if you like. And as you complete the tasks, close the issues. You can also use the issues for discussion on the specific tasks.\n\nStrongly recommended: Get a hold of the instructor or a TA and run your ideas by them."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html",
    "title": "Lab 03 - Nobel laureates",
    "section": "",
    "text": "In January 2017, Buzzfeed published an article on why Nobel laureates show immigration is so important for American science. You can read the article here. In the article they show that while most living Nobel laureates in the sciences are based in the US, many of them were born in other countries. This is one reason why scientific leaders say that immigration is vital for progress. In this lab we will work with the data from this article to recreate some of their visualizations as well as explore new questions."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#merges-and-merge-conflicts",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#merges-and-merge-conflicts",
    "title": "Lab 03 - Nobel laureates",
    "section": "Merges and merge conflicts",
    "text": "Merges and merge conflicts\nThis is the second week you’re working in teams, so we’re going to make things a little more interesting and let all of you make changes and push those changes to your team repository. Sometimes things will go swimmingly, and sometimes you’ll run into merge conflicts. So our first task today is to walk you through a merge conflict!\n\nPushing to a repo replaces the code on GitHub with the code you have on your computer.\nIf a collaborator has made a change to your repo on GitHub that you haven’t incorporated into your local work, GitHub will stop you from pushing to the repo because this could overwrite your collaborator’s work!\nSo you need to explicitly “merge” your collaborator’s work before you can push.\nIf your and your collaborator’s changes are in different files or in different parts of the same file, git merges the work for you automatically when you *pull*.\nIf you both changed the same part of a file, git will produce a **merge conflict** because it doesn’t know how which change you want to keep and which change you want to overwrite.\n\nGit will put conflict markers in your code that look like:\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD \n\nSee also: [dplyr documentation](https://dplyr.tidyverse.org/)   \n\n======= \n\nSee also [ggplot2 documentation](https://ggplot2.tidyverse.org/)  \n\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; some1alpha2numeric3string4\nThe ===s separate your changes (top) from their changes (bottom).\nNote that on top you see the word HEAD, which indicates that these are your changes.\nAnd at the bottom you see some1alpha2numeric3string4 (well, it probably looks more like 28e7b2ceb39972085a0860892062810fb812a08f).\nThis is the hash (a unique identifier) of the commit your collaborator made with the conflicting change.\nYour job is to reconcile the changes: edit the file so that it incorporates the best of both versions and delete the &lt;&lt;&lt;, ===, and &gt;&gt;&gt; lines. Then you can stage and commit the result."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#setup",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#setup",
    "title": "Lab 03 - Nobel laureates",
    "section": "Setup",
    "text": "Setup\n\nClone the repo and open the .Rmd file.\nAssign the numbers 1, 2, 3, and 4 to each of the team members. If your team has fewer than 4 people, some people will need to have multiple numbers. If your team has more than 4 people, some people will need to share some numbers."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#lets-cause-a-merge-conflict",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#lets-cause-a-merge-conflict",
    "title": "Lab 03 - Nobel laureates",
    "section": "Let’s cause a merge conflict!",
    "text": "Let’s cause a merge conflict!\nOur goal is to see two different types of merges: first we’ll see a type of merge that git can’t figure out on its own how to do on its own (a merge conflict) and requires human intervention, then another type of where that git can figure out how to do without human intervention.\nDoing this will require some tight choreography, so pay attention!\nTake turns in completing the exercise, only one member at a time. Others should just watch, not doing anything on their own projects (this includes not even pulling changes!) until they are instructed to. If you feel like you won’t be able to resist the urge to touch your computer when it’s not your turn, we recommend putting your hands in your pockets or sitting on them!\nBefore starting: everyone should have the repo cloned and know which role number(s) they are.\nRole 1:\n\nChange the team name to your actual team name.\nKnit, commit, push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nRole 2:\n\nChange the team name to some other word.\nKnit, commit, push. You should get an error.\nPull. Take a look at the document with the merge conflict.\nClear the merge conflict by editing the document to choose the correct/preferred change.\nKnit.\nClick the Stage checkbox for all files in your Git tab. Make sure they all have check marks, not filled-in boxes.\nCommit and push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nRole 3:\n\nChange the a label of the first code chunk\nKnit, commit, push. You should get an error.\nPull. No merge conflicts should occur, but you should see a message about merging.\nNow push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nRole 4:\n\nChange the label of the first code chunk to something other than previous role did.\nKnit, commit, push. You should get an error.\nPull. Take a look at the document with the merge conflict. Clear the merge conflict by choosing the correct/preferred change. Commit, and push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nEveryone: Pull, and observe the changes in your document."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#tips-for-collaborating-via-github",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#tips-for-collaborating-via-github",
    "title": "Lab 03 - Nobel laureates",
    "section": "Tips for collaborating via GitHub",
    "text": "Tips for collaborating via GitHub\n\nAlways pull first before you start working.\nResolve a merge conflict (commit and push) before continuing your work. Never do new work while resolving a merge conflict.\nKnit, commit, and push often to minimize merge conflicts and/or to make merge conflicts easier to resolve.\nIf you find yourself in a situation that is difficult to resolve, ask questions ASAP. Don’t let it linger and get bigger."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#warm-up",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#warm-up",
    "title": "Lab 03 - Nobel laureates",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and knit the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#packages",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#packages",
    "title": "Lab 03 - Nobel laureates",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling. This package is already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#data",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#data",
    "title": "Lab 03 - Nobel laureates",
    "section": "Data",
    "text": "Data\nThe dataset for this assignment can be found as a CSv (comma separated values) file in the data folder of your repository. You can read it in using the following.\n\nnobel &lt;- read_csv(\"data/nobel.csv\")\n\nThe variable descriptions are as follows:\n\nid: ID number\nfirstname: First name of laureate\nsurname: Surname\nyear: Year prize won\ncategory: Category of prize\naffiliation: Affiliation of laureate\ncity: City of laureate in prize year\ncountry: Country of laureate in prize year\nborn_date: Birth date of laureate\ndied_date: Death date of laureate\ngender: Gender of laureate\nborn_city: City where laureate was born\nborn_country: Country where laureate was born\nborn_country_code: Code of country where laureate was born\ndied_city: City where laureate died\ndied_country: Country where laureate died\ndied_country_code: Code of country where laureate died\noverall_motivation: Overall motivation for recognition\nshare: Number of other winners award is shared with\nmotivation: Motivation for recognition\n\nIn a few cases the name of the city/country changed after laureate was given (e.g. in 1975 Bosnia and Herzegovina was called the Socialist Federative Republic of Yugoslavia). In these cases the variables below reflect a different name than their counterparts without the suffix `_original`.\n\nborn_country_original: Original country where laureate was born\nborn_city_original: Original city where laureate was born\ndied_country_original: Original country where laureate died\ndied_city_original: Original city where laureate died\ncity_original: Original city where laureate lived at the time of winning the award\ncountry_original: Original country where laureate lived at the time of winning the award"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#get-to-know-your-data",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#get-to-know-your-data",
    "title": "Lab 03 - Nobel laureates",
    "section": "Get to know your data",
    "text": "Get to know your data\n\nHow many observations and how many variables are in the dataset? Use inline code to answer this question. What does each row represent?\n\nThere are some observations in this dataset that we will exclude from our analysis to match the Buzzfeed results.\n\nCreate a new data frame called nobel_living that filters for\n\n\nlaureates for whom country is available\nlaureates who are people as opposed to organizations (organizations are denoted with \"org\" as their gender)\nlaureates who are still alive (their died_date is NA)\n\nConfirm that once you have filtered for these characteristics you are left with a data frame with 228 observations, once again using inline code.\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#most-living-nobel-laureates-were-based-in-the-us-when-they-won-their-prizes",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#most-living-nobel-laureates-were-based-in-the-us-when-they-won-their-prizes",
    "title": "Lab 03 - Nobel laureates",
    "section": "Most living Nobel laureates were based in the US when they won their prizes",
    "text": "Most living Nobel laureates were based in the US when they won their prizes\n… says the Buzzfeed article. Let’s see if that’s true.\nFirst, we’ll create a new variable to identify whether the laureate was in the US when they won their prize. We’ll use the mutate() function for this. The following pipeline mutates the nobel_living data frame by adding a new variable called country_us. We use an if statement to create this variable. The first argument in the if_else() function we’re using to write this if statement is the condition we’re testing for. If country is equal to \"USA\", we set country_us to \"USA\". If not, we set the country_us to \"Other\".\n\nNote that we can achieve the same result using the `fct_other()` function we've seen before (i.e. with `country_us = fct_other(country, \"USA\")`). We decided to use the `if_else()` here to show you one example of an if statement in R.\n\n\nnobel_living &lt;- nobel_living %&gt;%\n  mutate(\n    country_us = if_else(country == \"USA\", \"USA\", \"Other\")\n  )\n\nNext, we will limit our analysis to only the following categories: Physics, Medicine, Chemistry, and Economics.\n\nnobel_living_science &lt;- nobel_living %&gt;%\n  filter(category %in% c(\"Physics\", \"Medicine\", \"Chemistry\", \"Economics\"))\n\nFor the next exercise work with the nobel_living_science data frame you created above. This means you’ll need to define this data frame in your R Markdown document, even though the next exercise doesn’t explicitly ask you to do so.\n\nCreate a faceted bar plot visualizing the relationship between the category of prize and whether the laureate was in the US when they won the nobel prize. Interpret your visualization, and say a few words about whether the Buzzfeed headline is supported by the data.\n\nYour visualization should be faceted by category.\nFor each facet you should have two bars, one for winners in the US and one for Other.\nFlip the coordinates so the bars are horizontal, not vertical.\n\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.d"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#but-of-those-us-based-nobel-laureates-many-were-born-in-other-countries",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#but-of-those-us-based-nobel-laureates-many-were-born-in-other-countries",
    "title": "Lab 03 - Nobel laureates",
    "section": "But of those US-based Nobel laureates, many were born in other countries",
    "text": "But of those US-based Nobel laureates, many were born in other countries\n\n**Hint:** You should be able to ~~cheat~~ borrow from code you used earlier to create the `country_us` variable.\n\n\nCreate a new variable called born_country_us that has the value \"USA\" if the laureate is born in the US, and \"Other\" otherwise. How many of the winners are born in the US?\nAdd a second variable to your visualization from Exercise 3 based on whether the laureate was born in the US or not. Based on your visualization, do the data appear to support Buzzfeed’s claim? Explain your reasoning in 1-2 sentences.\n\nYour final visualization should contain a facet for each category.\nWithin each facet, there should be a bar for whether the laureate won the award in the US or not.\nEach bar should have segments for whether the laureate was born in the US or not.\n\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#heres-where-those-immigrant-nobelists-were-born",
    "href": "course-materials/lab-instructions/lab-03/lab-03-nobel-laureates.html#heres-where-those-immigrant-nobelists-were-born",
    "title": "Lab 03 - Nobel laureates",
    "section": "Here’s where those immigrant Nobelists were born",
    "text": "Here’s where those immigrant Nobelists were born\n\nNote that your bar plot won't exactly match the one from the Buzzfeed article. This is likely because the data has been updated since the article was published.\n\n\nIn a single pipeline, filter for laureates who won their prize in the US, but were born outside of the US, and then create a frequency table (with the count() function) for their birth country (born_country) and arrange the resulting data frame in descending order of number of observations for each country. Which country is the most common?\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work.\nNow go back through your write up to make sure you’ve answered all questions and all of your R chunks are properly labelled. Once you decide as a team that you’re done with this lab, all members of the team should pull the changes and knit the R Markdown document to confirm that they can reproduce the report."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html",
    "href": "course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html",
    "title": "Lab 05 - La Quinta is Spanish for next to Denny’s, Pt. 2",
    "section": "",
    "text": "In this lab we revisit the Denny’s and La Quinta Inn and Suites data we visualized in the previous lab."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html#warm-up",
    "href": "course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html#warm-up",
    "title": "Lab 05 - La Quinta is Spanish for next to Denny’s, Pt. 2",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html#packages",
    "href": "course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html#packages",
    "title": "Lab 05 - La Quinta is Spanish for next to Denny’s, Pt. 2",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html#data",
    "href": "course-materials/lab-instructions/lab-05/lab-05-wrangle-sp-data.html#data",
    "title": "Lab 05 - La Quinta is Spanish for next to Denny’s, Pt. 2",
    "section": "Data",
    "text": "Data\nRemember that the datasets we’ll use are called dennys and laquinta from the dsbox package. Since the datasets are distributed with the package, we don’t need to load them separately; they become available to us when we load the package. You can find out more about the datasets by inspecting their documentation, which you can access by running ?dennys and ?laquinta in the Console or using the Help menu in RStudio to search for dennys or laquinta. You can also find this information here and here."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html",
    "href": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "",
    "text": "In this lab we revisit the professor evaluations data we modelled in the previous lab. In the last lab we modelled evaluation scores using a single predictor at a time. This time we will use multiple predictors to model evaluation scores.\nFor context, review the previous lab’s introduction before continuing on to the exercises."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#warm-up",
    "href": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#warm-up",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "Warm up",
    "text": "Warm up\nLet’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#packages",
    "href": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#packages",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation, the tidymodels package for modeling and inference, and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse) \nlibrary(tidymodels)\nlibrary(openintro)"
  },
  {
    "objectID": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#data",
    "href": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#data",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "Data",
    "text": "Data\nThe data can be found in the openintro package, and it’s called evals. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?evals in the Console or using the Help menu in RStudio to search for evals. You can also find this information here."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#simple-linear-regression",
    "href": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#simple-linear-regression",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "Simple linear regression",
    "text": "Simple linear regression\n\nFit a linear model (one you have fit before): score_bty_fit, predicting average professor evaluation score based on average beauty rating (bty_avg) only. Write the linear model, and note the \\(R^2\\) and the adjusted \\(R^2\\).\n\n🧶 ✅ ⬆️ If you haven’t done so recently, knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#multiple-linear-regression",
    "href": "course-materials/lab-instructions/lab-11/lab-11-mlr-course-evals.html#multiple-linear-regression",
    "title": "Lab 11 - Grading the professor, Pt. 2",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\n\nFit a linear model (one you have fit before): score_bty_gen_fit, predicting average professor evaluation score based on average beauty rating (bty_avg) and gender. Write the linear model, and note the \\(R^2\\) and the adjusted \\(R^2\\).\nInterpret the slopes and intercept of score_bty_gen_fit in context of the data.\nWhat percent of the variability in score is explained by the model score_bty_gen_fit.\nWhat is the equation of the line corresponding to just male professors?\nFor two professors who received the same beauty rating, which gender tends to have the higher course evaluation score?\nHow does the relationship between beauty and evaluation score vary between male and female professors?\nHow do the adjusted \\(R^2\\) values of score_bty_gen_fit and score_bty_fit compare? What does this tell us about how useful gender is in explaining the variability in evaluation scores when we already have information on the beauty score of the professor.\nCompare the slopes of bty_avg under the two models (score_bty_fit and score_bty_gen_fit). Has the addition of gender to the model changed the parameter estimate (slope) for bty_avg?\nCreate a new model called score_bty_rank_fit with gender removed and rank added in. Write the equation of the linear model and interpret the slopes and intercept in context of the data.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html",
    "title": "HW 04 - What should I major in?",
    "section": "",
    "text": "Photo by Marleena Garris on Unsplash\nThe first step in the process of turning information into knowledge process is to summarize and describe the raw information - the data. In this assignment we explore data on college majors and earnings, specifically the data begin the FiveThirtyEight story “The Economic Guide To Picking A College Major”.\nThese data originally come from the American Community Survey (ACS) 2010-2012 Public Use Microdata Series. While this is outside the scope of this assignment, if you are curious about how raw data from the ACS were cleaned and prepared, see the code FiveThirtyEight authors used.\nWe should also note that there are many considerations that go into picking a major. Earnings potential and employment prospects are two of them, and they are important, but they don’t tell the whole story. Keep this in mind as you analyze the data."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#warm-up",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#warm-up",
    "title": "HW 04 - What should I major in?",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and knit the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#packages",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#packages",
    "title": "HW 04 - What should I major in?",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation, the scales package for better formatting of labels on visualisations, and the data lives in the fivethirtyeight package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(fivethirtyeight)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#data",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#data",
    "title": "HW 04 - What should I major in?",
    "section": "Data",
    "text": "Data\nThe data can be found in the fivethirtyeight package, and it’s called college_recent_grads. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?college_recent_grads in the Console or using the Help menu in RStudio to search for college_recent_grads. You can also find this information here.\nYou can also take a quick peek at your data frame and view its dimensions with the glimpse function.\n\nglimpse(college_recent_grads)\n\nThe college_recent_grads data frame is a trove of information. Let’s think about some questions we might want to answer with these data:\n\nWhich major has the lowest unemployment rate?\nWhich major has the highest percentage of women?\nHow do the distributions of median income compare across major categories?\nDo women tend to choose majors with lower or higher earnings?\n\nIn the next section we aim to answer these questions."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#which-major-has-the-lowest-unemployment-rate",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#which-major-has-the-lowest-unemployment-rate",
    "title": "HW 04 - What should I major in?",
    "section": "Which major has the lowest unemployment rate?",
    "text": "Which major has the lowest unemployment rate?\nIn order to answer this question all we need to do is sort the data. We use the arrange function to do this, and sort it by the unemployment_rate variable. By default arrange sorts in ascending order, which is what we want here – we’re interested in the major with the lowest unemployment rate.\n\ncollege_recent_grads %&gt;%\n  arrange(unemployment_rate)\n\nThis gives us what we wanted, but not in an ideal form. First, the name of the major barely fits on the page. Second, some of the variables are not that useful (e.g. major_code, major_category) and some we might want front and center are not easily viewed (e.g. unemployment_rate).\nWe can use the select function to choose which variables to display, and in which order:\n\nNote how easily we expanded our code with adding another step to our pipeline,\nwith the pipe operator: `%&gt;%`.\n\n\ncollege_recent_grads %&gt;%\n  arrange(unemployment_rate) %&gt;%\n  select(rank, major, unemployment_rate)\n\nOk, this is looking better, but do we really need to display all those decimal places in the unemployment variable? Not really!\nWe can use the percent() function to clean up the display a bit.\n\ncollege_recent_grads %&gt;%\n  arrange(unemployment_rate) %&gt;%\n  select(rank, major, unemployment_rate) %&gt;%\n  mutate(unemployment_rate = percent(unemployment_rate))"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#which-major-has-the-highest-percentage-of-women",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#which-major-has-the-highest-percentage-of-women",
    "title": "HW 04 - What should I major in?",
    "section": "Which major has the highest percentage of women?",
    "text": "Which major has the highest percentage of women?\nTo answer such a question we need to arrange the data in descending order. For example, if earlier we were interested in the major with the highest unemployment rate, we would use the following:\n\nThe `desc` function specifies that we want `unemployment_rate` in descending order.\n\n\ncollege_recent_grads %&gt;%\n  arrange(desc(unemployment_rate)) %&gt;%\n  select(rank, major, unemployment_rate)\n\n\nUsing what you’ve learned so far, arrange the data in descending order with respect to proportion of women in a major, and display only the major, the total number of people with major, and proportion of women. Show only the top 3 majors by adding top_n(3) at the end of the pipeline."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#how-do-the-distributions-of-median-income-compare-across-major-categories",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#how-do-the-distributions-of-median-income-compare-across-major-categories",
    "title": "HW 04 - What should I major in?",
    "section": "How do the distributions of median income compare across major categories?",
    "text": "How do the distributions of median income compare across major categories?\n\nA percentile is a measure used in statistics indicating the value below which a given percentage of observations in a group of observations fall. For example, the 20th percentile is the value below which 20% of the observations may be found. (Source: [Wikipedia](https://en.wikipedia.org/wiki/Percentile)\n\nThere are three types of incomes reported in this data frame: p25th, median, and p75th. These correspond to the 25th, 50th, and 75th percentiles of the income distribution of sampled individuals for a given major.\n\nWhy do we often choose the median, rather than the mean, to describe the typical income of a group of people?\n\nThe question we want to answer “How do the distributions of median income compare across major categories?”. We need to do a few things to answer this question: First, we need to group the data by major_category. Then, we need a way to summarize the distributions of median income within these groups. This decision will depend on the shapes of these distributions. So first, we need to visualize the data.\nWe use the ggplot() function to do this. The first argument is the data frame, and the next argument gives the mapping of the variables of the data to the aesthetic elements of the plot.\nLet’s start simple and take a look at the distribution of all median incomes, without considering the major categories.\n\nggplot(data = college_recent_grads, mapping = aes(x = median)) +\n  geom_histogram()\n\nAlong with the plot, we get a message:\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nThis is telling us that we might want to reconsider the binwidth we chose for our histogram – or more accurately, the binwidth we didn’t specify. It’s good practice to always think in the context of the data and try out a few binwidths before settling on a binwidth. You might ask yourself: “What would be a meaningful difference in median incomes?” $1 is obviously too little, $10000 might be too high.\n\nTry binwidths of $1000 and $5000 and choose one. Explain your reasoning for your choice. Note that the binwidth is an argument for the geom_histogram function. So to specify a binwidth of $1000, you would use geom_histogram(binwidth = 1000).\n\nWe can also calculate summary statistics for this distribution using the summarise function:\n\ncollege_recent_grads %&gt;%\n  summarise(min = min(median), max = max(median),\n            mean = mean(median), med = median(median),\n            sd = sd(median), \n            q1 = quantile(median, probs = 0.25),\n            q3 = quantile(median, probs = 0.75))\n\n\nBased on the shape of the histogram you created in the previous exercise, determine which of these summary statistics is useful for describing the distribution. Write up your description (remember shape, center, spread, any unusual observations) and include the summary statistic output as well.\nPlot the distribution of median income using a histogram, faceted by major_category. Use the binwidth you chose in the earlier exercise.\n\nNow that we’ve seen the shapes of the distributions of median incomes for each major category, we should have a better idea for which summary statistic to use to quantify the typical median income.\n\nWhich major category has the highest typical (you’ll need to decide what this means) median income? Use the partial code below, filling it in with the appropriate statistic and function. Also note that we are looking for the highest statistic, so make sure to arrange in the correct direction.\n\n\ncollege_recent_grads %&gt;%\n  group_by(major_category) %&gt;%\n  summarise(___ = ___(median)) %&gt;%\n  arrange(___)\n\n\nWhich major category is the least popular in this sample? To answer this question we use a new function called count, which first groups the data and then counts the number of observations in each category (see below). Add to the pipeline appropriately to arrange the results so that the major with the lowest observations is on top.\n\n\ncollege_recent_grads %&gt;%\n  count(major_category)\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#all-stem-fields-arent-the-same",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#all-stem-fields-arent-the-same",
    "title": "HW 04 - What should I major in?",
    "section": "All STEM fields aren’t the same",
    "text": "All STEM fields aren’t the same\nOne of the sections of the FiveThirtyEight story is “All STEM fields aren’t the same”. Let’s see if this is true.\nFirst, let’s create a new vector called stem_categories that lists the major categories that are considered STEM fields.\n\nstem_categories &lt;- c(\"Biology & Life Science\",\n                     \"Computers & Mathematics\",\n                     \"Engineering\",\n                     \"Physical Sciences\")\n\nThen, we can use this to create a new variable in our data frame indicating whether a major is STEM or not.\n\ncollege_recent_grads &lt;- college_recent_grads %&gt;%\n  mutate(major_type = ifelse(major_category %in% stem_categories, \"stem\", \"not stem\"))\n\nLet’s unpack this: with mutate we create a new variable called major_type, which is defined as \"stem\" if the major_category is in the vector called stem_categories we created earlier, and as \"not stem\" otherwise.\n%in% is a logical operator. Other logical operators that are commonly used are\n\n\n\nOperator\nOperation\n\n\n\n\nx &lt; y\nless than\n\n\nx &gt; y\ngreater than\n\n\nx &lt;= y\nless than or equal to\n\n\nx &gt;= y\ngreater than or equal to\n\n\nx != y\nnot equal to\n\n\nx == y\nequal to\n\n\nx %in% y\ncontains\n\n\nx | y\nor\n\n\nx & y\nand\n\n\n!x\nnot\n\n\n\nWe can use the logical operators to also filter our data for STEM majors whose median earnings is less than median for all majors’ median earnings, which we found to be $36,000 earlier.\n\ncollege_recent_grads %&gt;%\n  filter(\n    major_type == \"stem\",\n    median &lt; 36000\n  )\n\n\nWhich STEM majors have median salaries equal to or less than the median for all majors’ median earnings? Your output should only show the major name and median, 25th percentile, and 75th percentile earning for that major as and should be sorted such that the major with the highest median earning is on top.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#what-types-of-majors-do-women-tend-to-major-in",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#what-types-of-majors-do-women-tend-to-major-in",
    "title": "HW 04 - What should I major in?",
    "section": "What types of majors do women tend to major in?",
    "text": "What types of majors do women tend to major in?\n\nCreate a scatterplot of median income vs. proportion of women in that major, coloured by whether the major is in a STEM field or not. Describe the association between these three variables."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#further-exploration",
    "href": "course-materials/hw-instructions/hw-04/hw-04-college-majors.html#further-exploration",
    "title": "HW 04 - What should I major in?",
    "section": "Further exploration",
    "text": "Further exploration\n\nAsk a question of interest to you, and answer it using summary statistic(s) and/or visualization(s).\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html",
    "href": "course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html",
    "title": "HW 02 - Airbnb listings in Edinburgh",
    "section": "",
    "text": "Photo by Madeleine Kohler on Unsplash\nOnce upon a time, people travelled all over the world, and some stayed in hotels and others chose to stay in other people’s houses that they booked through Airbnb. Recent developments in Edinburgh regarding the growth of Airbnb and its impact on the housing market means a better understanding of the Airbnb listings is needed. Using data provided by Airbnb, we can explore how Airbnb availability and prices vary by neighbourhood."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html#warm-up",
    "href": "course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html#warm-up",
    "title": "HW 02 - Airbnb listings in Edinburgh",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and knit the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html#packages",
    "href": "course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html#packages",
    "title": "HW 02 - Airbnb listings in Edinburgh",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html#data",
    "href": "course-materials/hw-instructions/hw-02/hw-02-airbnb-edi.html#data",
    "title": "HW 02 - Airbnb listings in Edinburgh",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it’s called edibnb. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package.\nYou can view the dataset as a spreadsheet using the View() function. Note that you should not put this function in your R Markdown document, but instead type it directly in the Console, as it pops open a new window (and the concept of popping open a window in a static document doesn’t really make sense…). When you run this in the console, you’ll see the following data viewer window pop up.\n\nView(edibnb)\n\nYou can find out more about the dataset by inspecting its documentation, which you can access by running ?edibnb in the Console or using the Help menu in RStudio to search for edibnb. You can also find this information here."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html",
    "href": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html",
    "title": "HW 10 - Wrap up!",
    "section": "",
    "text": "Photo by Kari Shea on Unsplash\nIt’s almost time to wrap up the course! In this three part assignment you get to practice what we learned this week, try something new, and get creative!"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html#warm-up",
    "href": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html#warm-up",
    "title": "HW 10 - Wrap up!",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html#packages",
    "href": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html#packages",
    "title": "HW 10 - Wrap up!",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for the first part of this assignment. For the second part you get to choose which package to use.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html#part-1---mirror-mirror-on-the-wall-whos-the-ugliest-of-them-all",
    "href": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html#part-1---mirror-mirror-on-the-wall-whos-the-ugliest-of-them-all",
    "title": "HW 10 - Wrap up!",
    "section": "Part 1 - Mirror, mirror on the wall, who’s the ugliest of them all?",
    "text": "Part 1 - Mirror, mirror on the wall, who’s the ugliest of them all?\nHere is a simple plot using the mpg dataset, which contains information on fuel economy of cars. We’re plotting highway miles per gallon vs. city miles per gallon, coloured by whether the car is front-wheel drive, rear wheel drive, or four-wheel drive.\n\nggplot(data = mpg, aes(x = cty, y = hwy, color = drv)) +\n  geom_point()\n\n\nI realize that \"ugly\" is subjective, so we're mostly looking to see if you can figure out how to change the look of a plot using help files of functions you haven't learned before.\n\n\nMake this plot as ugly as possible by changing colours, background color, fonts, or anything else you can think of. You will probably want to play around with theme options, but you can do more. You can also search online for other themes, fonts, etc. that you want to tweak. Try to make it as ugly as possible, the sky is the limit!\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html#part-2---you-gotta-pick-a-package-or-two",
    "href": "course-materials/hw-instructions/hw-10/hw-10-wrap-up.html#part-2---you-gotta-pick-a-package-or-two",
    "title": "HW 10 - Wrap up!",
    "section": "Part 2 - You gotta pick a package or two",
    "text": "Part 2 - You gotta pick a package or two\nBut really, one is enough. Pick a package from the list below, and use it to do something. If you want to use a package not on this list, that’s also ok, but it needs to be a package we haven’t used in class. If you start with a package and are struggling to get it to work, ask for help on Piazza or just move to another one.\n\n**Remember:** You *install* the package in the Console, not in the R Markdown document since you don't want to keep reinstalling it every time you knit the document.\n\nYour task is to install the package you pick. Depending on where the package comes from, how you install the package differs:\n\nIf the package is on CRAN (Comprehensive R Archive Network), you can install it with install.packages.\nIf the package is only on Github (most likely because it is still under development), you need to use the install_github function.\n\nThen, load the package. Regardless of how you installed the package you can load it with the library function.\nFinally, do something with the package. It doesn’t have to be complicated. In fact, keep it simple. The goal is for you to read and understand the package documentation to carry out a simple task.\n\n**Note:** For the output generated by some of these packages to show up properly, you might need to change the output of your R Markdown document from `github_document` to `html_document` in the YAML of your R Markdown document.\n\n\nWhich package are you using? State the name of the package, whether it was on CRAN or GitHub, and include the code for loading it. Also include a one sentence description of what the package does.Then, do something with the package and provide a brief narrative including code and output. Also comment on difficulties you had, if any, figuring out how to use the package.\n\n\nPackages on CRAN\nThese packages can be installed with:\n\ninstall.packages(\"PACKAGENAME\")\n\n\n\n\nPackage\nDescription\n\n\n\n\ncowsay\nAllows printing of character strings as messages/warnings/etc. with ASCII animals, including cats, cows, frogs, chickens, ghosts, and more\n\n\nbabynames\nUS Baby Names 1880-2015\n\n\ndragracer\nThese are data sets for the hit TV show, RuPaul’s Drag Race. Data right now include episode-level data, contestant-level data, and episode-contestant-level data\n\n\ndatapasta\nRStudio addins and R functions that make copy-pasting vectors and tables to text painless\n\n\nDiagrammeR\nGraph/Network Visualization\n\n\njaneaustenr\nFull texts for Jane Austen’s 6 completed novels, ready for text analysis. These novels are “Sense and Sensibility”, “Pride and Prejudice”, “Mansfield Park”, “Emma”, “Northanger Abbey”, and “Persuasion”\n\n\nggimage\nSupports image files and graphic objects to be visualized in ‘ggplot2’ graphic system\n\n\ngganimate\nCreate easy animations with ggplot2\n\n\ngt\nEasily Create Presentation-Ready Display Tables\n\n\nleaflet\nCreate Interactive Web Maps with the JavaScript ‘Leaflet’ Library\n\n\npraise\nBuild friendly R packages that praise their users if they have done something good, or they just need it to feel better\n\n\nplotly\nCreate interactive web graphics from ggplot2 graphs and/or a custom interface to the JavaScript library plotly.js inspired by the grammar of graphics\n\n\nsuncalc\nR interface to suncalc.js library, part of the SunCalc.net project, for calculating sun position, sunlight phases (times for sunrise, sunset, dusk, etc.), moon position and lunar phase for the given location and time\n\n\nschrute\nThe complete scripts from the American version of the Office television show in tibble format\n\n\nstatebins\nThe cartogram heatmaps generated by the included methods are an alternative to choropleth maps for the United States and are based on work by the Washington Post graphics department in their report on “The states most threatened by trade”\n\n\nttbbeer\nAn R data package of beer statistics from U.S. Department of the Treasury, Alcohol and Tobacco Tax and Trade Bureau (TTB)\n\n\nukbabynames\nFull listing of UK baby names occurring more than three times per year between 1996 and 2015, and rankings of baby name popularity by decade from 1904 to 1994\n\n\n\n\n\nPackages on GitHub only\nThese packages can be installed with:\n\nlibrary(devtools)\ninstall_github(\"USERNAME/PACKAGENAME\")\n\nUSERNAME refers to the user name of the developer of the package. For example, for the first package listed below, USERNAME is hadley and PACKAGENAME is emo.\n\n\n\nPackage\nDescription\n\n\n\n\nbingo\nGenerate Bingo cards\n\n\nBRRR\nBRRR extends the beepr package to include a number of rap adlibs\n\n\nCatterPlots\nPlots with Cats\n\n\ncooking\nChopping, peeling, frying, and cooking various ingredients, and combining them to a delicious ragout. Also includes buying them from a local supermarket\n\n\ndadjoke\nThe goal of dadjoke is to make you laugh in spite of yourself\n\n\nemo\nThe goal of emo(ji) is to make it very easy to insert emoji into RMarkdown documents\n\n\nemoGG\nUse Emoji in ggplot2\n\n\nemokid\nFor those times when you’re having trouble expressing how you feel about your broken code\n\n\nflametree\nThe goal of flametree is to make pretty pictures\n\n\nggbarf\nMake isotype bars using the vomit emoji\n\n\nggCyberPunk\nCreate Cyberpunk area and line plots\n\n\nggiraph\nCreate interactive ggplot2 graphics using htmlwidgets\n\n\nggkeyboard\nPlot a Keyboard Using ggplot2\n\n\njasmines\nMake generative art\n\n\nkandinsky\nTurn any dataset into a Kandinsky painting\n\n\nlego\nThis R data package contains information about every Lego set manufactured from 1970 to 2015, a total of 6172 sets\n\n\nlinkinpark\nData package that contains a few different datasets about the band\n\n\nprenoms\nFirst names given to babies in metropolitan France between 1900 and 2015\n\n\nraybonsai\nGenerate 3D procedural trees in R, rendered with rayrender! Procedural generation code based on the flametree package by Danielle Navarro.\n\n\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html",
    "href": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html",
    "title": "HW 07 - Bike rentals in DC",
    "section": "",
    "text": "Photo by Viktor Kern on Unsplash\nBike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return back has become automatic. Through these systems, user is able to easily rent a bike from a particular position and return back at another position. Currently, there are about over 500 bike-sharing programs around the world which is composed of over 500 thousands bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues.\nApart from interesting real world applications of bike sharing systems, the characteristics of data being generated by these systems make them attractive for the research. Opposed to other transport services such as bus or subway, the duration of travel, departure and arrival position is explicitly recorded in these systems. This feature turns bike sharing system into a virtual sensor network that can be used for sensing mobility in the city. Hence, it is expected that most of important events in the city could be detected via monitoring these data.\nSource: UCI Machine Learning Repository - Bike Sharing Dataset"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#warm-up",
    "href": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#warm-up",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises. Update the YAML of your R Markdown file with your information, knit, commit, and push your changes. Make sure to commit with a meaningful commit message. Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd and md files. If anything is missing, commit and push again."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#packages",
    "href": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#packages",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualisation and the data lives in the dsbox package. These packages are already installed for you. You can load them by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(dsbox)"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#data",
    "href": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#data",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it’s called dcbikeshare. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package. You can find out more about the dataset by inspecting its documentation, which you can access by running ?dcbikeshare in the Console or using the Help menu in RStudio to search for dcbikeshare. You can also find this information here.\nThe data include daily bike rental counts (by members and casual users) of Capital Bikeshare in Washington, DC in 2011 and 2012 as well as weather information on these days. The original data sources are http://capitalbikeshare.com/system-data and http://www.freemeteo.com."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#data-wrangling",
    "href": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#data-wrangling",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Data wrangling",
    "text": "Data wrangling\n\nRecode the season variable to be a factor with meaningful level names as outlined in the codebook, with spring as the baseline level.\nRecode the binary variables holiday and workingday to be factors with levels no (0) and yes (1), with no as the baseline level.\nRecode the yr variable to be a factor with levels 2011 and 2012, with 2011 as the baseline level.\nRecode the weathersit variable as 1 - clear, 2 - mist, 3 - light precipitation, and 4 - heavy precipitation, with clear as the baseline.\nCalculate raw temperature, feeling temperature, humidity, and windspeed as their values given in the dataset multiplied by the maximum raw values stated in the codebook for each variable. Instead of writing over the existing variables, create new ones with concise but informative names.\nCheck that the sum of casual and registered adds up to cnt for each record. Hint: One way of doing this is to create a new column that takes on the value TRUE if they add up and FALSE if not, and then checking if all values in that column are TRUEs. But this is only one way, you might come up with another.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#exploratory-data-analysis",
    "href": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#exploratory-data-analysis",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nRecreate the following visualization, and interpret it in context of the data. Hint: You will need to use one of the variables you created above. The temperature plotted is the feeling temperature.\n\n\n\n\n\n\n\n\n\n\n\nCreate a visualization displaying the relationship between bike rentals and season. Interpret the plot in context of the data.\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#modelling",
    "href": "course-materials/hw-instructions/hw-07/hw-07-bike-rentals-dc.html#modelling",
    "title": "HW 07 - Bike rentals in DC",
    "section": "Modelling",
    "text": "Modelling\n\nFit a linear model predicting total daily bike rentals from daily temperature. Write the linear model, interpret the slope and the intercept in context of the data, and determine and interpret the \\(R^2\\).\nFit another linear model predicting total daily bike rentals from daily feeling temperature. Write the linear model, interpret the slope and the intercept in context of the data, and determine and interpret the \\(R^2\\). Is temperature or feeling temperature a better predictor of bike rentals? Explain your reasoning.\nFit a model predicting total daily bike rentals from season, year, whether the day is holiday or not, whether the day is a workingday or not, the weather category, temperature, feeling temperature, humidity, and windspeed, as well as the interaction between feeling temperature and holiday. Record adjusted \\(R^2\\) of the model.\nWrite the linear models for holidays and non-holidays. Is the slope of temperature the same or different for these two models? How about the slope for feeling temperature? Why or why not?\nInterpret the slopes of season and feeling temperature. If the slopes are different for holidays and non-holidays, make sure to interpret both. If the variable has multiple levels, make sure you interpret all of the slope coefficients associated with it.\nInterpret the intercept. If the intercept is different for holidays and non-holidays, make sure to interpret both.\nAccording to this model, assuming everything else is the same, in which season does the model predict total daily bike rentals to be highest and which to be the lowest?\n\n🧶 ✅ ⬆️ Knit, commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you’re happy with the final state of your work."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html",
    "href": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html",
    "title": "HW 01 - Pet names",
    "section": "",
    "text": "Photo by Jovana Askrabic on Unsplash\nThe goal of this assignment is to introduce you to R, RStudio, Git, and GitHub, which you’ll be using throughout the course both to learn the data science concepts discussed in the course and to analyze real data and come to informed conclusions."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#prerequisites",
    "href": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#prerequisites",
    "title": "HW 01 - Pet names",
    "section": "Prerequisites",
    "text": "Prerequisites\nThis assignment assumes that you have reviewed the lectures titled “Meet the toolkit: Programming” and “Meet the toolkit: version control and collaboration”. If you haven’t yet done so, please pause and complete the following before continuing."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#terminology",
    "href": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#terminology",
    "title": "HW 01 - Pet names",
    "section": "Terminology",
    "text": "Terminology\nWe’ve already thrown around a few new terms, so let’s define them before we proceed.\n\nR: Name of the programming language we will be using throughout the course.\nRStudio: An integrated development environment for R. In other words, a convenient interface for writing and running R code.\nGit: A version control system.\nGitHub: A web platform for hosting version controlled files and facilitating collaboration among users.\nRepository: A Git repository contains all of your project’s files and stores each file’s revision history. It’s common to refer to a repository as a repo.\n\nIn this course, each assignment you work on will be contained in a Git repo.\nFor individual assignments, only you will have access to the repo. For team assignments, all team members will have access to a single repo where they work collaboratively.\nAll repos associated with this course are housed in the course GitHub organization. The organization is set up such that students can only see repos they have access to, but the course staff can see all of them."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#starting-slow",
    "href": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#starting-slow",
    "title": "HW 01 - Pet names",
    "section": "Starting slow",
    "text": "Starting slow\nAs the course progresses, you are encouraged to explore beyond what the assignments dictate; a willingness to experiment will make you a much better programmer! Before we get to that stage, however, you need to build some basic fluency in R. First, we will explore the fundamental building blocks of all of these tools.\nBefore you can get started with the analysis, you need to make sure you:\n\nhave a GitHub account\nare a member of the course GitHub organization\nare a member of the course RStudio Cloud space\n\nIf you failed to confirm any of these, it means you have not yet completed the prerequisites for this assignment. Please go back to Prerequisites and complete them before continuing the assignment."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#step-1.-update-the-yaml",
    "href": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#step-1.-update-the-yaml",
    "title": "HW 01 - Pet names",
    "section": "Step 1. Update the YAML",
    "text": "Step 1. Update the YAML\nOpen the R Markdown (Rmd) file in your project, change the author name to your name, and knit the document."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#step-2-commit",
    "href": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#step-2-commit",
    "title": "HW 01 - Pet names",
    "section": "Step 2: Commit",
    "text": "Step 2: Commit\nThen Go to the Git pane in your RStudio.\nYou should see that your Rmd (R Markdown) file and its output, your md file (Markdown), are listed there as recently changed files.\nNext, click on Diff. This will pop open a new window that shows you the difference between the last committed state of the document and its current state that includes your changes. If you’re happy with these changes, click on the checkboxes of all files in the list, and type “Update author name” in the Commit message box and hit Commit.\n\n\n\n\n\n\n\n\n\nYou don’t have to commit after every change, this would get quite cumbersome. You should consider committing states that are meaningful to you for inspection, comparison, or restoration. In the first few assignments we will tell you exactly when to commit and in some cases, what commit message to use. As the semester progresses we will let you make these decisions."
  },
  {
    "objectID": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#step-3.-push",
    "href": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#step-3.-push",
    "title": "HW 01 - Pet names",
    "section": "Step 3. Push",
    "text": "Step 3. Push\nNow that you have made an update and committed this change, it’s time to push these changes to the web! Or more specifically, to your repo on GitHub. Why? So that others can see your changes. And by others, we mean the course teaching team (your repos in this course are private to you and us, only). In order to push your changes to GitHub, click on Push.\n\n\n\n\n\n\n\n\n\nThis will prompt a dialogue box where you first need to enter your user name, and then your password. This might feel cumbersome. Bear with me… I will teach you how to save your password so you don’t have to enter it every time. But for this one assignment you’ll have to manually enter each time you push in order to gain some experience with it.\nThought exercise: Which of the above steps (updating the YAML, committing, and pushing) needs to talk to GitHub?1"
  },
  {
    "objectID": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#footnotes",
    "href": "course-materials/hw-instructions/hw-01/hw-01-pet-names.html#footnotes",
    "title": "HW 01 - Pet names",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOnly pushing requires talking to GitHub, this is why you’re asked for your password at that point.↩︎"
  },
  {
    "objectID": "course-materials/project-instructions/repo-structure/proposal/proposal.html",
    "href": "course-materials/project-instructions/repo-structure/proposal/proposal.html",
    "title": "Project proposal",
    "section": "",
    "text": "library(tidyverse)\nlibrary(broom)"
  },
  {
    "objectID": "course-materials/project-instructions/repo-structure/proposal/proposal.html#introduction",
    "href": "course-materials/project-instructions/repo-structure/proposal/proposal.html#introduction",
    "title": "Project proposal",
    "section": "1. Introduction",
    "text": "1. Introduction"
  },
  {
    "objectID": "course-materials/project-instructions/repo-structure/proposal/proposal.html#data",
    "href": "course-materials/project-instructions/repo-structure/proposal/proposal.html#data",
    "title": "Project proposal",
    "section": "2. Data",
    "text": "2. Data"
  },
  {
    "objectID": "course-materials/project-instructions/repo-structure/proposal/proposal.html#data-analysis-plan",
    "href": "course-materials/project-instructions/repo-structure/proposal/proposal.html#data-analysis-plan",
    "title": "Project proposal",
    "section": "3. Data analysis plan",
    "text": "3. Data analysis plan"
  },
  {
    "objectID": "course-materials/project-instructions/project.html#data",
    "href": "course-materials/project-instructions/project.html#data",
    "title": "Showcase your inner data scientist",
    "section": "Data",
    "text": "Data\nIn order for you to have the greatest chance of success with this project it is important that you choose a manageable dataset. This means that the data should be readily accessible and large enough that multiple relationships can be explored. As such, your dataset must have at least 50 observations and between 10 to 20 variables (exceptions can be made but you must speak with me first). The dataset’s variables should include categorical variables, discrete numerical variables, and continuous numerical variables.\nIf you are using a dataset that comes in a format that we haven’t encountered in class, make sure that you are able to load it into R as this can be tricky depending on the source. If you are having trouble ask for help before it is too late.\nNote on reusing datasets from class: Do not reuse datasets used in examples, homework assignments, or labs in the class.\nBelow are a list of data repositories that might be of interest to browse. You’re not limited to these resources, and in fact you’re encouraged to venture beyond them. But you might find something interesting there:\n\nTidyTuesday\nNHS Scotland Open Data\nEdinburgh Open Data\nOpen access to Scotland’s official statistics\nBikeshare data portal\nUK Gov Data\nKaggle datasets\nOpenIntro datasets\nAwesome public datasets\nYouth Risk Behavior Surveillance System (YRBSS)\nPRISM Data Archive Project\nHarvard Dataverse\nIf you know of others, let me know, and we’ll add here…"
  },
  {
    "objectID": "course-materials/project-instructions/project.html#deliverables",
    "href": "course-materials/project-instructions/project.html#deliverables",
    "title": "Showcase your inner data scientist",
    "section": "Deliverables",
    "text": "Deliverables\n\nProposal - due [ENTER DUE DATE]\nPresentation - due [ENTER DUE DATE]\nExecutive summary - due [ENTER DUE DATE]\n\n\nProposal\nThis is a draft of the introduction section of your project as well as a data analysis plan and your dataset.\n\nSection 1 - Introduction: The introduction should introduce your general\nresearch question and your data (where it came from, how it was collected,\nwhat are the cases, what are the variables, etc.).\nSection 2 - Data: Place your data in the `/data` folder, and add dimensions and codebook to the README in that folder. Then print out the output of and codebook to the README in that folder. Then print out the output of glimpse() or skim() of your data frame.\nSection 3 - Data analysis plan:\n\nThe outcome (response, Y) and predictor (explanatory, X) variables you will use to answer your question.\nThe comparison groups you will use, if applicable.\nVery preliminary exploratory data analysis, including some summary statistics and visualizations, along with some explanation on how they help you learn more about your data. (You can add to these later as you work on your project.)\nThe method(s) that you believe will be useful in answering your question(s). (You can update these later as you work on your project.)\nWhat results from these specific statistical methods are needed to support your hypothesized answer?\n\n\nEach section should be no more than 1 page (excluding figures). You can check a print preview to confirm length.\nThe grading scheme for the project proposal is as follows. Note that after you receive feedback for your proposal you can improve it based on the feedback and re-submit it. If you re-submit, your final score for the proposal will be the average of two scores you receive (first and second submission).\n\n\n\nTotal\n10 pts\n\n\n\n\nData\n3 pts\n\n\nProposal\n5 pts\n\n\nWorkflow, organization, code quality\n1 pt\n\n\nTeamwork\n1 pt\n\n\n\n\n\nPresentation\n5 minutes maximum, and each team member should say something substantial. You can either present live during your workshop or pre-record and submit your video to be played during the workshop.\nPrepare a slide deck using the template in your repo. This template uses a package called xaringan, and allows you to make presentation slides using R Markdown syntax. There isn’t a limit to how many slides you can use, just a time limit (5 minutes total). Each team member should get a chance to speak during the presentation. Your presentation should not just be an account of everything you tried (“then we did this, then we did this, etc.”), instead it should convey what choices you made, and why, and what you found.\nBefore you finalize your presentation, make sure your chunks are turned off with echo = FALSE.\nPresentations will take place during the last workshop of the semester. You can choose to do your presentation live or pre-record it. During your workshop you will watch presentations from other teams in your workshop and provide feedback in the form of peer evaluations. The presentation line-up will be generated randomly.\nThe grading scheme for the presentation is as follows:\n\n\n\n\n\n\n\nTotal\n50 pts\n\n\n\n\nTime management: Did the team divide the time well amongst themselves or got cut off going over time?\n4 pts\n\n\nContent: Is the research question well designed and is the data being used relevant to the research question?\n5 pts\n\n\nProfessionalism: How well did the team present? Does the presentation appear to be well practiced? Did everyone get a chance to say something meaningful about the project?\n5 pts\n\n\nTeamwork: Did the team present a unified story, or did it seem like independent pieces of work patched together?\n6 pts\n\n\nContent: Did the team use appropriate statistical procedures and interpretations of results accurately?\n10 pts\n\n\nCreativity and Critical Thought: Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n10 pts\n\n\nSlides: Are the slides well organized, readable, not full of text, featuring figures with legible labels, legends, etc.?\n10 pts\n\n\n\n\n\nExecutive summary\nAlong with your presentation slides, we want you to provide a brief summary of your project in the README of your repository.\nThis executive summary should provide information on the dataset you’re using, your research question(s), your methodology, and your findings.\nThe executive summary is worth 15 points and will be evaluated based on whether it follows guidance and whether it’s concise but detailed enough.\n\n\nRepo organization\nThe following folders and files in your project repository:\n\npresentation.Rmd + presentation.html: Your presentation slides\nREADME.Rmd + README.md: Your write-up\n/data: Your dataset in CSV or RDS format and your data dictionary\n/proposal: Your project proposal\n\nStyle and format does count for this assignment, so please take the time to make sure everything looks good and your data and code are properly formatted."
  },
  {
    "objectID": "course-materials/project-instructions/project.html#tips",
    "href": "course-materials/project-instructions/project.html#tips",
    "title": "Showcase your inner data scientist",
    "section": "Tips",
    "text": "Tips\n\nYou’re working in the same repo as your teammates now, so merge conflicts will happen, issues will arise, and that’s fine Commit and push often, and ask questions when stuck.\nReview the marking guidelines below and ask questions if any of the expectations are unclear.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nSet aside time to work together and apart (physically).\nWhen you’re done, review the documents on GitHub to make sure you’re happy with the final state of your work. Then go get some rest!\nCode: In your presentation your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your R Markdown file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcomed to show that portion.\n\nTeamwork: You are to complete the assignment as a team. All team members are expected to contribute equally to the completion of this assignment and team evaluations will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works."
  },
  {
    "objectID": "course-materials/project-instructions/project.html#marking",
    "href": "course-materials/project-instructions/project.html#marking",
    "title": "Showcase your inner data scientist",
    "section": "Marking",
    "text": "Marking\n\n\n\nTotal\n100 pts\n\n\n\n\nProposal\n10 pts\n\n\nPresentation\n50 pts\n\n\nExecutive summary\n15 pts\n\n\nReproducibility and organization\n10 pts\n\n\nTeam peer evaluation\n10 pts\n\n\nClassmates’ evaluation\n5 pts\n\n\n\n\nCriteria\nYour project will be assessed on the following criteria:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100% - Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89% - Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79% - Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69% - Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60% - Student is not making a sufficient effort.\n\n\n\nTeam peer evaluation\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member out of 10 points. You will additionally report a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation.If you are suggesting that an individual did less than 20% of the work, please provide some explanation. If any individual gets an average peer score indicating that they did less than 10% of the work, this person will receive half the grade of the rest of the group.\n\n\nLate work policy\n\nThere is no late submission / make up for the presentation. You must be in class on the day of the presentation to get credit for it or pre-record and submit your presentation by 9am in the morning of the presentations.\nThe late work policy for the write-up is 5% of the maximum obtainable mark per calendar day up to seven calendar days after the deadline. If you intend to submit work late for the project, you must notify the course organizer before the original deadline as well as as soon as the completed work is submitted on GitHub."
  },
  {
    "objectID": "03-discussion.html",
    "href": "03-discussion.html",
    "title": "Discussion",
    "section": "",
    "text": "My recommended tool for course discussion is Piazza.\nI have, in the past, used Slack for course communication as well. Slack has the advantage of being real-life feeling as well as being the communication tool of choice for many data science teams. However it doesn’t work well for lasting class discussions as threading and searchability are poor. Additionally, the instructor does not have the option to edit student questions, which can be frustrating if they have not formatted their code appropriately. Similar tools like Discord and MS Teams have similar advantages when it comes to real-life discussions and similar disadvantages when it comes to threading and searchability.\nOther options are GitHub issues and GitHub Discussions, especially for courses using version control.",
    "crumbs": [
      "Infrastructure",
      "Discussion"
    ]
  },
  {
    "objectID": "kudos/kudos.html",
    "href": "kudos/kudos.html",
    "title": "CS112 - Data Structures",
    "section": "",
    "text": "2021-03-17\n\nDear Mine,\nI wanted to take this opportunity to thank you for the wonderful Data Science in a Box materials.  I have been using them extensively in a new course I am putting together.  The title of the course is “predictive analytics” but I also am tasked with teaching them programming and getting data ready, so your course is at a great level for the students who have only had one introductory course in statistics.  I am adding and subtracting things but having your work was a life saver for me given all that is going on.  I am hopefully giving you appropriate creative attribution.\nhttps://laurark.github.io/sta323content/slides/u1-d02-toolkit-r/u1-d02-toolkit-r.html#2 is an example of how I did it on a slide.\nI have learned so much from you..  Thank you so very much for all the work you do and for your wonderful materials and training videos.\nI was able to integrate the XaringanXtra scribble into my slides as well.  https://pkg.garrickadenbuie.com/xaringanExtra/#/scribble  . I was super excited, impressed and grateful Matt and Garrett built this after I asked for it.\nThank you again.\nLaura\nLaura Ring Kapitula, PhD Associate Professor Department of Statistics\nGrand Valley State University"
  },
  {
    "objectID": "02-looking-further.html",
    "href": "02-looking-further.html",
    "title": "Looking further",
    "section": "",
    "text": "In the last unit we present a series of modules such as interactive reporting and visualization with Shiny, text analysis, machine learning, and Bayesian inference. These are independent modules that educators can choose to include in their introductory data science curriculum depending on how much time they have left in the semester. Note that the slides in this unit are a bit more sparse than the others, and much of the content is delivered as live coding sessions.",
    "crumbs": [
      "Content",
      "Looking further"
    ]
  },
  {
    "objectID": "02-looking-further.html#slides-videos-and-application-exercises",
    "href": "02-looking-further.html#slides-videos-and-application-exercises",
    "title": "Looking further",
    "section": "Slides, videos, and application exercises",
    "text": "Slides, videos, and application exercises\n\nUnit 5 - Deck 1: Text analysis\n\nSlides\n\n\nSource\n\n\nVideo\n\n\n\nUnit 5 - Deck 2: Comparing texts\n\nSlides\n\n\nSource\n\n\nVideo\n\n\n\nUnit 5 - Deck 3: Interactive web apps\n\nSlides\n\n\nSource\n\n\nVideo\n\n\n\nUnit 5 - Deck 4: Machine learning\n\nSlides\n\n\nSource\n\n\nVideo\n\n\n\nUnit 5 - Deck 5: Interactive data visualisation\n\nSlides\n\n\n\nUnit 5 - Deck 6: Interactive data visualisation and reporting\n\nSlides\n\n\n\nUnit 5 - Deck 7: Bayesian inference\n\nSlides\n\n\nSource",
    "crumbs": [
      "Content",
      "Looking further"
    ]
  },
  {
    "objectID": "02-looking-further.html#labs",
    "href": "02-looking-further.html#labs",
    "title": "Looking further",
    "section": "Labs",
    "text": "Labs\n\nLab 13: Working on projects\nFitting and interpreting simple linear regression models\n\nInstructions\n\n\nSource\n\n\n\nLab 14: Collaboration on GitHub\nFitting and interpreting simple linear regression models\n\nInstructions\n\n\nSource",
    "crumbs": [
      "Content",
      "Looking further"
    ]
  },
  {
    "objectID": "02-looking-further.html#homework-assignments",
    "href": "02-looking-further.html#homework-assignments",
    "title": "Looking further",
    "section": "Homework assignments",
    "text": "Homework assignments\n\nHW 10: Wrapping up\nModel validation and inference\n\nInstructions\n\n\nSource\n\n\nStarter",
    "crumbs": [
      "Content",
      "Looking further"
    ]
  },
  {
    "objectID": "03-access-r.html",
    "href": "03-access-r.html",
    "title": "Accessing R",
    "section": "",
    "text": "The RStudio IDE includes a viewable environment, a file browser, data viewer, and a plotting pane, which makes it less intimidating than the bare R shell. Additionally, since it is a full fledged IDE, it also features integrated help, syntax highlighting, and context-aware tab completion, which are all powerful tools that help flatten the learning curve.\nRStudio Cloud is a managed cloud instance of the RStudio IDE. We recommend having students access RStudio via RStudio Cloud as opposed to using a local installation. The main reason for this choice is reducing friction at first exposure to R. Local installation can be difficult to manage, both for the student and the instructor, and can shift the focus away from data science learning at the beginning of the course. We discuss in further detail the reasons for avoiding local installation at the beginning of the course in Design Principles.1\nWhen you create an account on RStudio Cloud, you get a workspace of your own, and the projects you create here can be public or private. You can also add a new workspace and control its permissions, and the projects you create here can also be public or private.\nA natural way to set up a course in RStudio Cloud is using a private workspace. In this structure a classroom (a cohort of students in one semester of the course) maps to a workspace. Once a workspace is set up, instructors can invite students to the workspace via an invite link. Workspaces allow for various permission levels which can be assigned to students, teaching assistants, and instructors. Then, each assignment/project in the course maps to an RStudio Cloud project.\nRStudio Cloud classroom structure",
    "crumbs": [
      "Infrastructure",
      "Accessing R"
    ]
  },
  {
    "objectID": "03-access-r.html#setting-up-your-course-in-rstudio-cloud",
    "href": "03-access-r.html#setting-up-your-course-in-rstudio-cloud",
    "title": "Accessing R",
    "section": "Setting up your course in RStudio Cloud",
    "text": "Setting up your course in RStudio Cloud\nFirst, create a new workspace on RStudio Cloud. By default, this new workspace will be a private workspace. All it takes to create a new workspace is a name and brief information for the space. You can update the information once the space is created, however you can’t change the name of the space. For the name,\nI recommend using something along the lines of Course number - Semester.\n\n\n\n\n\nCreating a new workspace on RStudio Cloud\n\n\n\n\nNext step is to invite members to the workspace. You can do this by sending invitations or using a sharing link. I recommend using the latter approach for efficiency. Once all of your students are in the course (or once drop/add period ends) you can change the settings so that additional members cannot join throughout the semester using the sharing link, and can only be added via an invitation from the instructor.\n\n\n\n\n\nSetting workspace permissions\n\n\n\n\nAs highlighted in the figure above, when a workspace is set to accept members via a shared link, the owner can also set a default permission level for those entering the workspace via the sharing link. Suggested permission levels and suggestions for mapping to course roles are as follows.\n\n\n\n\n\n\n\n\nRStudio Cloud role\nPermissions\nCourse role\n\n\n\n\nAdmin\nManage users, view, edit and manage all projects\nInstructor\n\n\nModerator\nView, edit and manage all projects\nTeaching Assistant\n\n\nContributor\nCreate, edit and manage their own projects\nStudent\n\n\nViewer\nView projects shared with everyone\nAuditor, Visitor\n\n\n\nThis set of permissions will allow instructors full access including management of users. Teaching assistants will be able to peek into student projects, which can be very useful when helping troubleshoot. Students won’t be able to see each others’ projects. Students auditing your course or visitors, such as colleagues wanting to view/experience your course setup will have limited access.\nRStudio Cloud also allows you to specify who can see the list of members. Admins and moderators can, by default, see all members of the workspace. I prefer to allow contributors (students) to see the list of members and viewers (auditors and visitors) to not since course enrollment information should not be available to non-official members of the course.",
    "crumbs": [
      "Infrastructure",
      "Accessing R"
    ]
  },
  {
    "objectID": "03-access-r.html#projects",
    "href": "03-access-r.html#projects",
    "title": "Accessing R",
    "section": "Projects",
    "text": "Projects\nA project in RStudio Cloud is equivalent to an RStudio project. If you are an RStudio user, but you don’t use projects, I highly recommend considering switching your workflow to include projects. You can learn more about them here.\n\n\n\n\n\nA new project in RStudio Cloud is a new project in the RStudio IDE\n\n\n\n\n\nAccess\nWhen you create a new project in your workspace, it is by default visible only to you plus the admins and moderators of the space. This default has two advantages:\n\nIt allows you to develop a project semi-privately and actively decide when the project is ready to be shared with students. This can be especially beneficial when developing an assessment like an exam.\nIt means when a student creates a project in the workspace it’s not, by default, visible to other students.\n\nWhen your project is ready to be shared with the students in your course, you can adjust the access level by clicking on the gear icon to reveal the settings menu. You should also check the “Make this project an assignment” box so that when a student starts their assignment RStudio Cloud automatically makes a copy of the project for them.\n\n\n\n\n\nSetting project permissions within a workspace",
    "crumbs": [
      "Infrastructure",
      "Accessing R"
    ]
  },
  {
    "objectID": "03-access-r.html#base-project-template",
    "href": "03-access-r.html#base-project-template",
    "title": "Accessing R",
    "section": "Base project template",
    "text": "Base project template\nIf you consistently use a particular set of packages and/or need a particular set of documents to be included in each project, the base project template functionality will come in very handy. You can use this by defining a base project template for the space. Simply create a new project and add any packages or files you want projects created in the space to start with. After creating your project, select it on the Settings page as the base project template.\n\n\n\n\n\nSelecting a base project template\n\n\n\n\nNote that a project must be shared with everyone in the space in order to be used as a template; only projects which are viewable by everyone in the space will appear in the templates list.\nYou can update your base project as many times as you want throughout the semester. The base template is applied prospectively – it only effects projects created after the template has been set. Therefore updating the base project will not break projects already created with the previous version of a base project.",
    "crumbs": [
      "Infrastructure",
      "Accessing R"
    ]
  },
  {
    "objectID": "03-access-r.html#git-integration",
    "href": "03-access-r.html#git-integration",
    "title": "Accessing R",
    "section": "Git integration",
    "text": "Git integration\nIt is possible to create (clone) a new project in RStudio Cloud from a GitHub repository, just like in the RStudio IDE.\n\n\n\n\n\nCreating a new project from GitHub repository\n\n\n\n\nIf you have a base project template set up for your workspace, this new project created from GitHub will also have the packages installed in the base project template.\nFor more on using Git and GitHub in the classroom, see Version Control.",
    "crumbs": [
      "Infrastructure",
      "Accessing R"
    ]
  },
  {
    "objectID": "03-access-r.html#troubleshooting",
    "href": "03-access-r.html#troubleshooting",
    "title": "Accessing R",
    "section": "Troubleshooting",
    "text": "Troubleshooting\nI strongly recommend that you make a second account for themselves on RStudio Cloud and add that user as a contributor to the workspace to be able to see what your students see when they log in. It’s a great way to test out functionality and resolve unexpected issues your students might encounter, before they encounter them. I recommend using an incognito browser window for the student account so that you can stay logged in both as a student and as the instructor at the same time and test the student view as you develop content as an instructor.\nOne huge advantage of your students working in RStudio Cloud is that you as the instructor, and anyone with an admin and moderator role, can peek into student projects. While it is important for your students to learn to ask questions in a way that does not depend on someone else being able to see their work directly (and for this I strongly recommend teaching students to make reprexes), it is sometimes, especially early on, nice to be able to peek into a student’s project.",
    "crumbs": [
      "Infrastructure",
      "Accessing R"
    ]
  },
  {
    "objectID": "03-access-r.html#limits",
    "href": "03-access-r.html#limits",
    "title": "Accessing R",
    "section": "Limits",
    "text": "Limits\n\nMemory & CPU\nEach project on RStudio Cloud is allocated 1 GB of RAM and 1 CPU by default. While this is a pretty generous limit, actions like joining very large tables or fitting complicated models could exceed the limit.\nI recommend testing out the any work you assign, especially those using large datasets, in order to avoid unexpected hiccups due to out of memory issues. One challenge is that you might have no control over what issues students might run into if they are working on an open ended project using a dataset of their own choice. In these circumstances it’s helpful to keep in the back of your mind that one way an out of memory issue can present itself is with the RStudio Cloud project crashing.\n\n\nOther limits\nFor most up to date information on limits on free RStudio Cloud accounts, as well as any other technical details, see the RStudio Cloud Guide. This document gets updated as changes are made to the user interface and/or the backend of RStudio Cloud and should be assumed to be more current than the information outlined here.",
    "crumbs": [
      "Infrastructure",
      "Accessing R"
    ]
  },
  {
    "objectID": "03-access-r.html#learn-more",
    "href": "03-access-r.html#learn-more",
    "title": "Accessing R",
    "section": "Learn more",
    "text": "Learn more\nTo see this all in action and learn more, watch the following RStudio Cloud webinars:\n\nTeaching R online with RStudio Cloud (July 2020)\nTeaching R online with RStudio Cloud (March 2020)\nRStudio Cloud in the Classroom",
    "crumbs": [
      "Infrastructure",
      "Accessing R"
    ]
  },
  {
    "objectID": "03-access-r.html#footnotes",
    "href": "03-access-r.html#footnotes",
    "title": "Accessing R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote that as of August 2020 RStudio Cloud offers paid tiers as well, and you will likely need a paid subscription to teach with RStudio Cloud (unless you’re teaching a short, small course). Depending on your institution’s IT infrastructure and your class size, RStudio Cloud may or may not be the most economically feasible solution for your teaching needs. See Alternative Setups for suggestions for other setups for providing server access to RStudio for your students. Note that these alternatives generally require system infrastructure expertise or IT professional time.↩︎",
    "crumbs": [
      "Infrastructure",
      "Accessing R"
    ]
  },
  {
    "objectID": "01-tech-stack.html",
    "href": "01-tech-stack.html",
    "title": "Tech stack",
    "section": "",
    "text": "This course teaches computing and statistics to undergraduates with no background in either. Managing such a course with students from varied backgrounds doing non-trivial computational work is a big technical challenge. This page briefly describes the toolkit choices, and the Infrastructure part provides a path forward for educators who are considering using these tools for their own teaching purposes.\nWhile the recommended tech stack for the entirety of course development is tall, only a few of the technologies are student facing:\n\nRStudio Cloud: RStudio Cloud is a managed cloud instance of the RStudio IDE. We recommend having students access RStudio via RStudio Cloud as opposed to using a local installation. See Accessing R for more on this.\nGitHub: The use of GitHub also goes a long way to help students visualize and understand the git process which also aids in student buy-in. The web interface allows students to easily view diffs (file changes over time) in files they are collaborating on, keep track of commit histories, and search both the current state as well as the entire history of the code base. Within the classroom GitHub can be thought of as an advanced and flexible learning management system (compared to traditional tools like Blackboard or Sakai). See Version Control for more on this.\nPiazza: Piazza is an easy to use and free Q&A platform that your students might very well be already familiar with from other classes. It is also possible that it’s already integrated into your learning management system if you’re teaching in a university setting. Students are discouraged from using email for questions and discussions related to content of the course, only emails about personal matters are allowed. Hence most course communication happens on Piazza. Both public (for announcements and general questions) and private (for team communication) channels are used. Note that Piazza is not everyone’s first choice, a few options for alternatives used in statistics and data science courses can be found on this Twitter thread.",
    "crumbs": [
      "Hello #dsbox!",
      "Tech stack"
    ]
  }
]